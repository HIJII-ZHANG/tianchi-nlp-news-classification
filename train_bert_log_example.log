2025-12-15 16:44:52 - train - INFO - File logging enabled: /root/work/tianchi-nlp-news-classification/bert_train_log_example.log
2025-12-15 16:45:02 - models.bert_model - WARNING - use_multi_gpu=True but only 1 GPU available
2025-12-15 16:45:02 - models.bert_model - INFO - Initialized BERT classifier with device: cuda, Multi-GPU: False
2025-12-15 16:45:02 - models.bert_model - INFO - Starting BERT training with 180000 samples
2025-12-15 16:45:34 - models.bert_model - INFO - Built vocabulary with 6000 tokens
2025-12-15 16:45:34 - models.bert_model - INFO - Number of classes: 14
2025-12-15 16:45:35 - models.bert_model - INFO - Train size: 162000, Validation size: 18000
2025-12-15 16:45:35 - models.bert_model - INFO - Encoding training texts...
2025-12-15 16:46:09 - models.bert_model - INFO - Encoding validation texts...
2025-12-15 16:46:14 - models.bert_model - INFO - Model parameters: 49,321,230
2025-12-15 16:46:14 - models.bert_model - INFO - Using Focal Loss with gamma=2.0
2025-12-15 16:46:14 - models.bert_model - INFO - Training config: warmup_steps=3796, total_steps=25312, gradient_accumulation=4
2025-12-15 16:46:29 - models.bert_model - INFO - Epoch 1/10 - Batch 40/10125 - Loss: 2.3235 - Acc: 4.69% - LR: 3.95e-08
2025-12-15 16:46:43 - models.bert_model - INFO - Epoch 1/10 - Batch 80/10125 - Loss: 2.4444 - Acc: 5.31% - LR: 7.90e-08
2025-12-15 16:46:58 - models.bert_model - INFO - Epoch 1/10 - Batch 120/10125 - Loss: 2.3083 - Acc: 5.16% - LR: 1.19e-07
2025-12-15 16:47:12 - models.bert_model - INFO - Epoch 1/10 - Batch 160/10125 - Loss: 2.3125 - Acc: 5.35% - LR: 1.58e-07
2025-12-15 16:47:27 - models.bert_model - INFO - Epoch 1/10 - Batch 200/10125 - Loss: 2.2973 - Acc: 5.53% - LR: 1.98e-07
2025-12-15 16:47:41 - models.bert_model - INFO - Epoch 1/10 - Batch 240/10125 - Loss: 2.3639 - Acc: 6.25% - LR: 2.37e-07
2025-12-15 16:47:56 - models.bert_model - INFO - Epoch 1/10 - Batch 280/10125 - Loss: 2.3125 - Acc: 6.79% - LR: 2.77e-07
2025-12-15 16:48:10 - models.bert_model - INFO - Epoch 1/10 - Batch 320/10125 - Loss: 2.1706 - Acc: 7.58% - LR: 3.16e-07
2025-12-15 16:48:25 - models.bert_model - INFO - Epoch 1/10 - Batch 360/10125 - Loss: 2.1873 - Acc: 8.02% - LR: 3.56e-07
2025-12-15 16:48:39 - models.bert_model - INFO - Epoch 1/10 - Batch 400/10125 - Loss: 2.2268 - Acc: 8.50% - LR: 3.95e-07
2025-12-15 16:48:54 - models.bert_model - INFO - Epoch 1/10 - Batch 440/10125 - Loss: 2.1673 - Acc: 9.20% - LR: 4.35e-07
2025-12-15 16:49:08 - models.bert_model - INFO - Epoch 1/10 - Batch 480/10125 - Loss: 2.1596 - Acc: 9.87% - LR: 4.74e-07
2025-12-15 16:49:23 - models.bert_model - INFO - Epoch 1/10 - Batch 520/10125 - Loss: 2.0553 - Acc: 10.22% - LR: 5.14e-07
2025-12-15 16:49:38 - models.bert_model - INFO - Epoch 1/10 - Batch 560/10125 - Loss: 2.1534 - Acc: 10.80% - LR: 5.53e-07
2025-12-15 16:49:52 - models.bert_model - INFO - Epoch 1/10 - Batch 600/10125 - Loss: 2.3352 - Acc: 11.43% - LR: 5.93e-07
2025-12-15 16:50:07 - models.bert_model - INFO - Epoch 1/10 - Batch 640/10125 - Loss: 2.0415 - Acc: 11.81% - LR: 6.32e-07
2025-12-15 16:50:21 - models.bert_model - INFO - Epoch 1/10 - Batch 680/10125 - Loss: 2.1564 - Acc: 12.03% - LR: 6.72e-07
2025-12-15 16:50:36 - models.bert_model - INFO - Epoch 1/10 - Batch 720/10125 - Loss: 1.9636 - Acc: 12.49% - LR: 7.11e-07
2025-12-15 16:50:50 - models.bert_model - INFO - Epoch 1/10 - Batch 760/10125 - Loss: 2.0768 - Acc: 12.78% - LR: 7.51e-07
2025-12-15 16:51:05 - models.bert_model - INFO - Epoch 1/10 - Batch 800/10125 - Loss: 1.7100 - Acc: 13.05% - LR: 7.90e-07
2025-12-15 16:51:19 - models.bert_model - INFO - Epoch 1/10 - Batch 840/10125 - Loss: 1.9984 - Acc: 13.27% - LR: 8.30e-07
2025-12-15 16:51:34 - models.bert_model - INFO - Epoch 1/10 - Batch 880/10125 - Loss: 2.1945 - Acc: 13.62% - LR: 8.69e-07
2025-12-15 16:51:48 - models.bert_model - INFO - Epoch 1/10 - Batch 920/10125 - Loss: 1.8460 - Acc: 13.70% - LR: 9.09e-07
2025-12-15 16:52:03 - models.bert_model - INFO - Epoch 1/10 - Batch 960/10125 - Loss: 2.0025 - Acc: 14.08% - LR: 9.48e-07
2025-12-15 16:52:17 - models.bert_model - INFO - Epoch 1/10 - Batch 1000/10125 - Loss: 1.6864 - Acc: 14.40% - LR: 9.88e-07
2025-12-15 16:52:32 - models.bert_model - INFO - Epoch 1/10 - Batch 1040/10125 - Loss: 1.8503 - Acc: 14.66% - LR: 1.03e-06
2025-12-15 16:52:46 - models.bert_model - INFO - Epoch 1/10 - Batch 1080/10125 - Loss: 2.3534 - Acc: 14.82% - LR: 1.07e-06
2025-12-15 16:53:01 - models.bert_model - INFO - Epoch 1/10 - Batch 1120/10125 - Loss: 2.3625 - Acc: 14.88% - LR: 1.11e-06
2025-12-15 16:53:15 - models.bert_model - INFO - Epoch 1/10 - Batch 1160/10125 - Loss: 1.9740 - Acc: 15.04% - LR: 1.15e-06
2025-12-15 16:53:30 - models.bert_model - INFO - Epoch 1/10 - Batch 1200/10125 - Loss: 1.7401 - Acc: 15.16% - LR: 1.19e-06
2025-12-15 16:53:44 - models.bert_model - INFO - Epoch 1/10 - Batch 1240/10125 - Loss: 1.8022 - Acc: 15.37% - LR: 1.22e-06
2025-12-15 16:53:59 - models.bert_model - INFO - Epoch 1/10 - Batch 1280/10125 - Loss: 2.0925 - Acc: 15.54% - LR: 1.26e-06
2025-12-15 16:54:13 - models.bert_model - INFO - Epoch 1/10 - Batch 1320/10125 - Loss: 1.8164 - Acc: 15.71% - LR: 1.30e-06
2025-12-15 16:54:28 - models.bert_model - INFO - Epoch 1/10 - Batch 1360/10125 - Loss: 1.7525 - Acc: 15.89% - LR: 1.34e-06
2025-12-15 16:54:42 - models.bert_model - INFO - Epoch 1/10 - Batch 1400/10125 - Loss: 2.0674 - Acc: 16.12% - LR: 1.38e-06
2025-12-15 16:54:57 - models.bert_model - INFO - Epoch 1/10 - Batch 1440/10125 - Loss: 2.2803 - Acc: 16.30% - LR: 1.42e-06
2025-12-15 16:55:11 - models.bert_model - INFO - Epoch 1/10 - Batch 1480/10125 - Loss: 2.2643 - Acc: 16.42% - LR: 1.46e-06
2025-12-15 16:55:26 - models.bert_model - INFO - Epoch 1/10 - Batch 1520/10125 - Loss: 1.5762 - Acc: 16.59% - LR: 1.50e-06
2025-12-15 16:55:40 - models.bert_model - INFO - Epoch 1/10 - Batch 1560/10125 - Loss: 1.9266 - Acc: 16.72% - LR: 1.54e-06
2025-12-15 16:55:55 - models.bert_model - INFO - Epoch 1/10 - Batch 1600/10125 - Loss: 1.7519 - Acc: 16.86% - LR: 1.58e-06
2025-12-15 16:56:10 - models.bert_model - INFO - Epoch 1/10 - Batch 1640/10125 - Loss: 2.1152 - Acc: 16.99% - LR: 1.62e-06
2025-12-15 16:56:24 - models.bert_model - INFO - Epoch 1/10 - Batch 1680/10125 - Loss: 1.8955 - Acc: 17.06% - LR: 1.66e-06
2025-12-15 16:56:39 - models.bert_model - INFO - Epoch 1/10 - Batch 1720/10125 - Loss: 1.8106 - Acc: 17.31% - LR: 1.70e-06
2025-12-15 16:56:53 - models.bert_model - INFO - Epoch 1/10 - Batch 1760/10125 - Loss: 1.9420 - Acc: 17.48% - LR: 1.74e-06
2025-12-15 16:57:08 - models.bert_model - INFO - Epoch 1/10 - Batch 1800/10125 - Loss: 1.8864 - Acc: 17.60% - LR: 1.78e-06
2025-12-15 16:57:22 - models.bert_model - INFO - Epoch 1/10 - Batch 1840/10125 - Loss: 2.1341 - Acc: 17.80% - LR: 1.82e-06
2025-12-15 16:57:37 - models.bert_model - INFO - Epoch 1/10 - Batch 1880/10125 - Loss: 1.9814 - Acc: 18.03% - LR: 1.86e-06
2025-12-15 16:57:51 - models.bert_model - INFO - Epoch 1/10 - Batch 1920/10125 - Loss: 1.8439 - Acc: 18.26% - LR: 1.90e-06
2025-12-15 16:58:06 - models.bert_model - INFO - Epoch 1/10 - Batch 1960/10125 - Loss: 2.0716 - Acc: 18.40% - LR: 1.94e-06
2025-12-15 16:58:21 - models.bert_model - INFO - Epoch 1/10 - Batch 2000/10125 - Loss: 1.3752 - Acc: 18.54% - LR: 1.98e-06
2025-12-15 16:58:35 - models.bert_model - INFO - Epoch 1/10 - Batch 2040/10125 - Loss: 2.2904 - Acc: 18.65% - LR: 2.02e-06
2025-12-15 16:58:50 - models.bert_model - INFO - Epoch 1/10 - Batch 2080/10125 - Loss: 1.8855 - Acc: 18.77% - LR: 2.05e-06
2025-12-15 16:59:04 - models.bert_model - INFO - Epoch 1/10 - Batch 2120/10125 - Loss: 1.9613 - Acc: 18.94% - LR: 2.09e-06
2025-12-15 16:59:19 - models.bert_model - INFO - Epoch 1/10 - Batch 2160/10125 - Loss: 2.0154 - Acc: 19.06% - LR: 2.13e-06
2025-12-15 16:59:33 - models.bert_model - INFO - Epoch 1/10 - Batch 2200/10125 - Loss: 1.9602 - Acc: 19.19% - LR: 2.17e-06
2025-12-15 16:59:48 - models.bert_model - INFO - Epoch 1/10 - Batch 2240/10125 - Loss: 2.0572 - Acc: 19.32% - LR: 2.21e-06
2025-12-15 17:00:02 - models.bert_model - INFO - Epoch 1/10 - Batch 2280/10125 - Loss: 2.0058 - Acc: 19.43% - LR: 2.25e-06
2025-12-15 17:00:17 - models.bert_model - INFO - Epoch 1/10 - Batch 2320/10125 - Loss: 1.8539 - Acc: 19.55% - LR: 2.29e-06
2025-12-15 17:00:31 - models.bert_model - INFO - Epoch 1/10 - Batch 2360/10125 - Loss: 1.7043 - Acc: 19.71% - LR: 2.33e-06
2025-12-15 17:00:46 - models.bert_model - INFO - Epoch 1/10 - Batch 2400/10125 - Loss: 1.7184 - Acc: 19.88% - LR: 2.37e-06
2025-12-15 17:01:00 - models.bert_model - INFO - Epoch 1/10 - Batch 2440/10125 - Loss: 1.9165 - Acc: 19.99% - LR: 2.41e-06
2025-12-15 17:01:15 - models.bert_model - INFO - Epoch 1/10 - Batch 2480/10125 - Loss: 2.0014 - Acc: 20.14% - LR: 2.45e-06
2025-12-15 17:01:29 - models.bert_model - INFO - Epoch 1/10 - Batch 2520/10125 - Loss: 1.9296 - Acc: 20.31% - LR: 2.49e-06
2025-12-15 17:01:44 - models.bert_model - INFO - Epoch 1/10 - Batch 2560/10125 - Loss: 2.0197 - Acc: 20.45% - LR: 2.53e-06
2025-12-15 17:01:58 - models.bert_model - INFO - Epoch 1/10 - Batch 2600/10125 - Loss: 1.5344 - Acc: 20.64% - LR: 2.57e-06
2025-12-15 17:02:13 - models.bert_model - INFO - Epoch 1/10 - Batch 2640/10125 - Loss: 1.1700 - Acc: 20.75% - LR: 2.61e-06
2025-12-15 17:02:27 - models.bert_model - INFO - Epoch 1/10 - Batch 2680/10125 - Loss: 2.1878 - Acc: 20.93% - LR: 2.65e-06
2025-12-15 17:02:42 - models.bert_model - INFO - Epoch 1/10 - Batch 2720/10125 - Loss: 2.0263 - Acc: 21.06% - LR: 2.69e-06
2025-12-15 17:02:56 - models.bert_model - INFO - Epoch 1/10 - Batch 2760/10125 - Loss: 1.8166 - Acc: 21.18% - LR: 2.73e-06
2025-12-15 17:03:11 - models.bert_model - INFO - Epoch 1/10 - Batch 2800/10125 - Loss: 1.7767 - Acc: 21.37% - LR: 2.77e-06
2025-12-15 17:03:25 - models.bert_model - INFO - Epoch 1/10 - Batch 2840/10125 - Loss: 1.7923 - Acc: 21.60% - LR: 2.81e-06
2025-12-15 17:03:40 - models.bert_model - INFO - Epoch 1/10 - Batch 2880/10125 - Loss: 1.5779 - Acc: 21.81% - LR: 2.85e-06
2025-12-15 17:03:54 - models.bert_model - INFO - Epoch 1/10 - Batch 2920/10125 - Loss: 1.7181 - Acc: 21.99% - LR: 2.88e-06
2025-12-15 17:04:09 - models.bert_model - INFO - Epoch 1/10 - Batch 2960/10125 - Loss: 1.9120 - Acc: 22.22% - LR: 2.92e-06
2025-12-15 17:04:23 - models.bert_model - INFO - Epoch 1/10 - Batch 3000/10125 - Loss: 1.3809 - Acc: 22.48% - LR: 2.96e-06
2025-12-15 17:04:38 - models.bert_model - INFO - Epoch 1/10 - Batch 3040/10125 - Loss: 1.3248 - Acc: 22.70% - LR: 3.00e-06
2025-12-15 17:04:52 - models.bert_model - INFO - Epoch 1/10 - Batch 3080/10125 - Loss: 1.6260 - Acc: 22.94% - LR: 3.04e-06
2025-12-15 17:05:07 - models.bert_model - INFO - Epoch 1/10 - Batch 3120/10125 - Loss: 1.3591 - Acc: 23.19% - LR: 3.08e-06
2025-12-15 17:05:22 - models.bert_model - INFO - Epoch 1/10 - Batch 3160/10125 - Loss: 1.5225 - Acc: 23.42% - LR: 3.12e-06
2025-12-15 17:05:36 - models.bert_model - INFO - Epoch 1/10 - Batch 3200/10125 - Loss: 1.4697 - Acc: 23.66% - LR: 3.16e-06
2025-12-15 17:05:51 - models.bert_model - INFO - Epoch 1/10 - Batch 3240/10125 - Loss: 1.6137 - Acc: 23.94% - LR: 3.20e-06
2025-12-15 17:06:05 - models.bert_model - INFO - Epoch 1/10 - Batch 3280/10125 - Loss: 1.2635 - Acc: 24.14% - LR: 3.24e-06
2025-12-15 17:06:20 - models.bert_model - INFO - Epoch 1/10 - Batch 3320/10125 - Loss: 1.3808 - Acc: 24.39% - LR: 3.28e-06
2025-12-15 17:06:34 - models.bert_model - INFO - Epoch 1/10 - Batch 3360/10125 - Loss: 1.7883 - Acc: 24.63% - LR: 3.32e-06
2025-12-15 17:06:49 - models.bert_model - INFO - Epoch 1/10 - Batch 3400/10125 - Loss: 1.2443 - Acc: 24.93% - LR: 3.36e-06
2025-12-15 17:07:03 - models.bert_model - INFO - Epoch 1/10 - Batch 3440/10125 - Loss: 1.4852 - Acc: 25.18% - LR: 3.40e-06
2025-12-15 17:07:18 - models.bert_model - INFO - Epoch 1/10 - Batch 3480/10125 - Loss: 1.2545 - Acc: 25.47% - LR: 3.44e-06
2025-12-15 17:07:32 - models.bert_model - INFO - Epoch 1/10 - Batch 3520/10125 - Loss: 1.3484 - Acc: 25.74% - LR: 3.48e-06
2025-12-15 17:07:47 - models.bert_model - INFO - Epoch 1/10 - Batch 3560/10125 - Loss: 1.2578 - Acc: 26.02% - LR: 3.52e-06
2025-12-15 17:08:01 - models.bert_model - INFO - Epoch 1/10 - Batch 3600/10125 - Loss: 1.3256 - Acc: 26.34% - LR: 3.56e-06
2025-12-15 17:08:16 - models.bert_model - INFO - Epoch 1/10 - Batch 3640/10125 - Loss: 1.1425 - Acc: 26.64% - LR: 3.60e-06
2025-12-15 17:08:30 - models.bert_model - INFO - Epoch 1/10 - Batch 3680/10125 - Loss: 1.5332 - Acc: 26.93% - LR: 3.64e-06
2025-12-15 17:08:45 - models.bert_model - INFO - Epoch 1/10 - Batch 3720/10125 - Loss: 1.1570 - Acc: 27.20% - LR: 3.67e-06
2025-12-15 17:08:59 - models.bert_model - INFO - Epoch 1/10 - Batch 3760/10125 - Loss: 1.0425 - Acc: 27.48% - LR: 3.71e-06
2025-12-15 17:09:14 - models.bert_model - INFO - Epoch 1/10 - Batch 3800/10125 - Loss: 1.1162 - Acc: 27.75% - LR: 3.75e-06
2025-12-15 17:09:28 - models.bert_model - INFO - Epoch 1/10 - Batch 3840/10125 - Loss: 1.3344 - Acc: 28.03% - LR: 3.79e-06
2025-12-15 17:09:43 - models.bert_model - INFO - Epoch 1/10 - Batch 3880/10125 - Loss: 1.0978 - Acc: 28.31% - LR: 3.83e-06
2025-12-15 17:09:57 - models.bert_model - INFO - Epoch 1/10 - Batch 3920/10125 - Loss: 1.4265 - Acc: 28.62% - LR: 3.87e-06
2025-12-15 17:10:12 - models.bert_model - INFO - Epoch 1/10 - Batch 3960/10125 - Loss: 1.5310 - Acc: 28.93% - LR: 3.91e-06
2025-12-15 17:10:26 - models.bert_model - INFO - Epoch 1/10 - Batch 4000/10125 - Loss: 1.2540 - Acc: 29.21% - LR: 3.95e-06
2025-12-15 17:10:41 - models.bert_model - INFO - Epoch 1/10 - Batch 4040/10125 - Loss: 1.0417 - Acc: 29.48% - LR: 3.99e-06
2025-12-15 17:10:56 - models.bert_model - INFO - Epoch 1/10 - Batch 4080/10125 - Loss: 0.8271 - Acc: 29.74% - LR: 4.03e-06
2025-12-15 17:11:10 - models.bert_model - INFO - Epoch 1/10 - Batch 4120/10125 - Loss: 0.9134 - Acc: 30.01% - LR: 4.07e-06
2025-12-15 17:11:24 - models.bert_model - INFO - Epoch 1/10 - Batch 4160/10125 - Loss: 1.2377 - Acc: 30.30% - LR: 4.11e-06
2025-12-15 17:11:39 - models.bert_model - INFO - Epoch 1/10 - Batch 4200/10125 - Loss: 1.0552 - Acc: 30.58% - LR: 4.15e-06
2025-12-15 17:11:53 - models.bert_model - INFO - Epoch 1/10 - Batch 4240/10125 - Loss: 0.7108 - Acc: 30.89% - LR: 4.19e-06
2025-12-15 17:12:08 - models.bert_model - INFO - Epoch 1/10 - Batch 4280/10125 - Loss: 0.6499 - Acc: 31.14% - LR: 4.23e-06
2025-12-15 17:12:22 - models.bert_model - INFO - Epoch 1/10 - Batch 4320/10125 - Loss: 0.7600 - Acc: 31.42% - LR: 4.27e-06
2025-12-15 17:12:37 - models.bert_model - INFO - Epoch 1/10 - Batch 4360/10125 - Loss: 1.3100 - Acc: 31.68% - LR: 4.31e-06
2025-12-15 17:12:51 - models.bert_model - INFO - Epoch 1/10 - Batch 4400/10125 - Loss: 1.2239 - Acc: 31.96% - LR: 4.35e-06
2025-12-15 17:13:06 - models.bert_model - INFO - Epoch 1/10 - Batch 4440/10125 - Loss: 1.0024 - Acc: 32.23% - LR: 4.39e-06
2025-12-15 17:13:20 - models.bert_model - INFO - Epoch 1/10 - Batch 4480/10125 - Loss: 0.7773 - Acc: 32.52% - LR: 4.43e-06
2025-12-15 17:13:35 - models.bert_model - INFO - Epoch 1/10 - Batch 4520/10125 - Loss: 1.1445 - Acc: 32.81% - LR: 4.47e-06
2025-12-15 17:13:50 - models.bert_model - INFO - Epoch 1/10 - Batch 4560/10125 - Loss: 1.0547 - Acc: 33.09% - LR: 4.50e-06
2025-12-15 17:14:04 - models.bert_model - INFO - Epoch 1/10 - Batch 4600/10125 - Loss: 1.3723 - Acc: 33.35% - LR: 4.54e-06
2025-12-15 17:14:19 - models.bert_model - INFO - Epoch 1/10 - Batch 4640/10125 - Loss: 0.9383 - Acc: 33.63% - LR: 4.58e-06
2025-12-15 17:14:33 - models.bert_model - INFO - Epoch 1/10 - Batch 4680/10125 - Loss: 1.1277 - Acc: 33.91% - LR: 4.62e-06
2025-12-15 17:14:48 - models.bert_model - INFO - Epoch 1/10 - Batch 4720/10125 - Loss: 0.7445 - Acc: 34.20% - LR: 4.66e-06
2025-12-15 17:15:02 - models.bert_model - INFO - Epoch 1/10 - Batch 4760/10125 - Loss: 0.9990 - Acc: 34.45% - LR: 4.70e-06
2025-12-15 17:15:17 - models.bert_model - INFO - Epoch 1/10 - Batch 4800/10125 - Loss: 1.2180 - Acc: 34.71% - LR: 4.74e-06
2025-12-15 17:15:31 - models.bert_model - INFO - Epoch 1/10 - Batch 4840/10125 - Loss: 0.9266 - Acc: 34.98% - LR: 4.78e-06
2025-12-15 17:15:46 - models.bert_model - INFO - Epoch 1/10 - Batch 4880/10125 - Loss: 0.6981 - Acc: 35.22% - LR: 4.82e-06
2025-12-15 17:16:00 - models.bert_model - INFO - Epoch 1/10 - Batch 4920/10125 - Loss: 0.6612 - Acc: 35.47% - LR: 4.86e-06
2025-12-15 17:16:15 - models.bert_model - INFO - Epoch 1/10 - Batch 4960/10125 - Loss: 1.2066 - Acc: 35.71% - LR: 4.90e-06
2025-12-15 17:16:29 - models.bert_model - INFO - Epoch 1/10 - Batch 5000/10125 - Loss: 1.0282 - Acc: 35.98% - LR: 4.94e-06
2025-12-15 17:16:44 - models.bert_model - INFO - Epoch 1/10 - Batch 5040/10125 - Loss: 0.9205 - Acc: 36.23% - LR: 4.98e-06
2025-12-15 17:16:58 - models.bert_model - INFO - Epoch 1/10 - Batch 5080/10125 - Loss: 0.4447 - Acc: 36.49% - LR: 5.02e-06
2025-12-15 17:17:13 - models.bert_model - INFO - Epoch 1/10 - Batch 5120/10125 - Loss: 0.8117 - Acc: 36.74% - LR: 5.06e-06
2025-12-15 17:17:28 - models.bert_model - INFO - Epoch 1/10 - Batch 5160/10125 - Loss: 0.7287 - Acc: 36.99% - LR: 5.10e-06
2025-12-15 17:17:42 - models.bert_model - INFO - Epoch 1/10 - Batch 5200/10125 - Loss: 1.2799 - Acc: 37.22% - LR: 5.14e-06
2025-12-15 17:17:56 - models.bert_model - INFO - Epoch 1/10 - Batch 5240/10125 - Loss: 0.6579 - Acc: 37.48% - LR: 5.18e-06
2025-12-15 17:18:11 - models.bert_model - INFO - Epoch 1/10 - Batch 5280/10125 - Loss: 1.0010 - Acc: 37.71% - LR: 5.22e-06
2025-12-15 17:18:25 - models.bert_model - INFO - Epoch 1/10 - Batch 5320/10125 - Loss: 0.9519 - Acc: 37.94% - LR: 5.26e-06
2025-12-15 17:18:40 - models.bert_model - INFO - Epoch 1/10 - Batch 5360/10125 - Loss: 0.6499 - Acc: 38.17% - LR: 5.30e-06
2025-12-15 17:18:54 - models.bert_model - INFO - Epoch 1/10 - Batch 5400/10125 - Loss: 0.7650 - Acc: 38.44% - LR: 5.33e-06
2025-12-15 17:19:09 - models.bert_model - INFO - Epoch 1/10 - Batch 5440/10125 - Loss: 0.8364 - Acc: 38.65% - LR: 5.37e-06
2025-12-15 17:19:23 - models.bert_model - INFO - Epoch 1/10 - Batch 5480/10125 - Loss: 0.6705 - Acc: 38.85% - LR: 5.41e-06
2025-12-15 17:19:38 - models.bert_model - INFO - Epoch 1/10 - Batch 5520/10125 - Loss: 0.6470 - Acc: 39.09% - LR: 5.45e-06
2025-12-15 17:19:52 - models.bert_model - INFO - Epoch 1/10 - Batch 5560/10125 - Loss: 0.8970 - Acc: 39.33% - LR: 5.49e-06
2025-12-15 17:20:07 - models.bert_model - INFO - Epoch 1/10 - Batch 5600/10125 - Loss: 0.8413 - Acc: 39.54% - LR: 5.53e-06
2025-12-15 17:20:22 - models.bert_model - INFO - Epoch 1/10 - Batch 5640/10125 - Loss: 0.5269 - Acc: 39.78% - LR: 5.57e-06
2025-12-15 17:20:36 - models.bert_model - INFO - Epoch 1/10 - Batch 5680/10125 - Loss: 0.9843 - Acc: 39.99% - LR: 5.61e-06
2025-12-15 17:20:51 - models.bert_model - INFO - Epoch 1/10 - Batch 5720/10125 - Loss: 0.5570 - Acc: 40.22% - LR: 5.65e-06
2025-12-15 17:21:05 - models.bert_model - INFO - Epoch 1/10 - Batch 5760/10125 - Loss: 1.1641 - Acc: 40.44% - LR: 5.69e-06
2025-12-15 17:21:20 - models.bert_model - INFO - Epoch 1/10 - Batch 5800/10125 - Loss: 0.9780 - Acc: 40.66% - LR: 5.73e-06
2025-12-15 17:21:34 - models.bert_model - INFO - Epoch 1/10 - Batch 5840/10125 - Loss: 0.8234 - Acc: 40.89% - LR: 5.77e-06
2025-12-15 17:21:49 - models.bert_model - INFO - Epoch 1/10 - Batch 5880/10125 - Loss: 0.4943 - Acc: 41.10% - LR: 5.81e-06
2025-12-15 17:22:03 - models.bert_model - INFO - Epoch 1/10 - Batch 5920/10125 - Loss: 1.1985 - Acc: 41.30% - LR: 5.85e-06
2025-12-15 17:22:18 - models.bert_model - INFO - Epoch 1/10 - Batch 5960/10125 - Loss: 0.5905 - Acc: 41.50% - LR: 5.89e-06
2025-12-15 17:22:32 - models.bert_model - INFO - Epoch 1/10 - Batch 6000/10125 - Loss: 0.8093 - Acc: 41.74% - LR: 5.93e-06
2025-12-15 17:22:47 - models.bert_model - INFO - Epoch 1/10 - Batch 6040/10125 - Loss: 1.1686 - Acc: 41.96% - LR: 5.97e-06
2025-12-15 17:23:01 - models.bert_model - INFO - Epoch 1/10 - Batch 6080/10125 - Loss: 0.7402 - Acc: 42.19% - LR: 6.01e-06
2025-12-15 17:23:16 - models.bert_model - INFO - Epoch 1/10 - Batch 6120/10125 - Loss: 0.8765 - Acc: 42.39% - LR: 6.05e-06
2025-12-15 17:23:30 - models.bert_model - INFO - Epoch 1/10 - Batch 6160/10125 - Loss: 0.6645 - Acc: 42.59% - LR: 6.09e-06
2025-12-15 17:23:45 - models.bert_model - INFO - Epoch 1/10 - Batch 6200/10125 - Loss: 0.6331 - Acc: 42.79% - LR: 6.12e-06
2025-12-15 17:23:59 - models.bert_model - INFO - Epoch 1/10 - Batch 6240/10125 - Loss: 0.6040 - Acc: 43.00% - LR: 6.16e-06
2025-12-15 17:24:14 - models.bert_model - INFO - Epoch 1/10 - Batch 6280/10125 - Loss: 0.4352 - Acc: 43.21% - LR: 6.20e-06
2025-12-15 17:24:28 - models.bert_model - INFO - Epoch 1/10 - Batch 6320/10125 - Loss: 0.3709 - Acc: 43.41% - LR: 6.24e-06
2025-12-15 17:24:43 - models.bert_model - INFO - Epoch 1/10 - Batch 6360/10125 - Loss: 0.3838 - Acc: 43.61% - LR: 6.28e-06
2025-12-15 17:24:57 - models.bert_model - INFO - Epoch 1/10 - Batch 6400/10125 - Loss: 0.5258 - Acc: 43.81% - LR: 6.32e-06
2025-12-15 17:25:12 - models.bert_model - INFO - Epoch 1/10 - Batch 6440/10125 - Loss: 0.6938 - Acc: 43.99% - LR: 6.36e-06
2025-12-15 17:25:26 - models.bert_model - INFO - Epoch 1/10 - Batch 6480/10125 - Loss: 0.3353 - Acc: 44.18% - LR: 6.40e-06
2025-12-15 17:25:41 - models.bert_model - INFO - Epoch 1/10 - Batch 6520/10125 - Loss: 0.6044 - Acc: 44.38% - LR: 6.44e-06
2025-12-15 17:25:55 - models.bert_model - INFO - Epoch 1/10 - Batch 6560/10125 - Loss: 0.7754 - Acc: 44.58% - LR: 6.48e-06
2025-12-15 17:26:10 - models.bert_model - INFO - Epoch 1/10 - Batch 6600/10125 - Loss: 0.6978 - Acc: 44.76% - LR: 6.52e-06
2025-12-15 17:26:24 - models.bert_model - INFO - Epoch 1/10 - Batch 6640/10125 - Loss: 0.7091 - Acc: 44.97% - LR: 6.56e-06
2025-12-15 17:26:39 - models.bert_model - INFO - Epoch 1/10 - Batch 6680/10125 - Loss: 0.7527 - Acc: 45.17% - LR: 6.60e-06
2025-12-15 17:26:53 - models.bert_model - INFO - Epoch 1/10 - Batch 6720/10125 - Loss: 0.8293 - Acc: 45.37% - LR: 6.64e-06
2025-12-15 17:27:08 - models.bert_model - INFO - Epoch 1/10 - Batch 6760/10125 - Loss: 0.8554 - Acc: 45.54% - LR: 6.68e-06
2025-12-15 17:27:22 - models.bert_model - INFO - Epoch 1/10 - Batch 6800/10125 - Loss: 0.6256 - Acc: 45.73% - LR: 6.72e-06
2025-12-15 17:27:37 - models.bert_model - INFO - Epoch 1/10 - Batch 6840/10125 - Loss: 0.5460 - Acc: 45.92% - LR: 6.76e-06
2025-12-15 17:27:51 - models.bert_model - INFO - Epoch 1/10 - Batch 6880/10125 - Loss: 0.7967 - Acc: 46.10% - LR: 6.80e-06
2025-12-15 17:28:06 - models.bert_model - INFO - Epoch 1/10 - Batch 6920/10125 - Loss: 0.7695 - Acc: 46.30% - LR: 6.84e-06
2025-12-15 17:28:20 - models.bert_model - INFO - Epoch 1/10 - Batch 6960/10125 - Loss: 0.5055 - Acc: 46.47% - LR: 6.88e-06
2025-12-15 17:28:35 - models.bert_model - INFO - Epoch 1/10 - Batch 7000/10125 - Loss: 0.5957 - Acc: 46.66% - LR: 6.92e-06
2025-12-15 17:28:49 - models.bert_model - INFO - Epoch 1/10 - Batch 7040/10125 - Loss: 1.0079 - Acc: 46.82% - LR: 6.95e-06
2025-12-15 17:29:04 - models.bert_model - INFO - Epoch 1/10 - Batch 7080/10125 - Loss: 0.5483 - Acc: 47.01% - LR: 6.99e-06
2025-12-15 17:29:18 - models.bert_model - INFO - Epoch 1/10 - Batch 7120/10125 - Loss: 0.4190 - Acc: 47.18% - LR: 7.03e-06
2025-12-15 17:29:33 - models.bert_model - INFO - Epoch 1/10 - Batch 7160/10125 - Loss: 0.6094 - Acc: 47.37% - LR: 7.07e-06
2025-12-15 17:29:47 - models.bert_model - INFO - Epoch 1/10 - Batch 7200/10125 - Loss: 0.8363 - Acc: 47.55% - LR: 7.11e-06
2025-12-15 17:30:02 - models.bert_model - INFO - Epoch 1/10 - Batch 7240/10125 - Loss: 0.8405 - Acc: 47.71% - LR: 7.15e-06
2025-12-15 17:30:17 - models.bert_model - INFO - Epoch 1/10 - Batch 7280/10125 - Loss: 0.8113 - Acc: 47.88% - LR: 7.19e-06
2025-12-15 17:30:31 - models.bert_model - INFO - Epoch 1/10 - Batch 7320/10125 - Loss: 0.8080 - Acc: 48.05% - LR: 7.23e-06
2025-12-15 17:30:46 - models.bert_model - INFO - Epoch 1/10 - Batch 7360/10125 - Loss: 0.9501 - Acc: 48.23% - LR: 7.27e-06
2025-12-15 17:31:00 - models.bert_model - INFO - Epoch 1/10 - Batch 7400/10125 - Loss: 0.7543 - Acc: 48.40% - LR: 7.31e-06
2025-12-15 17:31:15 - models.bert_model - INFO - Epoch 1/10 - Batch 7440/10125 - Loss: 0.6667 - Acc: 48.58% - LR: 7.35e-06
2025-12-15 17:31:29 - models.bert_model - INFO - Epoch 1/10 - Batch 7480/10125 - Loss: 0.7131 - Acc: 48.75% - LR: 7.39e-06
2025-12-15 17:31:44 - models.bert_model - INFO - Epoch 1/10 - Batch 7520/10125 - Loss: 0.2613 - Acc: 48.94% - LR: 7.43e-06
2025-12-15 17:31:58 - models.bert_model - INFO - Epoch 1/10 - Batch 7560/10125 - Loss: 0.6942 - Acc: 49.12% - LR: 7.47e-06
2025-12-15 17:32:13 - models.bert_model - INFO - Epoch 1/10 - Batch 7600/10125 - Loss: 0.6830 - Acc: 49.27% - LR: 7.51e-06
2025-12-15 17:32:27 - models.bert_model - INFO - Epoch 1/10 - Batch 7640/10125 - Loss: 0.4664 - Acc: 49.44% - LR: 7.55e-06
2025-12-15 17:32:42 - models.bert_model - INFO - Epoch 1/10 - Batch 7680/10125 - Loss: 0.6019 - Acc: 49.61% - LR: 7.59e-06
2025-12-15 17:32:56 - models.bert_model - INFO - Epoch 1/10 - Batch 7720/10125 - Loss: 0.2429 - Acc: 49.76% - LR: 7.63e-06
2025-12-15 17:33:11 - models.bert_model - INFO - Epoch 1/10 - Batch 7760/10125 - Loss: 0.5130 - Acc: 49.93% - LR: 7.67e-06
2025-12-15 17:33:25 - models.bert_model - INFO - Epoch 1/10 - Batch 7800/10125 - Loss: 0.6368 - Acc: 50.08% - LR: 7.71e-06
2025-12-15 17:33:40 - models.bert_model - INFO - Epoch 1/10 - Batch 7840/10125 - Loss: 0.4129 - Acc: 50.25% - LR: 7.74e-06
2025-12-15 17:33:54 - models.bert_model - INFO - Epoch 1/10 - Batch 7880/10125 - Loss: 0.7475 - Acc: 50.41% - LR: 7.78e-06
2025-12-15 17:34:09 - models.bert_model - INFO - Epoch 1/10 - Batch 7920/10125 - Loss: 0.7804 - Acc: 50.57% - LR: 7.82e-06
2025-12-15 17:34:23 - models.bert_model - INFO - Epoch 1/10 - Batch 7960/10125 - Loss: 0.4691 - Acc: 50.73% - LR: 7.86e-06
2025-12-15 17:34:38 - models.bert_model - INFO - Epoch 1/10 - Batch 8000/10125 - Loss: 0.6453 - Acc: 50.88% - LR: 7.90e-06
2025-12-15 17:34:52 - models.bert_model - INFO - Epoch 1/10 - Batch 8040/10125 - Loss: 0.7327 - Acc: 51.04% - LR: 7.94e-06
2025-12-15 17:35:07 - models.bert_model - INFO - Epoch 1/10 - Batch 8080/10125 - Loss: 0.8250 - Acc: 51.18% - LR: 7.98e-06
2025-12-15 17:35:21 - models.bert_model - INFO - Epoch 1/10 - Batch 8120/10125 - Loss: 0.4478 - Acc: 51.32% - LR: 8.02e-06
2025-12-15 17:35:36 - models.bert_model - INFO - Epoch 1/10 - Batch 8160/10125 - Loss: 0.3305 - Acc: 51.47% - LR: 8.06e-06
2025-12-15 17:35:50 - models.bert_model - INFO - Epoch 1/10 - Batch 8200/10125 - Loss: 0.6022 - Acc: 51.60% - LR: 8.10e-06
2025-12-15 17:36:05 - models.bert_model - INFO - Epoch 1/10 - Batch 8240/10125 - Loss: 0.6476 - Acc: 51.74% - LR: 8.14e-06
2025-12-15 17:36:19 - models.bert_model - INFO - Epoch 1/10 - Batch 8280/10125 - Loss: 0.4386 - Acc: 51.89% - LR: 8.18e-06
2025-12-15 17:36:34 - models.bert_model - INFO - Epoch 1/10 - Batch 8320/10125 - Loss: 0.5154 - Acc: 52.04% - LR: 8.22e-06
2025-12-15 17:36:48 - models.bert_model - INFO - Epoch 1/10 - Batch 8360/10125 - Loss: 0.7962 - Acc: 52.18% - LR: 8.26e-06
2025-12-15 17:37:03 - models.bert_model - INFO - Epoch 1/10 - Batch 8400/10125 - Loss: 0.1795 - Acc: 52.33% - LR: 8.30e-06
2025-12-15 17:37:17 - models.bert_model - INFO - Epoch 1/10 - Batch 8440/10125 - Loss: 0.4549 - Acc: 52.48% - LR: 8.34e-06
2025-12-15 17:37:32 - models.bert_model - INFO - Epoch 1/10 - Batch 8480/10125 - Loss: 1.0366 - Acc: 52.62% - LR: 8.38e-06
2025-12-15 17:37:46 - models.bert_model - INFO - Epoch 1/10 - Batch 8520/10125 - Loss: 0.8840 - Acc: 52.76% - LR: 8.42e-06
2025-12-15 17:38:01 - models.bert_model - INFO - Epoch 1/10 - Batch 8560/10125 - Loss: 0.5548 - Acc: 52.90% - LR: 8.46e-06
2025-12-15 17:38:15 - models.bert_model - INFO - Epoch 1/10 - Batch 8600/10125 - Loss: 0.3352 - Acc: 53.05% - LR: 8.50e-06
2025-12-15 17:38:30 - models.bert_model - INFO - Epoch 1/10 - Batch 8640/10125 - Loss: 0.5873 - Acc: 53.20% - LR: 8.54e-06
2025-12-15 17:38:44 - models.bert_model - INFO - Epoch 1/10 - Batch 8680/10125 - Loss: 0.5278 - Acc: 53.34% - LR: 8.57e-06
2025-12-15 17:38:59 - models.bert_model - INFO - Epoch 1/10 - Batch 8720/10125 - Loss: 0.3820 - Acc: 53.47% - LR: 8.61e-06
2025-12-15 17:39:13 - models.bert_model - INFO - Epoch 1/10 - Batch 8760/10125 - Loss: 0.2848 - Acc: 53.60% - LR: 8.65e-06
2025-12-15 17:39:28 - models.bert_model - INFO - Epoch 1/10 - Batch 8800/10125 - Loss: 0.9875 - Acc: 53.73% - LR: 8.69e-06
2025-12-15 17:39:42 - models.bert_model - INFO - Epoch 1/10 - Batch 8840/10125 - Loss: 0.4513 - Acc: 53.86% - LR: 8.73e-06
2025-12-15 17:39:57 - models.bert_model - INFO - Epoch 1/10 - Batch 8880/10125 - Loss: 0.3497 - Acc: 53.99% - LR: 8.77e-06
2025-12-15 17:40:12 - models.bert_model - INFO - Epoch 1/10 - Batch 8920/10125 - Loss: 0.7370 - Acc: 54.12% - LR: 8.81e-06
2025-12-15 17:40:26 - models.bert_model - INFO - Epoch 1/10 - Batch 8960/10125 - Loss: 0.6862 - Acc: 54.25% - LR: 8.85e-06
2025-12-15 17:40:41 - models.bert_model - INFO - Epoch 1/10 - Batch 9000/10125 - Loss: 0.3506 - Acc: 54.38% - LR: 8.89e-06
2025-12-15 17:40:55 - models.bert_model - INFO - Epoch 1/10 - Batch 9040/10125 - Loss: 0.3306 - Acc: 54.51% - LR: 8.93e-06
2025-12-15 17:41:10 - models.bert_model - INFO - Epoch 1/10 - Batch 9080/10125 - Loss: 0.6845 - Acc: 54.64% - LR: 8.97e-06
2025-12-15 17:41:24 - models.bert_model - INFO - Epoch 1/10 - Batch 9120/10125 - Loss: 0.4052 - Acc: 54.76% - LR: 9.01e-06
2025-12-15 17:41:39 - models.bert_model - INFO - Epoch 1/10 - Batch 9160/10125 - Loss: 0.3877 - Acc: 54.89% - LR: 9.05e-06
2025-12-15 17:41:53 - models.bert_model - INFO - Epoch 1/10 - Batch 9200/10125 - Loss: 0.6241 - Acc: 55.01% - LR: 9.09e-06
2025-12-15 17:42:08 - models.bert_model - INFO - Epoch 1/10 - Batch 9240/10125 - Loss: 0.7106 - Acc: 55.14% - LR: 9.13e-06
2025-12-15 17:42:22 - models.bert_model - INFO - Epoch 1/10 - Batch 9280/10125 - Loss: 0.2936 - Acc: 55.26% - LR: 9.17e-06
2025-12-15 17:42:37 - models.bert_model - INFO - Epoch 1/10 - Batch 9320/10125 - Loss: 0.4499 - Acc: 55.39% - LR: 9.21e-06
2025-12-15 17:42:51 - models.bert_model - INFO - Epoch 1/10 - Batch 9360/10125 - Loss: 0.2015 - Acc: 55.52% - LR: 9.25e-06
2025-12-15 17:43:06 - models.bert_model - INFO - Epoch 1/10 - Batch 9400/10125 - Loss: 0.2888 - Acc: 55.66% - LR: 9.29e-06
2025-12-15 17:43:20 - models.bert_model - INFO - Epoch 1/10 - Batch 9440/10125 - Loss: 0.4049 - Acc: 55.79% - LR: 9.33e-06
2025-12-15 17:43:35 - models.bert_model - INFO - Epoch 1/10 - Batch 9480/10125 - Loss: 0.5827 - Acc: 55.91% - LR: 9.37e-06
2025-12-15 17:43:49 - models.bert_model - INFO - Epoch 1/10 - Batch 9520/10125 - Loss: 0.2212 - Acc: 56.02% - LR: 9.40e-06
2025-12-15 17:44:04 - models.bert_model - INFO - Epoch 1/10 - Batch 9560/10125 - Loss: 0.6865 - Acc: 56.15% - LR: 9.44e-06
2025-12-15 17:44:18 - models.bert_model - INFO - Epoch 1/10 - Batch 9600/10125 - Loss: 0.3441 - Acc: 56.28% - LR: 9.48e-06
2025-12-15 17:44:33 - models.bert_model - INFO - Epoch 1/10 - Batch 9640/10125 - Loss: 0.3243 - Acc: 56.40% - LR: 9.52e-06
2025-12-15 17:44:47 - models.bert_model - INFO - Epoch 1/10 - Batch 9680/10125 - Loss: 0.5445 - Acc: 56.52% - LR: 9.56e-06
2025-12-15 17:45:02 - models.bert_model - INFO - Epoch 1/10 - Batch 9720/10125 - Loss: 0.7980 - Acc: 56.64% - LR: 9.60e-06
2025-12-15 17:45:16 - models.bert_model - INFO - Epoch 1/10 - Batch 9760/10125 - Loss: 0.1678 - Acc: 56.76% - LR: 9.64e-06
2025-12-15 17:45:31 - models.bert_model - INFO - Epoch 1/10 - Batch 9800/10125 - Loss: 0.2069 - Acc: 56.88% - LR: 9.68e-06
2025-12-15 17:45:46 - models.bert_model - INFO - Epoch 1/10 - Batch 9840/10125 - Loss: 0.3045 - Acc: 57.00% - LR: 9.72e-06
2025-12-15 17:46:00 - models.bert_model - INFO - Epoch 1/10 - Batch 9880/10125 - Loss: 0.2561 - Acc: 57.11% - LR: 9.76e-06
2025-12-15 17:46:15 - models.bert_model - INFO - Epoch 1/10 - Batch 9920/10125 - Loss: 0.6602 - Acc: 57.22% - LR: 9.80e-06
2025-12-15 17:46:29 - models.bert_model - INFO - Epoch 1/10 - Batch 9960/10125 - Loss: 0.5508 - Acc: 57.33% - LR: 9.84e-06
2025-12-15 17:46:43 - models.bert_model - INFO - Epoch 1/10 - Batch 10000/10125 - Loss: 0.3627 - Acc: 57.44% - LR: 9.88e-06
2025-12-15 17:46:58 - models.bert_model - INFO - Epoch 1/10 - Batch 10040/10125 - Loss: 0.3253 - Acc: 57.54% - LR: 9.92e-06
2025-12-15 17:47:12 - models.bert_model - INFO - Epoch 1/10 - Batch 10080/10125 - Loss: 0.3537 - Acc: 57.67% - LR: 9.96e-06
2025-12-15 17:47:27 - models.bert_model - INFO - Epoch 1/10 - Batch 10120/10125 - Loss: 0.8045 - Acc: 57.78% - LR: 1.00e-05
2025-12-15 17:49:45 - models.bert_model - INFO - Epoch 1/10 - Train Loss: 1.1169, Train Acc: 57.79% - Val Loss: 0.4143, Val Acc: 86.92%
2025-12-15 17:49:45 - models.bert_model - INFO - New best validation accuracy: 86.92%
2025-12-15 17:49:59 - models.bert_model - INFO - Epoch 2/10 - Batch 40/10125 - Loss: 0.6008 - Acc: 87.03% - LR: 1.00e-05
2025-12-15 17:50:14 - models.bert_model - INFO - Epoch 2/10 - Batch 80/10125 - Loss: 0.2258 - Acc: 86.33% - LR: 1.01e-05
2025-12-15 17:50:28 - models.bert_model - INFO - Epoch 2/10 - Batch 120/10125 - Loss: 0.3341 - Acc: 86.46% - LR: 1.01e-05
2025-12-15 17:50:43 - models.bert_model - INFO - Epoch 2/10 - Batch 160/10125 - Loss: 0.3939 - Acc: 85.82% - LR: 1.02e-05
2025-12-15 17:50:57 - models.bert_model - INFO - Epoch 2/10 - Batch 200/10125 - Loss: 0.2793 - Acc: 86.03% - LR: 1.02e-05
2025-12-15 17:51:12 - models.bert_model - INFO - Epoch 2/10 - Batch 240/10125 - Loss: 0.2127 - Acc: 86.20% - LR: 1.02e-05
2025-12-15 17:51:26 - models.bert_model - INFO - Epoch 2/10 - Batch 280/10125 - Loss: 0.2460 - Acc: 85.74% - LR: 1.03e-05
2025-12-15 17:51:41 - models.bert_model - INFO - Epoch 2/10 - Batch 320/10125 - Loss: 0.2486 - Acc: 85.98% - LR: 1.03e-05
2025-12-15 17:51:55 - models.bert_model - INFO - Epoch 2/10 - Batch 360/10125 - Loss: 0.3177 - Acc: 85.89% - LR: 1.04e-05
2025-12-15 17:52:10 - models.bert_model - INFO - Epoch 2/10 - Batch 400/10125 - Loss: 0.2545 - Acc: 85.80% - LR: 1.04e-05
2025-12-15 17:52:25 - models.bert_model - INFO - Epoch 2/10 - Batch 440/10125 - Loss: 0.4678 - Acc: 85.95% - LR: 1.04e-05
2025-12-15 17:52:39 - models.bert_model - INFO - Epoch 2/10 - Batch 480/10125 - Loss: 0.4983 - Acc: 86.11% - LR: 1.05e-05
2025-12-15 17:52:53 - models.bert_model - INFO - Epoch 2/10 - Batch 520/10125 - Loss: 0.4768 - Acc: 86.20% - LR: 1.05e-05
2025-12-15 17:53:08 - models.bert_model - INFO - Epoch 2/10 - Batch 560/10125 - Loss: 0.7420 - Acc: 86.06% - LR: 1.06e-05
2025-12-15 17:53:23 - models.bert_model - INFO - Epoch 2/10 - Batch 600/10125 - Loss: 0.2307 - Acc: 86.05% - LR: 1.06e-05
2025-12-15 17:53:37 - models.bert_model - INFO - Epoch 2/10 - Batch 640/10125 - Loss: 0.4700 - Acc: 86.15% - LR: 1.06e-05
2025-12-15 17:53:52 - models.bert_model - INFO - Epoch 2/10 - Batch 680/10125 - Loss: 0.4375 - Acc: 86.16% - LR: 1.07e-05
2025-12-15 17:54:06 - models.bert_model - INFO - Epoch 2/10 - Batch 720/10125 - Loss: 0.4927 - Acc: 86.28% - LR: 1.07e-05
2025-12-15 17:54:20 - models.bert_model - INFO - Epoch 2/10 - Batch 760/10125 - Loss: 0.3668 - Acc: 86.38% - LR: 1.08e-05
2025-12-15 17:54:35 - models.bert_model - INFO - Epoch 2/10 - Batch 800/10125 - Loss: 0.2709 - Acc: 86.48% - LR: 1.08e-05
2025-12-15 17:54:49 - models.bert_model - INFO - Epoch 2/10 - Batch 840/10125 - Loss: 0.3418 - Acc: 86.57% - LR: 1.08e-05
2025-12-15 17:55:04 - models.bert_model - INFO - Epoch 2/10 - Batch 880/10125 - Loss: 0.2582 - Acc: 86.55% - LR: 1.09e-05
2025-12-15 17:55:19 - models.bert_model - INFO - Epoch 2/10 - Batch 920/10125 - Loss: 0.3574 - Acc: 86.59% - LR: 1.09e-05
2025-12-15 17:55:33 - models.bert_model - INFO - Epoch 2/10 - Batch 960/10125 - Loss: 0.4243 - Acc: 86.63% - LR: 1.09e-05
2025-12-15 17:55:48 - models.bert_model - INFO - Epoch 2/10 - Batch 1000/10125 - Loss: 0.5032 - Acc: 86.64% - LR: 1.10e-05
2025-12-15 17:56:02 - models.bert_model - INFO - Epoch 2/10 - Batch 1040/10125 - Loss: 0.3810 - Acc: 86.71% - LR: 1.10e-05
2025-12-15 17:56:17 - models.bert_model - INFO - Epoch 2/10 - Batch 1080/10125 - Loss: 0.4455 - Acc: 86.75% - LR: 1.11e-05
2025-12-15 17:56:31 - models.bert_model - INFO - Epoch 2/10 - Batch 1120/10125 - Loss: 0.3416 - Acc: 86.71% - LR: 1.11e-05
2025-12-15 17:56:46 - models.bert_model - INFO - Epoch 2/10 - Batch 1160/10125 - Loss: 0.5898 - Acc: 86.70% - LR: 1.11e-05
2025-12-15 17:57:00 - models.bert_model - INFO - Epoch 2/10 - Batch 1200/10125 - Loss: 0.5766 - Acc: 86.72% - LR: 1.12e-05
2025-12-15 17:57:15 - models.bert_model - INFO - Epoch 2/10 - Batch 1240/10125 - Loss: 0.4322 - Acc: 86.68% - LR: 1.12e-05
2025-12-15 17:57:29 - models.bert_model - INFO - Epoch 2/10 - Batch 1280/10125 - Loss: 0.5342 - Acc: 86.64% - LR: 1.13e-05
2025-12-15 17:57:44 - models.bert_model - INFO - Epoch 2/10 - Batch 1320/10125 - Loss: 0.5394 - Acc: 86.65% - LR: 1.13e-05
2025-12-15 17:57:58 - models.bert_model - INFO - Epoch 2/10 - Batch 1360/10125 - Loss: 0.3623 - Acc: 86.72% - LR: 1.13e-05
2025-12-15 17:58:13 - models.bert_model - INFO - Epoch 2/10 - Batch 1400/10125 - Loss: 0.5117 - Acc: 86.75% - LR: 1.14e-05
2025-12-15 17:58:27 - models.bert_model - INFO - Epoch 2/10 - Batch 1440/10125 - Loss: 0.3079 - Acc: 86.77% - LR: 1.14e-05
2025-12-15 17:58:42 - models.bert_model - INFO - Epoch 2/10 - Batch 1480/10125 - Loss: 0.5243 - Acc: 86.83% - LR: 1.15e-05
2025-12-15 17:58:56 - models.bert_model - INFO - Epoch 2/10 - Batch 1520/10125 - Loss: 0.3326 - Acc: 86.87% - LR: 1.15e-05
2025-12-15 17:59:11 - models.bert_model - INFO - Epoch 2/10 - Batch 1560/10125 - Loss: 0.5646 - Acc: 86.90% - LR: 1.15e-05
2025-12-15 17:59:25 - models.bert_model - INFO - Epoch 2/10 - Batch 1600/10125 - Loss: 0.2136 - Acc: 86.98% - LR: 1.16e-05
2025-12-15 17:59:40 - models.bert_model - INFO - Epoch 2/10 - Batch 1640/10125 - Loss: 0.2726 - Acc: 87.03% - LR: 1.16e-05
2025-12-15 17:59:54 - models.bert_model - INFO - Epoch 2/10 - Batch 1680/10125 - Loss: 0.4618 - Acc: 87.02% - LR: 1.17e-05
2025-12-15 18:00:09 - models.bert_model - INFO - Epoch 2/10 - Batch 1720/10125 - Loss: 0.3205 - Acc: 87.06% - LR: 1.17e-05
2025-12-15 18:00:23 - models.bert_model - INFO - Epoch 2/10 - Batch 1760/10125 - Loss: 0.3723 - Acc: 87.07% - LR: 1.17e-05
2025-12-15 18:00:38 - models.bert_model - INFO - Epoch 2/10 - Batch 1800/10125 - Loss: 0.6315 - Acc: 87.07% - LR: 1.18e-05
2025-12-15 18:00:52 - models.bert_model - INFO - Epoch 2/10 - Batch 1840/10125 - Loss: 0.3481 - Acc: 87.08% - LR: 1.18e-05
2025-12-15 18:01:07 - models.bert_model - INFO - Epoch 2/10 - Batch 1880/10125 - Loss: 0.6816 - Acc: 87.08% - LR: 1.19e-05
2025-12-15 18:01:21 - models.bert_model - INFO - Epoch 2/10 - Batch 1920/10125 - Loss: 0.2740 - Acc: 87.11% - LR: 1.19e-05
2025-12-15 18:01:36 - models.bert_model - INFO - Epoch 2/10 - Batch 1960/10125 - Loss: 0.4003 - Acc: 87.12% - LR: 1.19e-05
2025-12-15 18:01:50 - models.bert_model - INFO - Epoch 2/10 - Batch 2000/10125 - Loss: 0.5226 - Acc: 87.12% - LR: 1.20e-05
2025-12-15 18:02:05 - models.bert_model - INFO - Epoch 2/10 - Batch 2040/10125 - Loss: 0.4549 - Acc: 87.13% - LR: 1.20e-05
2025-12-15 18:02:19 - models.bert_model - INFO - Epoch 2/10 - Batch 2080/10125 - Loss: 0.5747 - Acc: 87.15% - LR: 1.21e-05
2025-12-15 18:02:34 - models.bert_model - INFO - Epoch 2/10 - Batch 2120/10125 - Loss: 0.6350 - Acc: 87.18% - LR: 1.21e-05
2025-12-15 18:02:48 - models.bert_model - INFO - Epoch 2/10 - Batch 2160/10125 - Loss: 0.2762 - Acc: 87.21% - LR: 1.21e-05
2025-12-15 18:03:03 - models.bert_model - INFO - Epoch 2/10 - Batch 2200/10125 - Loss: 0.2956 - Acc: 87.23% - LR: 1.22e-05
2025-12-15 18:03:18 - models.bert_model - INFO - Epoch 2/10 - Batch 2240/10125 - Loss: 0.6082 - Acc: 87.26% - LR: 1.22e-05
2025-12-15 18:03:32 - models.bert_model - INFO - Epoch 2/10 - Batch 2280/10125 - Loss: 0.1654 - Acc: 87.28% - LR: 1.23e-05
2025-12-15 18:03:47 - models.bert_model - INFO - Epoch 2/10 - Batch 2320/10125 - Loss: 0.3454 - Acc: 87.33% - LR: 1.23e-05
2025-12-15 18:04:01 - models.bert_model - INFO - Epoch 2/10 - Batch 2360/10125 - Loss: 0.4777 - Acc: 87.35% - LR: 1.23e-05
2025-12-15 18:04:16 - models.bert_model - INFO - Epoch 2/10 - Batch 2400/10125 - Loss: 0.2640 - Acc: 87.35% - LR: 1.24e-05
2025-12-15 18:04:30 - models.bert_model - INFO - Epoch 2/10 - Batch 2440/10125 - Loss: 0.1380 - Acc: 87.38% - LR: 1.24e-05
2025-12-15 18:04:45 - models.bert_model - INFO - Epoch 2/10 - Batch 2480/10125 - Loss: 0.4545 - Acc: 87.37% - LR: 1.25e-05
2025-12-15 18:04:59 - models.bert_model - INFO - Epoch 2/10 - Batch 2520/10125 - Loss: 0.1469 - Acc: 87.38% - LR: 1.25e-05
2025-12-15 18:05:14 - models.bert_model - INFO - Epoch 2/10 - Batch 2560/10125 - Loss: 0.2644 - Acc: 87.41% - LR: 1.25e-05
2025-12-15 18:05:28 - models.bert_model - INFO - Epoch 2/10 - Batch 2600/10125 - Loss: 0.4300 - Acc: 87.43% - LR: 1.26e-05
2025-12-15 18:05:43 - models.bert_model - INFO - Epoch 2/10 - Batch 2640/10125 - Loss: 0.1839 - Acc: 87.45% - LR: 1.26e-05
2025-12-15 18:05:57 - models.bert_model - INFO - Epoch 2/10 - Batch 2680/10125 - Loss: 0.1960 - Acc: 87.46% - LR: 1.26e-05
2025-12-15 18:06:12 - models.bert_model - INFO - Epoch 2/10 - Batch 2720/10125 - Loss: 0.2977 - Acc: 87.48% - LR: 1.27e-05
2025-12-15 18:06:26 - models.bert_model - INFO - Epoch 2/10 - Batch 2760/10125 - Loss: 0.6945 - Acc: 87.51% - LR: 1.27e-05
2025-12-15 18:06:41 - models.bert_model - INFO - Epoch 2/10 - Batch 2800/10125 - Loss: 0.4060 - Acc: 87.52% - LR: 1.28e-05
2025-12-15 18:06:55 - models.bert_model - INFO - Epoch 2/10 - Batch 2840/10125 - Loss: 0.4114 - Acc: 87.52% - LR: 1.28e-05
2025-12-15 18:07:10 - models.bert_model - INFO - Epoch 2/10 - Batch 2880/10125 - Loss: 0.7777 - Acc: 87.52% - LR: 1.28e-05
2025-12-15 18:07:24 - models.bert_model - INFO - Epoch 2/10 - Batch 2920/10125 - Loss: 0.3958 - Acc: 87.54% - LR: 1.29e-05
2025-12-15 18:07:39 - models.bert_model - INFO - Epoch 2/10 - Batch 2960/10125 - Loss: 0.2735 - Acc: 87.53% - LR: 1.29e-05
2025-12-15 18:07:53 - models.bert_model - INFO - Epoch 2/10 - Batch 3000/10125 - Loss: 0.5179 - Acc: 87.55% - LR: 1.30e-05
2025-12-15 18:08:08 - models.bert_model - INFO - Epoch 2/10 - Batch 3040/10125 - Loss: 0.3293 - Acc: 87.56% - LR: 1.30e-05
2025-12-15 18:08:22 - models.bert_model - INFO - Epoch 2/10 - Batch 3080/10125 - Loss: 0.3486 - Acc: 87.58% - LR: 1.30e-05
2025-12-15 18:08:37 - models.bert_model - INFO - Epoch 2/10 - Batch 3120/10125 - Loss: 0.1752 - Acc: 87.58% - LR: 1.31e-05
2025-12-15 18:08:52 - models.bert_model - INFO - Epoch 2/10 - Batch 3160/10125 - Loss: 0.3298 - Acc: 87.61% - LR: 1.31e-05
2025-12-15 18:09:06 - models.bert_model - INFO - Epoch 2/10 - Batch 3200/10125 - Loss: 0.4102 - Acc: 87.61% - LR: 1.32e-05
2025-12-15 18:09:21 - models.bert_model - INFO - Epoch 2/10 - Batch 3240/10125 - Loss: 0.3758 - Acc: 87.62% - LR: 1.32e-05
2025-12-15 18:09:35 - models.bert_model - INFO - Epoch 2/10 - Batch 3280/10125 - Loss: 0.2379 - Acc: 87.62% - LR: 1.32e-05
2025-12-15 18:09:50 - models.bert_model - INFO - Epoch 2/10 - Batch 3320/10125 - Loss: 0.2875 - Acc: 87.62% - LR: 1.33e-05
2025-12-15 18:10:04 - models.bert_model - INFO - Epoch 2/10 - Batch 3360/10125 - Loss: 0.3290 - Acc: 87.65% - LR: 1.33e-05
2025-12-15 18:10:19 - models.bert_model - INFO - Epoch 2/10 - Batch 3400/10125 - Loss: 0.2596 - Acc: 87.68% - LR: 1.34e-05
2025-12-15 18:10:33 - models.bert_model - INFO - Epoch 2/10 - Batch 3440/10125 - Loss: 0.2450 - Acc: 87.69% - LR: 1.34e-05
2025-12-15 18:10:48 - models.bert_model - INFO - Epoch 2/10 - Batch 3480/10125 - Loss: 0.2951 - Acc: 87.71% - LR: 1.34e-05
2025-12-15 18:11:02 - models.bert_model - INFO - Epoch 2/10 - Batch 3520/10125 - Loss: 0.4607 - Acc: 87.73% - LR: 1.35e-05
2025-12-15 18:11:17 - models.bert_model - INFO - Epoch 2/10 - Batch 3560/10125 - Loss: 0.1960 - Acc: 87.76% - LR: 1.35e-05
2025-12-15 18:11:31 - models.bert_model - INFO - Epoch 2/10 - Batch 3600/10125 - Loss: 0.6665 - Acc: 87.78% - LR: 1.36e-05
2025-12-15 18:11:46 - models.bert_model - INFO - Epoch 2/10 - Batch 3640/10125 - Loss: 0.2235 - Acc: 87.81% - LR: 1.36e-05
2025-12-15 18:12:00 - models.bert_model - INFO - Epoch 2/10 - Batch 3680/10125 - Loss: 0.3574 - Acc: 87.84% - LR: 1.36e-05
2025-12-15 18:12:15 - models.bert_model - INFO - Epoch 2/10 - Batch 3720/10125 - Loss: 0.2870 - Acc: 87.83% - LR: 1.37e-05
2025-12-15 18:12:29 - models.bert_model - INFO - Epoch 2/10 - Batch 3760/10125 - Loss: 0.5447 - Acc: 87.84% - LR: 1.37e-05
2025-12-15 18:12:44 - models.bert_model - INFO - Epoch 2/10 - Batch 3800/10125 - Loss: 0.2205 - Acc: 87.86% - LR: 1.38e-05
2025-12-15 18:12:58 - models.bert_model - INFO - Epoch 2/10 - Batch 3840/10125 - Loss: 0.4648 - Acc: 87.87% - LR: 1.38e-05
2025-12-15 18:13:13 - models.bert_model - INFO - Epoch 2/10 - Batch 3880/10125 - Loss: 0.7160 - Acc: 87.88% - LR: 1.38e-05
2025-12-15 18:13:27 - models.bert_model - INFO - Epoch 2/10 - Batch 3920/10125 - Loss: 0.6778 - Acc: 87.90% - LR: 1.39e-05
2025-12-15 18:13:42 - models.bert_model - INFO - Epoch 2/10 - Batch 3960/10125 - Loss: 0.2416 - Acc: 87.91% - LR: 1.39e-05
2025-12-15 18:13:56 - models.bert_model - INFO - Epoch 2/10 - Batch 4000/10125 - Loss: 0.2976 - Acc: 87.90% - LR: 1.40e-05
2025-12-15 18:14:11 - models.bert_model - INFO - Epoch 2/10 - Batch 4040/10125 - Loss: 0.2514 - Acc: 87.93% - LR: 1.40e-05
2025-12-15 18:14:26 - models.bert_model - INFO - Epoch 2/10 - Batch 4080/10125 - Loss: 0.3922 - Acc: 87.94% - LR: 1.40e-05
2025-12-15 18:14:40 - models.bert_model - INFO - Epoch 2/10 - Batch 4120/10125 - Loss: 0.2365 - Acc: 87.95% - LR: 1.41e-05
2025-12-15 18:14:55 - models.bert_model - INFO - Epoch 2/10 - Batch 4160/10125 - Loss: 0.2214 - Acc: 87.95% - LR: 1.41e-05
2025-12-15 18:15:09 - models.bert_model - INFO - Epoch 2/10 - Batch 4200/10125 - Loss: 0.2004 - Acc: 87.97% - LR: 1.42e-05
2025-12-15 18:15:24 - models.bert_model - INFO - Epoch 2/10 - Batch 4240/10125 - Loss: 0.4728 - Acc: 87.98% - LR: 1.42e-05
2025-12-15 18:15:38 - models.bert_model - INFO - Epoch 2/10 - Batch 4280/10125 - Loss: 0.3092 - Acc: 87.99% - LR: 1.42e-05
2025-12-15 18:15:53 - models.bert_model - INFO - Epoch 2/10 - Batch 4320/10125 - Loss: 0.5941 - Acc: 88.00% - LR: 1.43e-05
2025-12-15 18:16:07 - models.bert_model - INFO - Epoch 2/10 - Batch 4360/10125 - Loss: 0.2208 - Acc: 88.03% - LR: 1.43e-05
2025-12-15 18:16:22 - models.bert_model - INFO - Epoch 2/10 - Batch 4400/10125 - Loss: 0.3039 - Acc: 88.06% - LR: 1.43e-05
2025-12-15 18:16:36 - models.bert_model - INFO - Epoch 2/10 - Batch 4440/10125 - Loss: 0.4242 - Acc: 88.09% - LR: 1.44e-05
2025-12-15 18:16:51 - models.bert_model - INFO - Epoch 2/10 - Batch 4480/10125 - Loss: 0.3400 - Acc: 88.10% - LR: 1.44e-05
2025-12-15 18:17:05 - models.bert_model - INFO - Epoch 2/10 - Batch 4520/10125 - Loss: 0.1811 - Acc: 88.12% - LR: 1.45e-05
2025-12-15 18:17:20 - models.bert_model - INFO - Epoch 2/10 - Batch 4560/10125 - Loss: 0.2437 - Acc: 88.12% - LR: 1.45e-05
2025-12-15 18:17:34 - models.bert_model - INFO - Epoch 2/10 - Batch 4600/10125 - Loss: 0.1710 - Acc: 88.13% - LR: 1.45e-05
2025-12-15 18:17:49 - models.bert_model - INFO - Epoch 2/10 - Batch 4640/10125 - Loss: 0.3970 - Acc: 88.16% - LR: 1.46e-05
2025-12-15 18:18:03 - models.bert_model - INFO - Epoch 2/10 - Batch 4680/10125 - Loss: 0.1904 - Acc: 88.19% - LR: 1.46e-05
2025-12-15 18:18:18 - models.bert_model - INFO - Epoch 2/10 - Batch 4720/10125 - Loss: 0.4084 - Acc: 88.18% - LR: 1.47e-05
2025-12-15 18:18:32 - models.bert_model - INFO - Epoch 2/10 - Batch 4760/10125 - Loss: 0.4424 - Acc: 88.20% - LR: 1.47e-05
2025-12-15 18:18:47 - models.bert_model - INFO - Epoch 2/10 - Batch 4800/10125 - Loss: 0.1475 - Acc: 88.20% - LR: 1.47e-05
2025-12-15 18:19:01 - models.bert_model - INFO - Epoch 2/10 - Batch 4840/10125 - Loss: 0.4690 - Acc: 88.21% - LR: 1.48e-05
2025-12-15 18:19:16 - models.bert_model - INFO - Epoch 2/10 - Batch 4880/10125 - Loss: 0.1709 - Acc: 88.23% - LR: 1.48e-05
2025-12-15 18:19:30 - models.bert_model - INFO - Epoch 2/10 - Batch 4920/10125 - Loss: 0.1990 - Acc: 88.26% - LR: 1.49e-05
2025-12-15 18:19:45 - models.bert_model - INFO - Epoch 2/10 - Batch 4960/10125 - Loss: 0.3926 - Acc: 88.25% - LR: 1.49e-05
2025-12-15 18:19:59 - models.bert_model - INFO - Epoch 2/10 - Batch 5000/10125 - Loss: 0.3438 - Acc: 88.27% - LR: 1.49e-05
2025-12-15 18:20:14 - models.bert_model - INFO - Epoch 2/10 - Batch 5040/10125 - Loss: 0.2125 - Acc: 88.28% - LR: 1.50e-05
2025-12-15 18:20:28 - models.bert_model - INFO - Epoch 2/10 - Batch 5080/10125 - Loss: 0.2635 - Acc: 88.30% - LR: 1.50e-05
2025-12-15 18:20:43 - models.bert_model - INFO - Epoch 2/10 - Batch 5120/10125 - Loss: 0.5703 - Acc: 88.31% - LR: 1.50e-05
2025-12-15 18:20:57 - models.bert_model - INFO - Epoch 2/10 - Batch 5160/10125 - Loss: 0.2902 - Acc: 88.32% - LR: 1.50e-05
2025-12-15 18:21:12 - models.bert_model - INFO - Epoch 2/10 - Batch 5200/10125 - Loss: 0.1969 - Acc: 88.35% - LR: 1.50e-05
2025-12-15 18:21:26 - models.bert_model - INFO - Epoch 2/10 - Batch 5240/10125 - Loss: 0.1761 - Acc: 88.36% - LR: 1.50e-05
2025-12-15 18:21:41 - models.bert_model - INFO - Epoch 2/10 - Batch 5280/10125 - Loss: 0.1585 - Acc: 88.38% - LR: 1.50e-05
2025-12-15 18:21:55 - models.bert_model - INFO - Epoch 2/10 - Batch 5320/10125 - Loss: 0.4872 - Acc: 88.38% - LR: 1.50e-05
2025-12-15 18:22:10 - models.bert_model - INFO - Epoch 2/10 - Batch 5360/10125 - Loss: 0.4938 - Acc: 88.38% - LR: 1.50e-05
2025-12-15 18:22:24 - models.bert_model - INFO - Epoch 2/10 - Batch 5400/10125 - Loss: 0.5428 - Acc: 88.40% - LR: 1.50e-05
2025-12-15 18:22:39 - models.bert_model - INFO - Epoch 2/10 - Batch 5440/10125 - Loss: 0.3032 - Acc: 88.40% - LR: 1.50e-05
2025-12-15 18:22:54 - models.bert_model - INFO - Epoch 2/10 - Batch 5480/10125 - Loss: 0.2229 - Acc: 88.40% - LR: 1.50e-05
2025-12-15 18:23:08 - models.bert_model - INFO - Epoch 2/10 - Batch 5520/10125 - Loss: 0.3260 - Acc: 88.42% - LR: 1.50e-05
2025-12-15 18:23:23 - models.bert_model - INFO - Epoch 2/10 - Batch 5560/10125 - Loss: 0.4188 - Acc: 88.43% - LR: 1.50e-05
2025-12-15 18:23:37 - models.bert_model - INFO - Epoch 2/10 - Batch 5600/10125 - Loss: 0.4994 - Acc: 88.43% - LR: 1.50e-05
2025-12-15 18:23:52 - models.bert_model - INFO - Epoch 2/10 - Batch 5640/10125 - Loss: 0.3508 - Acc: 88.45% - LR: 1.50e-05
2025-12-15 18:24:06 - models.bert_model - INFO - Epoch 2/10 - Batch 5680/10125 - Loss: 0.1268 - Acc: 88.47% - LR: 1.50e-05
2025-12-15 18:24:21 - models.bert_model - INFO - Epoch 2/10 - Batch 5720/10125 - Loss: 0.3825 - Acc: 88.48% - LR: 1.50e-05
2025-12-15 18:24:35 - models.bert_model - INFO - Epoch 2/10 - Batch 5760/10125 - Loss: 0.5121 - Acc: 88.48% - LR: 1.50e-05
2025-12-15 18:24:50 - models.bert_model - INFO - Epoch 2/10 - Batch 5800/10125 - Loss: 0.5859 - Acc: 88.50% - LR: 1.50e-05
2025-12-15 18:25:04 - models.bert_model - INFO - Epoch 2/10 - Batch 5840/10125 - Loss: 0.2426 - Acc: 88.51% - LR: 1.50e-05
2025-12-15 18:25:19 - models.bert_model - INFO - Epoch 2/10 - Batch 5880/10125 - Loss: 0.2400 - Acc: 88.52% - LR: 1.50e-05
2025-12-15 18:25:33 - models.bert_model - INFO - Epoch 2/10 - Batch 5920/10125 - Loss: 0.2448 - Acc: 88.51% - LR: 1.50e-05
2025-12-15 18:25:48 - models.bert_model - INFO - Epoch 2/10 - Batch 5960/10125 - Loss: 0.3476 - Acc: 88.53% - LR: 1.50e-05
2025-12-15 18:26:02 - models.bert_model - INFO - Epoch 2/10 - Batch 6000/10125 - Loss: 0.4557 - Acc: 88.55% - LR: 1.50e-05
2025-12-15 18:26:17 - models.bert_model - INFO - Epoch 2/10 - Batch 6040/10125 - Loss: 0.3338 - Acc: 88.58% - LR: 1.50e-05
2025-12-15 18:26:31 - models.bert_model - INFO - Epoch 2/10 - Batch 6080/10125 - Loss: 0.1726 - Acc: 88.59% - LR: 1.50e-05
2025-12-15 18:26:46 - models.bert_model - INFO - Epoch 2/10 - Batch 6120/10125 - Loss: 0.3522 - Acc: 88.60% - LR: 1.50e-05
2025-12-15 18:27:00 - models.bert_model - INFO - Epoch 2/10 - Batch 6160/10125 - Loss: 0.4469 - Acc: 88.59% - LR: 1.50e-05
2025-12-15 18:27:15 - models.bert_model - INFO - Epoch 2/10 - Batch 6200/10125 - Loss: 0.4141 - Acc: 88.60% - LR: 1.50e-05
2025-12-15 18:27:29 - models.bert_model - INFO - Epoch 2/10 - Batch 6240/10125 - Loss: 0.2830 - Acc: 88.61% - LR: 1.50e-05
2025-12-15 18:27:44 - models.bert_model - INFO - Epoch 2/10 - Batch 6280/10125 - Loss: 0.3277 - Acc: 88.62% - LR: 1.50e-05
2025-12-15 18:27:58 - models.bert_model - INFO - Epoch 2/10 - Batch 6320/10125 - Loss: 0.2451 - Acc: 88.63% - LR: 1.50e-05
2025-12-15 18:28:13 - models.bert_model - INFO - Epoch 2/10 - Batch 6360/10125 - Loss: 0.2035 - Acc: 88.64% - LR: 1.50e-05
2025-12-15 18:28:27 - models.bert_model - INFO - Epoch 2/10 - Batch 6400/10125 - Loss: 0.1926 - Acc: 88.66% - LR: 1.50e-05
2025-12-15 18:28:42 - models.bert_model - INFO - Epoch 2/10 - Batch 6440/10125 - Loss: 0.1994 - Acc: 88.67% - LR: 1.50e-05
2025-12-15 18:28:56 - models.bert_model - INFO - Epoch 2/10 - Batch 6480/10125 - Loss: 0.1499 - Acc: 88.69% - LR: 1.50e-05
2025-12-15 18:29:11 - models.bert_model - INFO - Epoch 2/10 - Batch 6520/10125 - Loss: 0.1699 - Acc: 88.70% - LR: 1.50e-05
2025-12-15 18:29:26 - models.bert_model - INFO - Epoch 2/10 - Batch 6560/10125 - Loss: 0.1914 - Acc: 88.72% - LR: 1.50e-05
2025-12-15 18:29:40 - models.bert_model - INFO - Epoch 2/10 - Batch 6600/10125 - Loss: 0.2522 - Acc: 88.73% - LR: 1.50e-05
2025-12-15 18:29:55 - models.bert_model - INFO - Epoch 2/10 - Batch 6640/10125 - Loss: 0.4059 - Acc: 88.75% - LR: 1.50e-05
2025-12-15 18:30:09 - models.bert_model - INFO - Epoch 2/10 - Batch 6680/10125 - Loss: 0.4619 - Acc: 88.76% - LR: 1.50e-05
2025-12-15 18:30:24 - models.bert_model - INFO - Epoch 2/10 - Batch 6720/10125 - Loss: 0.2926 - Acc: 88.77% - LR: 1.50e-05
2025-12-15 18:30:38 - models.bert_model - INFO - Epoch 2/10 - Batch 6760/10125 - Loss: 0.2075 - Acc: 88.77% - LR: 1.50e-05
2025-12-15 18:30:53 - models.bert_model - INFO - Epoch 2/10 - Batch 6800/10125 - Loss: 0.5803 - Acc: 88.78% - LR: 1.50e-05
2025-12-15 18:31:07 - models.bert_model - INFO - Epoch 2/10 - Batch 6840/10125 - Loss: 0.1292 - Acc: 88.80% - LR: 1.50e-05
2025-12-15 18:31:22 - models.bert_model - INFO - Epoch 2/10 - Batch 6880/10125 - Loss: 0.2037 - Acc: 88.82% - LR: 1.50e-05
2025-12-15 18:31:37 - models.bert_model - INFO - Epoch 2/10 - Batch 6920/10125 - Loss: 0.5115 - Acc: 88.81% - LR: 1.50e-05
2025-12-15 18:31:51 - models.bert_model - INFO - Epoch 2/10 - Batch 6960/10125 - Loss: 0.3063 - Acc: 88.82% - LR: 1.50e-05
2025-12-15 18:32:06 - models.bert_model - INFO - Epoch 2/10 - Batch 7000/10125 - Loss: 0.1412 - Acc: 88.83% - LR: 1.50e-05
2025-12-15 18:32:20 - models.bert_model - INFO - Epoch 2/10 - Batch 7040/10125 - Loss: 0.8354 - Acc: 88.82% - LR: 1.50e-05
2025-12-15 18:32:35 - models.bert_model - INFO - Epoch 2/10 - Batch 7080/10125 - Loss: 0.1455 - Acc: 88.83% - LR: 1.50e-05
2025-12-15 18:32:49 - models.bert_model - INFO - Epoch 2/10 - Batch 7120/10125 - Loss: 0.3875 - Acc: 88.83% - LR: 1.50e-05
2025-12-15 18:33:04 - models.bert_model - INFO - Epoch 2/10 - Batch 7160/10125 - Loss: 0.2984 - Acc: 88.83% - LR: 1.50e-05
2025-12-15 18:33:18 - models.bert_model - INFO - Epoch 2/10 - Batch 7200/10125 - Loss: 0.1444 - Acc: 88.85% - LR: 1.50e-05
2025-12-15 18:33:33 - models.bert_model - INFO - Epoch 2/10 - Batch 7240/10125 - Loss: 0.3317 - Acc: 88.84% - LR: 1.50e-05
2025-12-15 18:33:47 - models.bert_model - INFO - Epoch 2/10 - Batch 7280/10125 - Loss: 0.3021 - Acc: 88.85% - LR: 1.50e-05
2025-12-15 18:34:02 - models.bert_model - INFO - Epoch 2/10 - Batch 7320/10125 - Loss: 0.3390 - Acc: 88.86% - LR: 1.50e-05
2025-12-15 18:34:16 - models.bert_model - INFO - Epoch 2/10 - Batch 7360/10125 - Loss: 0.1991 - Acc: 88.87% - LR: 1.50e-05
2025-12-15 18:34:31 - models.bert_model - INFO - Epoch 2/10 - Batch 7400/10125 - Loss: 0.3023 - Acc: 88.87% - LR: 1.50e-05
2025-12-15 18:34:45 - models.bert_model - INFO - Epoch 2/10 - Batch 7440/10125 - Loss: 0.2966 - Acc: 88.89% - LR: 1.50e-05
2025-12-15 18:35:00 - models.bert_model - INFO - Epoch 2/10 - Batch 7480/10125 - Loss: 0.5221 - Acc: 88.91% - LR: 1.50e-05
2025-12-15 18:35:14 - models.bert_model - INFO - Epoch 2/10 - Batch 7520/10125 - Loss: 0.4100 - Acc: 88.93% - LR: 1.50e-05
2025-12-15 18:35:29 - models.bert_model - INFO - Epoch 2/10 - Batch 7560/10125 - Loss: 0.3309 - Acc: 88.94% - LR: 1.50e-05
2025-12-15 18:35:43 - models.bert_model - INFO - Epoch 2/10 - Batch 7600/10125 - Loss: 0.1628 - Acc: 88.94% - LR: 1.50e-05
2025-12-15 18:35:58 - models.bert_model - INFO - Epoch 2/10 - Batch 7640/10125 - Loss: 0.2594 - Acc: 88.95% - LR: 1.50e-05
2025-12-15 18:36:12 - models.bert_model - INFO - Epoch 2/10 - Batch 7680/10125 - Loss: 0.2625 - Acc: 88.95% - LR: 1.50e-05
2025-12-15 18:36:27 - models.bert_model - INFO - Epoch 2/10 - Batch 7720/10125 - Loss: 0.4171 - Acc: 88.96% - LR: 1.50e-05
2025-12-15 18:36:42 - models.bert_model - INFO - Epoch 2/10 - Batch 7760/10125 - Loss: 0.2967 - Acc: 88.97% - LR: 1.50e-05
2025-12-15 18:36:56 - models.bert_model - INFO - Epoch 2/10 - Batch 7800/10125 - Loss: 0.1485 - Acc: 88.98% - LR: 1.50e-05
2025-12-15 18:37:11 - models.bert_model - INFO - Epoch 2/10 - Batch 7840/10125 - Loss: 0.4853 - Acc: 88.98% - LR: 1.50e-05
2025-12-15 18:37:25 - models.bert_model - INFO - Epoch 2/10 - Batch 7880/10125 - Loss: 0.5780 - Acc: 88.98% - LR: 1.50e-05
2025-12-15 18:37:40 - models.bert_model - INFO - Epoch 2/10 - Batch 7920/10125 - Loss: 0.5870 - Acc: 88.99% - LR: 1.50e-05
2025-12-15 18:37:54 - models.bert_model - INFO - Epoch 2/10 - Batch 7960/10125 - Loss: 0.1695 - Acc: 89.00% - LR: 1.50e-05
2025-12-15 18:38:09 - models.bert_model - INFO - Epoch 2/10 - Batch 8000/10125 - Loss: 0.2357 - Acc: 88.99% - LR: 1.50e-05
2025-12-15 18:38:23 - models.bert_model - INFO - Epoch 2/10 - Batch 8040/10125 - Loss: 0.1862 - Acc: 89.00% - LR: 1.50e-05
2025-12-15 18:38:38 - models.bert_model - INFO - Epoch 2/10 - Batch 8080/10125 - Loss: 0.1247 - Acc: 89.01% - LR: 1.50e-05
2025-12-15 18:38:52 - models.bert_model - INFO - Epoch 2/10 - Batch 8120/10125 - Loss: 0.1385 - Acc: 89.02% - LR: 1.50e-05
2025-12-15 18:39:07 - models.bert_model - INFO - Epoch 2/10 - Batch 8160/10125 - Loss: 0.1475 - Acc: 89.03% - LR: 1.50e-05
2025-12-15 18:39:21 - models.bert_model - INFO - Epoch 2/10 - Batch 8200/10125 - Loss: 0.5260 - Acc: 89.04% - LR: 1.50e-05
2025-12-15 18:39:36 - models.bert_model - INFO - Epoch 2/10 - Batch 8240/10125 - Loss: 0.1849 - Acc: 89.05% - LR: 1.49e-05
2025-12-15 18:39:50 - models.bert_model - INFO - Epoch 2/10 - Batch 8280/10125 - Loss: 0.2308 - Acc: 89.06% - LR: 1.49e-05
2025-12-15 18:40:05 - models.bert_model - INFO - Epoch 2/10 - Batch 8320/10125 - Loss: 0.2758 - Acc: 89.07% - LR: 1.49e-05
2025-12-15 18:40:19 - models.bert_model - INFO - Epoch 2/10 - Batch 8360/10125 - Loss: 0.1613 - Acc: 89.09% - LR: 1.49e-05
2025-12-15 18:40:34 - models.bert_model - INFO - Epoch 2/10 - Batch 8400/10125 - Loss: 0.2785 - Acc: 89.10% - LR: 1.49e-05
2025-12-15 18:40:49 - models.bert_model - INFO - Epoch 2/10 - Batch 8440/10125 - Loss: 0.3476 - Acc: 89.10% - LR: 1.49e-05
2025-12-15 18:41:03 - models.bert_model - INFO - Epoch 2/10 - Batch 8480/10125 - Loss: 0.1373 - Acc: 89.12% - LR: 1.49e-05
2025-12-15 18:41:18 - models.bert_model - INFO - Epoch 2/10 - Batch 8520/10125 - Loss: 0.2663 - Acc: 89.12% - LR: 1.49e-05
2025-12-15 18:41:32 - models.bert_model - INFO - Epoch 2/10 - Batch 8560/10125 - Loss: 0.6103 - Acc: 89.14% - LR: 1.49e-05
2025-12-15 18:41:47 - models.bert_model - INFO - Epoch 2/10 - Batch 8600/10125 - Loss: 0.3332 - Acc: 89.14% - LR: 1.49e-05
2025-12-15 18:42:01 - models.bert_model - INFO - Epoch 2/10 - Batch 8640/10125 - Loss: 0.2576 - Acc: 89.15% - LR: 1.49e-05
2025-12-15 18:42:16 - models.bert_model - INFO - Epoch 2/10 - Batch 8680/10125 - Loss: 0.3096 - Acc: 89.16% - LR: 1.49e-05
2025-12-15 18:42:30 - models.bert_model - INFO - Epoch 2/10 - Batch 8720/10125 - Loss: 0.2501 - Acc: 89.17% - LR: 1.49e-05
2025-12-15 18:42:45 - models.bert_model - INFO - Epoch 2/10 - Batch 8760/10125 - Loss: 0.1393 - Acc: 89.19% - LR: 1.49e-05
2025-12-15 18:42:59 - models.bert_model - INFO - Epoch 2/10 - Batch 8800/10125 - Loss: 0.3124 - Acc: 89.20% - LR: 1.49e-05
2025-12-15 18:43:14 - models.bert_model - INFO - Epoch 2/10 - Batch 8840/10125 - Loss: 0.1355 - Acc: 89.21% - LR: 1.49e-05
2025-12-15 18:43:28 - models.bert_model - INFO - Epoch 2/10 - Batch 8880/10125 - Loss: 0.2721 - Acc: 89.21% - LR: 1.49e-05
2025-12-15 18:43:43 - models.bert_model - INFO - Epoch 2/10 - Batch 8920/10125 - Loss: 0.3628 - Acc: 89.23% - LR: 1.49e-05
2025-12-15 18:43:57 - models.bert_model - INFO - Epoch 2/10 - Batch 8960/10125 - Loss: 0.5258 - Acc: 89.23% - LR: 1.49e-05
2025-12-15 18:44:12 - models.bert_model - INFO - Epoch 2/10 - Batch 9000/10125 - Loss: 0.2813 - Acc: 89.23% - LR: 1.49e-05
2025-12-15 18:44:26 - models.bert_model - INFO - Epoch 2/10 - Batch 9040/10125 - Loss: 0.3078 - Acc: 89.23% - LR: 1.49e-05
2025-12-15 18:44:41 - models.bert_model - INFO - Epoch 2/10 - Batch 9080/10125 - Loss: 0.2515 - Acc: 89.24% - LR: 1.49e-05
2025-12-15 18:44:56 - models.bert_model - INFO - Epoch 2/10 - Batch 9120/10125 - Loss: 0.3290 - Acc: 89.25% - LR: 1.49e-05
2025-12-15 18:45:10 - models.bert_model - INFO - Epoch 2/10 - Batch 9160/10125 - Loss: 0.1534 - Acc: 89.26% - LR: 1.49e-05
2025-12-15 18:45:25 - models.bert_model - INFO - Epoch 2/10 - Batch 9200/10125 - Loss: 0.1811 - Acc: 89.27% - LR: 1.49e-05
2025-12-15 18:45:39 - models.bert_model - INFO - Epoch 2/10 - Batch 9240/10125 - Loss: 0.2882 - Acc: 89.27% - LR: 1.49e-05
2025-12-15 18:45:54 - models.bert_model - INFO - Epoch 2/10 - Batch 9280/10125 - Loss: 0.1296 - Acc: 89.28% - LR: 1.49e-05
2025-12-15 18:46:08 - models.bert_model - INFO - Epoch 2/10 - Batch 9320/10125 - Loss: 0.4367 - Acc: 89.29% - LR: 1.49e-05
2025-12-15 18:46:23 - models.bert_model - INFO - Epoch 2/10 - Batch 9360/10125 - Loss: 0.3464 - Acc: 89.28% - LR: 1.49e-05
2025-12-15 18:46:37 - models.bert_model - INFO - Epoch 2/10 - Batch 9400/10125 - Loss: 0.5447 - Acc: 89.29% - LR: 1.49e-05
2025-12-15 18:46:52 - models.bert_model - INFO - Epoch 2/10 - Batch 9440/10125 - Loss: 0.1562 - Acc: 89.30% - LR: 1.49e-05
2025-12-15 18:47:06 - models.bert_model - INFO - Epoch 2/10 - Batch 9480/10125 - Loss: 0.2738 - Acc: 89.31% - LR: 1.49e-05
2025-12-15 18:47:21 - models.bert_model - INFO - Epoch 2/10 - Batch 9520/10125 - Loss: 0.2094 - Acc: 89.32% - LR: 1.49e-05
2025-12-15 18:47:35 - models.bert_model - INFO - Epoch 2/10 - Batch 9560/10125 - Loss: 0.3783 - Acc: 89.33% - LR: 1.49e-05
2025-12-15 18:47:50 - models.bert_model - INFO - Epoch 2/10 - Batch 9600/10125 - Loss: 0.2728 - Acc: 89.33% - LR: 1.49e-05
2025-12-15 18:48:04 - models.bert_model - INFO - Epoch 2/10 - Batch 9640/10125 - Loss: 0.2216 - Acc: 89.34% - LR: 1.49e-05
2025-12-15 18:48:19 - models.bert_model - INFO - Epoch 2/10 - Batch 9680/10125 - Loss: 0.2183 - Acc: 89.34% - LR: 1.49e-05
2025-12-15 18:48:33 - models.bert_model - INFO - Epoch 2/10 - Batch 9720/10125 - Loss: 0.1815 - Acc: 89.35% - LR: 1.49e-05
2025-12-15 18:48:48 - models.bert_model - INFO - Epoch 2/10 - Batch 9760/10125 - Loss: 0.2497 - Acc: 89.36% - LR: 1.49e-05
2025-12-15 18:49:03 - models.bert_model - INFO - Epoch 2/10 - Batch 9800/10125 - Loss: 0.2239 - Acc: 89.36% - LR: 1.49e-05
2025-12-15 18:49:17 - models.bert_model - INFO - Epoch 2/10 - Batch 9840/10125 - Loss: 0.3753 - Acc: 89.37% - LR: 1.49e-05
2025-12-15 18:49:32 - models.bert_model - INFO - Epoch 2/10 - Batch 9880/10125 - Loss: 0.1220 - Acc: 89.38% - LR: 1.49e-05
2025-12-15 18:49:46 - models.bert_model - INFO - Epoch 2/10 - Batch 9920/10125 - Loss: 0.1969 - Acc: 89.38% - LR: 1.49e-05
2025-12-15 18:50:01 - models.bert_model - INFO - Epoch 2/10 - Batch 9960/10125 - Loss: 0.1480 - Acc: 89.39% - LR: 1.49e-05
2025-12-15 18:50:15 - models.bert_model - INFO - Epoch 2/10 - Batch 10000/10125 - Loss: 0.4552 - Acc: 89.41% - LR: 1.49e-05
2025-12-15 18:50:30 - models.bert_model - INFO - Epoch 2/10 - Batch 10040/10125 - Loss: 0.3543 - Acc: 89.41% - LR: 1.49e-05
2025-12-15 18:50:44 - models.bert_model - INFO - Epoch 2/10 - Batch 10080/10125 - Loss: 0.2815 - Acc: 89.41% - LR: 1.49e-05
2025-12-15 18:50:59 - models.bert_model - INFO - Epoch 2/10 - Batch 10120/10125 - Loss: 0.3921 - Acc: 89.42% - LR: 1.49e-05
2025-12-15 18:53:17 - models.bert_model - INFO - Epoch 2/10 - Train Loss: 0.3467, Train Acc: 89.42% - Val Loss: 0.2773, Val Acc: 92.04%
2025-12-15 18:53:17 - models.bert_model - INFO - New best validation accuracy: 92.04%
2025-12-15 18:53:32 - models.bert_model - INFO - Epoch 3/10 - Batch 40/10125 - Loss: 0.2171 - Acc: 90.31% - LR: 1.49e-05
2025-12-15 18:53:46 - models.bert_model - INFO - Epoch 3/10 - Batch 80/10125 - Loss: 0.5131 - Acc: 91.17% - LR: 1.49e-05
2025-12-15 18:54:01 - models.bert_model - INFO - Epoch 3/10 - Batch 120/10125 - Loss: 0.1689 - Acc: 90.83% - LR: 1.49e-05
2025-12-15 18:54:15 - models.bert_model - INFO - Epoch 3/10 - Batch 160/10125 - Loss: 0.3155 - Acc: 90.59% - LR: 1.49e-05
2025-12-15 18:54:30 - models.bert_model - INFO - Epoch 3/10 - Batch 200/10125 - Loss: 0.3045 - Acc: 90.94% - LR: 1.49e-05
2025-12-15 18:54:44 - models.bert_model - INFO - Epoch 3/10 - Batch 240/10125 - Loss: 0.1908 - Acc: 91.28% - LR: 1.49e-05
2025-12-15 18:54:59 - models.bert_model - INFO - Epoch 3/10 - Batch 280/10125 - Loss: 0.2192 - Acc: 91.16% - LR: 1.49e-05
2025-12-15 18:55:13 - models.bert_model - INFO - Epoch 3/10 - Batch 320/10125 - Loss: 0.3564 - Acc: 91.29% - LR: 1.49e-05
2025-12-15 18:55:28 - models.bert_model - INFO - Epoch 3/10 - Batch 360/10125 - Loss: 0.3843 - Acc: 91.22% - LR: 1.49e-05
2025-12-15 18:55:42 - models.bert_model - INFO - Epoch 3/10 - Batch 400/10125 - Loss: 0.1995 - Acc: 91.42% - LR: 1.49e-05
2025-12-15 18:55:57 - models.bert_model - INFO - Epoch 3/10 - Batch 440/10125 - Loss: 0.2535 - Acc: 91.43% - LR: 1.48e-05
2025-12-15 18:56:11 - models.bert_model - INFO - Epoch 3/10 - Batch 480/10125 - Loss: 0.4537 - Acc: 91.28% - LR: 1.48e-05
2025-12-15 18:56:26 - models.bert_model - INFO - Epoch 3/10 - Batch 520/10125 - Loss: 0.1574 - Acc: 91.41% - LR: 1.48e-05
2025-12-15 18:56:40 - models.bert_model - INFO - Epoch 3/10 - Batch 560/10125 - Loss: 0.2287 - Acc: 91.46% - LR: 1.48e-05
2025-12-15 18:56:55 - models.bert_model - INFO - Epoch 3/10 - Batch 600/10125 - Loss: 0.2945 - Acc: 91.40% - LR: 1.48e-05
2025-12-15 18:57:09 - models.bert_model - INFO - Epoch 3/10 - Batch 640/10125 - Loss: 0.1856 - Acc: 91.30% - LR: 1.48e-05
2025-12-15 18:57:24 - models.bert_model - INFO - Epoch 3/10 - Batch 680/10125 - Loss: 0.1371 - Acc: 91.39% - LR: 1.48e-05
2025-12-15 18:57:39 - models.bert_model - INFO - Epoch 3/10 - Batch 720/10125 - Loss: 0.3632 - Acc: 91.34% - LR: 1.48e-05
2025-12-15 18:57:53 - models.bert_model - INFO - Epoch 3/10 - Batch 760/10125 - Loss: 0.2840 - Acc: 91.30% - LR: 1.48e-05
2025-12-15 18:58:08 - models.bert_model - INFO - Epoch 3/10 - Batch 800/10125 - Loss: 0.2325 - Acc: 91.28% - LR: 1.48e-05
2025-12-15 18:58:22 - models.bert_model - INFO - Epoch 3/10 - Batch 840/10125 - Loss: 0.1361 - Acc: 91.38% - LR: 1.48e-05
2025-12-15 18:58:37 - models.bert_model - INFO - Epoch 3/10 - Batch 880/10125 - Loss: 0.1872 - Acc: 91.47% - LR: 1.48e-05
2025-12-15 18:58:51 - models.bert_model - INFO - Epoch 3/10 - Batch 920/10125 - Loss: 0.1779 - Acc: 91.49% - LR: 1.48e-05
2025-12-15 18:59:06 - models.bert_model - INFO - Epoch 3/10 - Batch 960/10125 - Loss: 0.2781 - Acc: 91.48% - LR: 1.48e-05
2025-12-15 18:59:20 - models.bert_model - INFO - Epoch 3/10 - Batch 1000/10125 - Loss: 0.3572 - Acc: 91.46% - LR: 1.48e-05
2025-12-15 18:59:35 - models.bert_model - INFO - Epoch 3/10 - Batch 1040/10125 - Loss: 0.2434 - Acc: 91.53% - LR: 1.48e-05
2025-12-15 18:59:49 - models.bert_model - INFO - Epoch 3/10 - Batch 1080/10125 - Loss: 0.3435 - Acc: 91.56% - LR: 1.48e-05
2025-12-15 19:00:04 - models.bert_model - INFO - Epoch 3/10 - Batch 1120/10125 - Loss: 0.1831 - Acc: 91.56% - LR: 1.48e-05
2025-12-15 19:00:18 - models.bert_model - INFO - Epoch 3/10 - Batch 1160/10125 - Loss: 0.3383 - Acc: 91.60% - LR: 1.48e-05
2025-12-15 19:00:33 - models.bert_model - INFO - Epoch 3/10 - Batch 1200/10125 - Loss: 0.2909 - Acc: 91.59% - LR: 1.48e-05
2025-12-15 19:00:47 - models.bert_model - INFO - Epoch 3/10 - Batch 1240/10125 - Loss: 0.2216 - Acc: 91.59% - LR: 1.48e-05
2025-12-15 19:01:02 - models.bert_model - INFO - Epoch 3/10 - Batch 1280/10125 - Loss: 0.3947 - Acc: 91.55% - LR: 1.48e-05
2025-12-15 19:01:16 - models.bert_model - INFO - Epoch 3/10 - Batch 1320/10125 - Loss: 0.1828 - Acc: 91.55% - LR: 1.48e-05
2025-12-15 19:01:31 - models.bert_model - INFO - Epoch 3/10 - Batch 1360/10125 - Loss: 0.1581 - Acc: 91.62% - LR: 1.48e-05
2025-12-15 19:01:45 - models.bert_model - INFO - Epoch 3/10 - Batch 1400/10125 - Loss: 0.1430 - Acc: 91.60% - LR: 1.48e-05
2025-12-15 19:02:00 - models.bert_model - INFO - Epoch 3/10 - Batch 1440/10125 - Loss: 0.1379 - Acc: 91.61% - LR: 1.48e-05
2025-12-15 19:02:14 - models.bert_model - INFO - Epoch 3/10 - Batch 1480/10125 - Loss: 0.3752 - Acc: 91.63% - LR: 1.48e-05
2025-12-15 19:02:29 - models.bert_model - INFO - Epoch 3/10 - Batch 1520/10125 - Loss: 0.1825 - Acc: 91.67% - LR: 1.48e-05
2025-12-15 19:02:43 - models.bert_model - INFO - Epoch 3/10 - Batch 1560/10125 - Loss: 0.3054 - Acc: 91.64% - LR: 1.48e-05
2025-12-15 19:02:58 - models.bert_model - INFO - Epoch 3/10 - Batch 1600/10125 - Loss: 0.3535 - Acc: 91.66% - LR: 1.48e-05
2025-12-15 19:03:12 - models.bert_model - INFO - Epoch 3/10 - Batch 1640/10125 - Loss: 0.1572 - Acc: 91.67% - LR: 1.48e-05
2025-12-15 19:03:27 - models.bert_model - INFO - Epoch 3/10 - Batch 1680/10125 - Loss: 0.3394 - Acc: 91.66% - LR: 1.48e-05
2025-12-15 19:03:41 - models.bert_model - INFO - Epoch 3/10 - Batch 1720/10125 - Loss: 0.1676 - Acc: 91.68% - LR: 1.48e-05
2025-12-15 19:03:56 - models.bert_model - INFO - Epoch 3/10 - Batch 1760/10125 - Loss: 0.1826 - Acc: 91.64% - LR: 1.48e-05
2025-12-15 19:04:11 - models.bert_model - INFO - Epoch 3/10 - Batch 1800/10125 - Loss: 0.4360 - Acc: 91.63% - LR: 1.48e-05
2025-12-15 19:04:25 - models.bert_model - INFO - Epoch 3/10 - Batch 1840/10125 - Loss: 0.1533 - Acc: 91.65% - LR: 1.48e-05
2025-12-15 19:04:40 - models.bert_model - INFO - Epoch 3/10 - Batch 1880/10125 - Loss: 0.3335 - Acc: 91.63% - LR: 1.48e-05
2025-12-15 19:04:54 - models.bert_model - INFO - Epoch 3/10 - Batch 1920/10125 - Loss: 0.3065 - Acc: 91.63% - LR: 1.48e-05
2025-12-15 19:05:09 - models.bert_model - INFO - Epoch 3/10 - Batch 1960/10125 - Loss: 0.2167 - Acc: 91.66% - LR: 1.48e-05
2025-12-15 19:05:23 - models.bert_model - INFO - Epoch 3/10 - Batch 2000/10125 - Loss: 0.2202 - Acc: 91.67% - LR: 1.48e-05
2025-12-15 19:05:38 - models.bert_model - INFO - Epoch 3/10 - Batch 2040/10125 - Loss: 0.3339 - Acc: 91.69% - LR: 1.47e-05
2025-12-15 19:05:52 - models.bert_model - INFO - Epoch 3/10 - Batch 2080/10125 - Loss: 0.5541 - Acc: 91.69% - LR: 1.47e-05
2025-12-15 19:06:07 - models.bert_model - INFO - Epoch 3/10 - Batch 2120/10125 - Loss: 0.3223 - Acc: 91.66% - LR: 1.47e-05
2025-12-15 19:06:22 - models.bert_model - INFO - Epoch 3/10 - Batch 2160/10125 - Loss: 0.3661 - Acc: 91.68% - LR: 1.47e-05
2025-12-15 19:06:36 - models.bert_model - INFO - Epoch 3/10 - Batch 2200/10125 - Loss: 0.2287 - Acc: 91.69% - LR: 1.47e-05
2025-12-15 19:06:51 - models.bert_model - INFO - Epoch 3/10 - Batch 2240/10125 - Loss: 0.4136 - Acc: 91.71% - LR: 1.47e-05
2025-12-15 19:07:05 - models.bert_model - INFO - Epoch 3/10 - Batch 2280/10125 - Loss: 0.2361 - Acc: 91.72% - LR: 1.47e-05
2025-12-15 19:07:20 - models.bert_model - INFO - Epoch 3/10 - Batch 2320/10125 - Loss: 0.4537 - Acc: 91.72% - LR: 1.47e-05
2025-12-15 19:07:34 - models.bert_model - INFO - Epoch 3/10 - Batch 2360/10125 - Loss: 0.4005 - Acc: 91.70% - LR: 1.47e-05
2025-12-15 19:07:49 - models.bert_model - INFO - Epoch 3/10 - Batch 2400/10125 - Loss: 0.2526 - Acc: 91.69% - LR: 1.47e-05
2025-12-15 19:08:03 - models.bert_model - INFO - Epoch 3/10 - Batch 2440/10125 - Loss: 0.2778 - Acc: 91.70% - LR: 1.47e-05
2025-12-15 19:08:17 - models.bert_model - INFO - Epoch 3/10 - Batch 2480/10125 - Loss: 0.1243 - Acc: 91.72% - LR: 1.47e-05
2025-12-15 19:08:32 - models.bert_model - INFO - Epoch 3/10 - Batch 2520/10125 - Loss: 0.4920 - Acc: 91.69% - LR: 1.47e-05
2025-12-15 19:08:46 - models.bert_model - INFO - Epoch 3/10 - Batch 2560/10125 - Loss: 0.3660 - Acc: 91.67% - LR: 1.47e-05
2025-12-15 19:09:01 - models.bert_model - INFO - Epoch 3/10 - Batch 2600/10125 - Loss: 0.2123 - Acc: 91.70% - LR: 1.47e-05
2025-12-15 19:09:16 - models.bert_model - INFO - Epoch 3/10 - Batch 2640/10125 - Loss: 0.1235 - Acc: 91.69% - LR: 1.47e-05
2025-12-15 19:09:30 - models.bert_model - INFO - Epoch 3/10 - Batch 2680/10125 - Loss: 0.1670 - Acc: 91.68% - LR: 1.47e-05
2025-12-15 19:09:45 - models.bert_model - INFO - Epoch 3/10 - Batch 2720/10125 - Loss: 0.4422 - Acc: 91.69% - LR: 1.47e-05
2025-12-15 19:09:59 - models.bert_model - INFO - Epoch 3/10 - Batch 2760/10125 - Loss: 0.1332 - Acc: 91.67% - LR: 1.47e-05
2025-12-15 19:10:14 - models.bert_model - INFO - Epoch 3/10 - Batch 2800/10125 - Loss: 0.2358 - Acc: 91.68% - LR: 1.47e-05
2025-12-15 19:10:28 - models.bert_model - INFO - Epoch 3/10 - Batch 2840/10125 - Loss: 0.1332 - Acc: 91.70% - LR: 1.47e-05
2025-12-15 19:10:43 - models.bert_model - INFO - Epoch 3/10 - Batch 2880/10125 - Loss: 0.3322 - Acc: 91.71% - LR: 1.47e-05
2025-12-15 19:10:57 - models.bert_model - INFO - Epoch 3/10 - Batch 2920/10125 - Loss: 0.3327 - Acc: 91.71% - LR: 1.47e-05
2025-12-15 19:11:12 - models.bert_model - INFO - Epoch 3/10 - Batch 2960/10125 - Loss: 0.2281 - Acc: 91.71% - LR: 1.47e-05
2025-12-15 19:11:27 - models.bert_model - INFO - Epoch 3/10 - Batch 3000/10125 - Loss: 0.2310 - Acc: 91.70% - LR: 1.47e-05
2025-12-15 19:11:41 - models.bert_model - INFO - Epoch 3/10 - Batch 3040/10125 - Loss: 0.2853 - Acc: 91.71% - LR: 1.47e-05
2025-12-15 19:11:55 - models.bert_model - INFO - Epoch 3/10 - Batch 3080/10125 - Loss: 0.1659 - Acc: 91.72% - LR: 1.47e-05
2025-12-15 19:12:10 - models.bert_model - INFO - Epoch 3/10 - Batch 3120/10125 - Loss: 0.5616 - Acc: 91.74% - LR: 1.47e-05
2025-12-15 19:12:24 - models.bert_model - INFO - Epoch 3/10 - Batch 3160/10125 - Loss: 0.2160 - Acc: 91.74% - LR: 1.47e-05
2025-12-15 19:12:39 - models.bert_model - INFO - Epoch 3/10 - Batch 3200/10125 - Loss: 0.2751 - Acc: 91.75% - LR: 1.47e-05
2025-12-15 19:12:53 - models.bert_model - INFO - Epoch 3/10 - Batch 3240/10125 - Loss: 0.2951 - Acc: 91.75% - LR: 1.47e-05
2025-12-15 19:13:08 - models.bert_model - INFO - Epoch 3/10 - Batch 3280/10125 - Loss: 0.3048 - Acc: 91.76% - LR: 1.47e-05
2025-12-15 19:13:23 - models.bert_model - INFO - Epoch 3/10 - Batch 3320/10125 - Loss: 0.1634 - Acc: 91.77% - LR: 1.47e-05
2025-12-15 19:13:37 - models.bert_model - INFO - Epoch 3/10 - Batch 3360/10125 - Loss: 0.2296 - Acc: 91.78% - LR: 1.46e-05
2025-12-15 19:13:51 - models.bert_model - INFO - Epoch 3/10 - Batch 3400/10125 - Loss: 0.3370 - Acc: 91.80% - LR: 1.46e-05
2025-12-15 19:14:06 - models.bert_model - INFO - Epoch 3/10 - Batch 3440/10125 - Loss: 0.2594 - Acc: 91.81% - LR: 1.46e-05
2025-12-15 19:14:21 - models.bert_model - INFO - Epoch 3/10 - Batch 3480/10125 - Loss: 0.3577 - Acc: 91.79% - LR: 1.46e-05
2025-12-15 19:14:35 - models.bert_model - INFO - Epoch 3/10 - Batch 3520/10125 - Loss: 0.4039 - Acc: 91.80% - LR: 1.46e-05
2025-12-15 19:14:50 - models.bert_model - INFO - Epoch 3/10 - Batch 3560/10125 - Loss: 0.2379 - Acc: 91.80% - LR: 1.46e-05
2025-12-15 19:15:04 - models.bert_model - INFO - Epoch 3/10 - Batch 3600/10125 - Loss: 0.3648 - Acc: 91.78% - LR: 1.46e-05
2025-12-15 19:15:19 - models.bert_model - INFO - Epoch 3/10 - Batch 3640/10125 - Loss: 0.4536 - Acc: 91.77% - LR: 1.46e-05
2025-12-15 19:15:33 - models.bert_model - INFO - Epoch 3/10 - Batch 3680/10125 - Loss: 0.3576 - Acc: 91.77% - LR: 1.46e-05
2025-12-15 19:15:48 - models.bert_model - INFO - Epoch 3/10 - Batch 3720/10125 - Loss: 0.3659 - Acc: 91.76% - LR: 1.46e-05
2025-12-15 19:16:02 - models.bert_model - INFO - Epoch 3/10 - Batch 3760/10125 - Loss: 0.1611 - Acc: 91.77% - LR: 1.46e-05
2025-12-15 19:16:17 - models.bert_model - INFO - Epoch 3/10 - Batch 3800/10125 - Loss: 0.3608 - Acc: 91.79% - LR: 1.46e-05
2025-12-15 19:16:31 - models.bert_model - INFO - Epoch 3/10 - Batch 3840/10125 - Loss: 0.1946 - Acc: 91.79% - LR: 1.46e-05
2025-12-15 19:16:46 - models.bert_model - INFO - Epoch 3/10 - Batch 3880/10125 - Loss: 0.1589 - Acc: 91.79% - LR: 1.46e-05
2025-12-15 19:17:00 - models.bert_model - INFO - Epoch 3/10 - Batch 3920/10125 - Loss: 0.1556 - Acc: 91.79% - LR: 1.46e-05
2025-12-15 19:17:15 - models.bert_model - INFO - Epoch 3/10 - Batch 3960/10125 - Loss: 0.4845 - Acc: 91.80% - LR: 1.46e-05
2025-12-15 19:17:29 - models.bert_model - INFO - Epoch 3/10 - Batch 4000/10125 - Loss: 0.1243 - Acc: 91.82% - LR: 1.46e-05
2025-12-15 19:17:44 - models.bert_model - INFO - Epoch 3/10 - Batch 4040/10125 - Loss: 0.3691 - Acc: 91.84% - LR: 1.46e-05
2025-12-15 19:17:58 - models.bert_model - INFO - Epoch 3/10 - Batch 4080/10125 - Loss: 0.2011 - Acc: 91.85% - LR: 1.46e-05
2025-12-15 19:18:13 - models.bert_model - INFO - Epoch 3/10 - Batch 4120/10125 - Loss: 0.2989 - Acc: 91.85% - LR: 1.46e-05
2025-12-15 19:18:28 - models.bert_model - INFO - Epoch 3/10 - Batch 4160/10125 - Loss: 0.4252 - Acc: 91.85% - LR: 1.46e-05
2025-12-15 19:18:42 - models.bert_model - INFO - Epoch 3/10 - Batch 4200/10125 - Loss: 0.2602 - Acc: 91.86% - LR: 1.46e-05
2025-12-15 19:18:57 - models.bert_model - INFO - Epoch 3/10 - Batch 4240/10125 - Loss: 0.1543 - Acc: 91.85% - LR: 1.46e-05
2025-12-15 19:19:11 - models.bert_model - INFO - Epoch 3/10 - Batch 4280/10125 - Loss: 0.6680 - Acc: 91.85% - LR: 1.46e-05
2025-12-15 19:19:26 - models.bert_model - INFO - Epoch 3/10 - Batch 4320/10125 - Loss: 0.3146 - Acc: 91.87% - LR: 1.46e-05
2025-12-15 19:19:40 - models.bert_model - INFO - Epoch 3/10 - Batch 4360/10125 - Loss: 0.3982 - Acc: 91.86% - LR: 1.46e-05
2025-12-15 19:19:55 - models.bert_model - INFO - Epoch 3/10 - Batch 4400/10125 - Loss: 0.2614 - Acc: 91.87% - LR: 1.46e-05
2025-12-15 19:20:09 - models.bert_model - INFO - Epoch 3/10 - Batch 4440/10125 - Loss: 0.1256 - Acc: 91.89% - LR: 1.46e-05
2025-12-15 19:20:24 - models.bert_model - INFO - Epoch 3/10 - Batch 4480/10125 - Loss: 0.1135 - Acc: 91.91% - LR: 1.45e-05
2025-12-15 19:20:38 - models.bert_model - INFO - Epoch 3/10 - Batch 4520/10125 - Loss: 0.1683 - Acc: 91.91% - LR: 1.45e-05
2025-12-15 19:20:53 - models.bert_model - INFO - Epoch 3/10 - Batch 4560/10125 - Loss: 0.4166 - Acc: 91.89% - LR: 1.45e-05
2025-12-15 19:21:07 - models.bert_model - INFO - Epoch 3/10 - Batch 4600/10125 - Loss: 0.3203 - Acc: 91.89% - LR: 1.45e-05
2025-12-15 19:21:22 - models.bert_model - INFO - Epoch 3/10 - Batch 4640/10125 - Loss: 0.2533 - Acc: 91.89% - LR: 1.45e-05
2025-12-15 19:21:36 - models.bert_model - INFO - Epoch 3/10 - Batch 4680/10125 - Loss: 0.4564 - Acc: 91.89% - LR: 1.45e-05
2025-12-15 19:21:51 - models.bert_model - INFO - Epoch 3/10 - Batch 4720/10125 - Loss: 0.5463 - Acc: 91.88% - LR: 1.45e-05
2025-12-15 19:22:05 - models.bert_model - INFO - Epoch 3/10 - Batch 4760/10125 - Loss: 0.1525 - Acc: 91.87% - LR: 1.45e-05
2025-12-15 19:22:20 - models.bert_model - INFO - Epoch 3/10 - Batch 4800/10125 - Loss: 0.1668 - Acc: 91.88% - LR: 1.45e-05
2025-12-15 19:22:35 - models.bert_model - INFO - Epoch 3/10 - Batch 4840/10125 - Loss: 0.1370 - Acc: 91.87% - LR: 1.45e-05
2025-12-15 19:22:49 - models.bert_model - INFO - Epoch 3/10 - Batch 4880/10125 - Loss: 0.1680 - Acc: 91.88% - LR: 1.45e-05
2025-12-15 19:23:04 - models.bert_model - INFO - Epoch 3/10 - Batch 4920/10125 - Loss: 0.1621 - Acc: 91.87% - LR: 1.45e-05
2025-12-15 19:23:18 - models.bert_model - INFO - Epoch 3/10 - Batch 4960/10125 - Loss: 0.2507 - Acc: 91.87% - LR: 1.45e-05
2025-12-15 19:23:33 - models.bert_model - INFO - Epoch 3/10 - Batch 5000/10125 - Loss: 0.1787 - Acc: 91.88% - LR: 1.45e-05
2025-12-15 19:23:47 - models.bert_model - INFO - Epoch 3/10 - Batch 5040/10125 - Loss: 0.2017 - Acc: 91.88% - LR: 1.45e-05
2025-12-15 19:24:02 - models.bert_model - INFO - Epoch 3/10 - Batch 5080/10125 - Loss: 0.1301 - Acc: 91.88% - LR: 1.45e-05
2025-12-15 19:24:16 - models.bert_model - INFO - Epoch 3/10 - Batch 5120/10125 - Loss: 0.7161 - Acc: 91.88% - LR: 1.45e-05
2025-12-15 19:24:31 - models.bert_model - INFO - Epoch 3/10 - Batch 5160/10125 - Loss: 0.1658 - Acc: 91.90% - LR: 1.45e-05
2025-12-15 19:24:46 - models.bert_model - INFO - Epoch 3/10 - Batch 5200/10125 - Loss: 0.1148 - Acc: 91.89% - LR: 1.45e-05
2025-12-15 19:25:00 - models.bert_model - INFO - Epoch 3/10 - Batch 5240/10125 - Loss: 0.1902 - Acc: 91.89% - LR: 1.45e-05
2025-12-15 19:25:14 - models.bert_model - INFO - Epoch 3/10 - Batch 5280/10125 - Loss: 0.1608 - Acc: 91.88% - LR: 1.45e-05
2025-12-15 19:25:29 - models.bert_model - INFO - Epoch 3/10 - Batch 5320/10125 - Loss: 0.2511 - Acc: 91.89% - LR: 1.45e-05
2025-12-15 19:25:43 - models.bert_model - INFO - Epoch 3/10 - Batch 5360/10125 - Loss: 0.1227 - Acc: 91.91% - LR: 1.45e-05
2025-12-15 19:25:58 - models.bert_model - INFO - Epoch 3/10 - Batch 5400/10125 - Loss: 0.3540 - Acc: 91.90% - LR: 1.45e-05
2025-12-15 19:26:12 - models.bert_model - INFO - Epoch 3/10 - Batch 5440/10125 - Loss: 0.2080 - Acc: 91.90% - LR: 1.45e-05
2025-12-15 19:26:27 - models.bert_model - INFO - Epoch 3/10 - Batch 5480/10125 - Loss: 0.2094 - Acc: 91.92% - LR: 1.45e-05
2025-12-15 19:26:41 - models.bert_model - INFO - Epoch 3/10 - Batch 5520/10125 - Loss: 0.1577 - Acc: 91.92% - LR: 1.44e-05
2025-12-15 19:26:56 - models.bert_model - INFO - Epoch 3/10 - Batch 5560/10125 - Loss: 0.3950 - Acc: 91.92% - LR: 1.44e-05
2025-12-15 19:27:10 - models.bert_model - INFO - Epoch 3/10 - Batch 5600/10125 - Loss: 0.2282 - Acc: 91.93% - LR: 1.44e-05
2025-12-15 19:27:25 - models.bert_model - INFO - Epoch 3/10 - Batch 5640/10125 - Loss: 0.1380 - Acc: 91.93% - LR: 1.44e-05
2025-12-15 19:27:40 - models.bert_model - INFO - Epoch 3/10 - Batch 5680/10125 - Loss: 0.1417 - Acc: 91.93% - LR: 1.44e-05
2025-12-15 19:27:54 - models.bert_model - INFO - Epoch 3/10 - Batch 5720/10125 - Loss: 0.1749 - Acc: 91.93% - LR: 1.44e-05
2025-12-15 19:28:09 - models.bert_model - INFO - Epoch 3/10 - Batch 5760/10125 - Loss: 0.1749 - Acc: 91.92% - LR: 1.44e-05
2025-12-15 19:28:23 - models.bert_model - INFO - Epoch 3/10 - Batch 5800/10125 - Loss: 0.2328 - Acc: 91.92% - LR: 1.44e-05
2025-12-15 19:28:38 - models.bert_model - INFO - Epoch 3/10 - Batch 5840/10125 - Loss: 0.1679 - Acc: 91.93% - LR: 1.44e-05
2025-12-15 19:28:52 - models.bert_model - INFO - Epoch 3/10 - Batch 5880/10125 - Loss: 0.3439 - Acc: 91.92% - LR: 1.44e-05
2025-12-15 19:29:07 - models.bert_model - INFO - Epoch 3/10 - Batch 5920/10125 - Loss: 0.2450 - Acc: 91.92% - LR: 1.44e-05
2025-12-15 19:29:21 - models.bert_model - INFO - Epoch 3/10 - Batch 5960/10125 - Loss: 0.1756 - Acc: 91.91% - LR: 1.44e-05
2025-12-15 19:29:36 - models.bert_model - INFO - Epoch 3/10 - Batch 6000/10125 - Loss: 0.2155 - Acc: 91.92% - LR: 1.44e-05
2025-12-15 19:29:50 - models.bert_model - INFO - Epoch 3/10 - Batch 6040/10125 - Loss: 0.1988 - Acc: 91.92% - LR: 1.44e-05
2025-12-15 19:30:05 - models.bert_model - INFO - Epoch 3/10 - Batch 6080/10125 - Loss: 0.1359 - Acc: 91.93% - LR: 1.44e-05
2025-12-15 19:30:20 - models.bert_model - INFO - Epoch 3/10 - Batch 6120/10125 - Loss: 0.1508 - Acc: 91.94% - LR: 1.44e-05
2025-12-15 19:30:34 - models.bert_model - INFO - Epoch 3/10 - Batch 6160/10125 - Loss: 0.3931 - Acc: 91.94% - LR: 1.44e-05
2025-12-15 19:30:49 - models.bert_model - INFO - Epoch 3/10 - Batch 6200/10125 - Loss: 0.3016 - Acc: 91.93% - LR: 1.44e-05
2025-12-15 19:31:03 - models.bert_model - INFO - Epoch 3/10 - Batch 6240/10125 - Loss: 0.1809 - Acc: 91.94% - LR: 1.44e-05
2025-12-15 19:31:18 - models.bert_model - INFO - Epoch 3/10 - Batch 6280/10125 - Loss: 0.3551 - Acc: 91.94% - LR: 1.44e-05
2025-12-15 19:31:32 - models.bert_model - INFO - Epoch 3/10 - Batch 6320/10125 - Loss: 0.1164 - Acc: 91.95% - LR: 1.44e-05
2025-12-15 19:31:47 - models.bert_model - INFO - Epoch 3/10 - Batch 6360/10125 - Loss: 0.1544 - Acc: 91.95% - LR: 1.44e-05
2025-12-15 19:32:01 - models.bert_model - INFO - Epoch 3/10 - Batch 6400/10125 - Loss: 0.2997 - Acc: 91.94% - LR: 1.44e-05
2025-12-15 19:32:16 - models.bert_model - INFO - Epoch 3/10 - Batch 6440/10125 - Loss: 0.1548 - Acc: 91.95% - LR: 1.43e-05
2025-12-15 19:32:30 - models.bert_model - INFO - Epoch 3/10 - Batch 6480/10125 - Loss: 0.2801 - Acc: 91.94% - LR: 1.43e-05
2025-12-15 19:32:45 - models.bert_model - INFO - Epoch 3/10 - Batch 6520/10125 - Loss: 0.1173 - Acc: 91.95% - LR: 1.43e-05
2025-12-15 19:32:59 - models.bert_model - INFO - Epoch 3/10 - Batch 6560/10125 - Loss: 0.1854 - Acc: 91.97% - LR: 1.43e-05
2025-12-15 19:33:14 - models.bert_model - INFO - Epoch 3/10 - Batch 6600/10125 - Loss: 0.2184 - Acc: 91.97% - LR: 1.43e-05
2025-12-15 19:33:28 - models.bert_model - INFO - Epoch 3/10 - Batch 6640/10125 - Loss: 0.3767 - Acc: 91.98% - LR: 1.43e-05
2025-12-15 19:33:43 - models.bert_model - INFO - Epoch 3/10 - Batch 6680/10125 - Loss: 0.1453 - Acc: 91.99% - LR: 1.43e-05
2025-12-15 19:33:57 - models.bert_model - INFO - Epoch 3/10 - Batch 6720/10125 - Loss: 0.1130 - Acc: 91.99% - LR: 1.43e-05
2025-12-15 19:34:12 - models.bert_model - INFO - Epoch 3/10 - Batch 6760/10125 - Loss: 0.1758 - Acc: 91.99% - LR: 1.43e-05
2025-12-15 19:34:26 - models.bert_model - INFO - Epoch 3/10 - Batch 6800/10125 - Loss: 0.2888 - Acc: 91.99% - LR: 1.43e-05
2025-12-15 19:34:41 - models.bert_model - INFO - Epoch 3/10 - Batch 6840/10125 - Loss: 0.1845 - Acc: 91.99% - LR: 1.43e-05
2025-12-15 19:34:55 - models.bert_model - INFO - Epoch 3/10 - Batch 6880/10125 - Loss: 0.1668 - Acc: 92.00% - LR: 1.43e-05
2025-12-15 19:35:10 - models.bert_model - INFO - Epoch 3/10 - Batch 6920/10125 - Loss: 0.1383 - Acc: 92.00% - LR: 1.43e-05
2025-12-15 19:35:24 - models.bert_model - INFO - Epoch 3/10 - Batch 6960/10125 - Loss: 0.2528 - Acc: 92.00% - LR: 1.43e-05
2025-12-15 19:35:39 - models.bert_model - INFO - Epoch 3/10 - Batch 7000/10125 - Loss: 0.2883 - Acc: 92.00% - LR: 1.43e-05
2025-12-15 19:35:54 - models.bert_model - INFO - Epoch 3/10 - Batch 7040/10125 - Loss: 0.2482 - Acc: 92.00% - LR: 1.43e-05
2025-12-15 19:36:08 - models.bert_model - INFO - Epoch 3/10 - Batch 7080/10125 - Loss: 0.1106 - Acc: 92.02% - LR: 1.43e-05
2025-12-15 19:36:23 - models.bert_model - INFO - Epoch 3/10 - Batch 7120/10125 - Loss: 0.1318 - Acc: 92.03% - LR: 1.43e-05
2025-12-15 19:36:37 - models.bert_model - INFO - Epoch 3/10 - Batch 7160/10125 - Loss: 0.1212 - Acc: 92.03% - LR: 1.43e-05
2025-12-15 19:36:52 - models.bert_model - INFO - Epoch 3/10 - Batch 7200/10125 - Loss: 0.2039 - Acc: 92.02% - LR: 1.43e-05
2025-12-15 19:37:06 - models.bert_model - INFO - Epoch 3/10 - Batch 7240/10125 - Loss: 0.1856 - Acc: 92.01% - LR: 1.43e-05
2025-12-15 19:37:21 - models.bert_model - INFO - Epoch 3/10 - Batch 7280/10125 - Loss: 0.2191 - Acc: 92.01% - LR: 1.43e-05
2025-12-15 19:37:35 - models.bert_model - INFO - Epoch 3/10 - Batch 7320/10125 - Loss: 0.1602 - Acc: 92.02% - LR: 1.42e-05
2025-12-15 19:37:50 - models.bert_model - INFO - Epoch 3/10 - Batch 7360/10125 - Loss: 0.5763 - Acc: 92.03% - LR: 1.42e-05
2025-12-15 19:38:04 - models.bert_model - INFO - Epoch 3/10 - Batch 7400/10125 - Loss: 0.4696 - Acc: 92.02% - LR: 1.42e-05
2025-12-15 19:38:19 - models.bert_model - INFO - Epoch 3/10 - Batch 7440/10125 - Loss: 0.1367 - Acc: 92.03% - LR: 1.42e-05
2025-12-15 19:38:33 - models.bert_model - INFO - Epoch 3/10 - Batch 7480/10125 - Loss: 0.2019 - Acc: 92.04% - LR: 1.42e-05
2025-12-15 19:38:48 - models.bert_model - INFO - Epoch 3/10 - Batch 7520/10125 - Loss: 0.1783 - Acc: 92.05% - LR: 1.42e-05
2025-12-15 19:39:02 - models.bert_model - INFO - Epoch 3/10 - Batch 7560/10125 - Loss: 0.1237 - Acc: 92.05% - LR: 1.42e-05
2025-12-15 19:39:17 - models.bert_model - INFO - Epoch 3/10 - Batch 7600/10125 - Loss: 0.2034 - Acc: 92.06% - LR: 1.42e-05
2025-12-15 19:39:31 - models.bert_model - INFO - Epoch 3/10 - Batch 7640/10125 - Loss: 0.1521 - Acc: 92.06% - LR: 1.42e-05
2025-12-15 19:39:46 - models.bert_model - INFO - Epoch 3/10 - Batch 7680/10125 - Loss: 0.1734 - Acc: 92.06% - LR: 1.42e-05
2025-12-15 19:40:01 - models.bert_model - INFO - Epoch 3/10 - Batch 7720/10125 - Loss: 0.2509 - Acc: 92.06% - LR: 1.42e-05
2025-12-15 19:40:15 - models.bert_model - INFO - Epoch 3/10 - Batch 7760/10125 - Loss: 0.1703 - Acc: 92.06% - LR: 1.42e-05
2025-12-15 19:40:30 - models.bert_model - INFO - Epoch 3/10 - Batch 7800/10125 - Loss: 0.3691 - Acc: 92.06% - LR: 1.42e-05
2025-12-15 19:40:44 - models.bert_model - INFO - Epoch 3/10 - Batch 7840/10125 - Loss: 0.1303 - Acc: 92.07% - LR: 1.42e-05
2025-12-15 19:40:59 - models.bert_model - INFO - Epoch 3/10 - Batch 7880/10125 - Loss: 0.5649 - Acc: 92.07% - LR: 1.42e-05
2025-12-15 19:41:13 - models.bert_model - INFO - Epoch 3/10 - Batch 7920/10125 - Loss: 0.1189 - Acc: 92.08% - LR: 1.42e-05
2025-12-15 19:41:28 - models.bert_model - INFO - Epoch 3/10 - Batch 7960/10125 - Loss: 0.3548 - Acc: 92.08% - LR: 1.42e-05
2025-12-15 19:41:42 - models.bert_model - INFO - Epoch 3/10 - Batch 8000/10125 - Loss: 0.4467 - Acc: 92.08% - LR: 1.42e-05
2025-12-15 19:41:57 - models.bert_model - INFO - Epoch 3/10 - Batch 8040/10125 - Loss: 0.1492 - Acc: 92.09% - LR: 1.42e-05
2025-12-15 19:42:11 - models.bert_model - INFO - Epoch 3/10 - Batch 8080/10125 - Loss: 0.3721 - Acc: 92.09% - LR: 1.42e-05
2025-12-15 19:42:26 - models.bert_model - INFO - Epoch 3/10 - Batch 8120/10125 - Loss: 0.2153 - Acc: 92.10% - LR: 1.41e-05
2025-12-15 19:42:41 - models.bert_model - INFO - Epoch 3/10 - Batch 8160/10125 - Loss: 0.1521 - Acc: 92.10% - LR: 1.41e-05
2025-12-15 19:42:55 - models.bert_model - INFO - Epoch 3/10 - Batch 8200/10125 - Loss: 0.3685 - Acc: 92.10% - LR: 1.41e-05
2025-12-15 19:43:10 - models.bert_model - INFO - Epoch 3/10 - Batch 8240/10125 - Loss: 0.2094 - Acc: 92.11% - LR: 1.41e-05
2025-12-15 19:43:24 - models.bert_model - INFO - Epoch 3/10 - Batch 8280/10125 - Loss: 0.2110 - Acc: 92.12% - LR: 1.41e-05
2025-12-15 19:43:39 - models.bert_model - INFO - Epoch 3/10 - Batch 8320/10125 - Loss: 0.2361 - Acc: 92.12% - LR: 1.41e-05
2025-12-15 19:43:53 - models.bert_model - INFO - Epoch 3/10 - Batch 8360/10125 - Loss: 0.3824 - Acc: 92.13% - LR: 1.41e-05
2025-12-15 19:44:08 - models.bert_model - INFO - Epoch 3/10 - Batch 8400/10125 - Loss: 0.1308 - Acc: 92.14% - LR: 1.41e-05
2025-12-15 19:44:22 - models.bert_model - INFO - Epoch 3/10 - Batch 8440/10125 - Loss: 0.1694 - Acc: 92.14% - LR: 1.41e-05
2025-12-15 19:44:37 - models.bert_model - INFO - Epoch 3/10 - Batch 8480/10125 - Loss: 0.3268 - Acc: 92.14% - LR: 1.41e-05
2025-12-15 19:44:51 - models.bert_model - INFO - Epoch 3/10 - Batch 8520/10125 - Loss: 0.2336 - Acc: 92.14% - LR: 1.41e-05
2025-12-15 19:45:06 - models.bert_model - INFO - Epoch 3/10 - Batch 8560/10125 - Loss: 0.1896 - Acc: 92.14% - LR: 1.41e-05
2025-12-15 19:45:20 - models.bert_model - INFO - Epoch 3/10 - Batch 8600/10125 - Loss: 0.2686 - Acc: 92.13% - LR: 1.41e-05
2025-12-15 19:45:35 - models.bert_model - INFO - Epoch 3/10 - Batch 8640/10125 - Loss: 0.3235 - Acc: 92.13% - LR: 1.41e-05
2025-12-15 19:45:50 - models.bert_model - INFO - Epoch 3/10 - Batch 8680/10125 - Loss: 0.1289 - Acc: 92.14% - LR: 1.41e-05
2025-12-15 19:46:04 - models.bert_model - INFO - Epoch 3/10 - Batch 8720/10125 - Loss: 0.3700 - Acc: 92.14% - LR: 1.41e-05
2025-12-15 19:46:19 - models.bert_model - INFO - Epoch 3/10 - Batch 8760/10125 - Loss: 0.4626 - Acc: 92.15% - LR: 1.41e-05
2025-12-15 19:46:33 - models.bert_model - INFO - Epoch 3/10 - Batch 8800/10125 - Loss: 0.2836 - Acc: 92.14% - LR: 1.41e-05
2025-12-15 19:46:48 - models.bert_model - INFO - Epoch 3/10 - Batch 8840/10125 - Loss: 0.1439 - Acc: 92.15% - LR: 1.41e-05
2025-12-15 19:47:02 - models.bert_model - INFO - Epoch 3/10 - Batch 8880/10125 - Loss: 0.2166 - Acc: 92.15% - LR: 1.40e-05
2025-12-15 19:47:17 - models.bert_model - INFO - Epoch 3/10 - Batch 8920/10125 - Loss: 0.2162 - Acc: 92.15% - LR: 1.40e-05
2025-12-15 19:47:31 - models.bert_model - INFO - Epoch 3/10 - Batch 8960/10125 - Loss: 0.2772 - Acc: 92.15% - LR: 1.40e-05
2025-12-15 19:47:46 - models.bert_model - INFO - Epoch 3/10 - Batch 9000/10125 - Loss: 0.4588 - Acc: 92.16% - LR: 1.40e-05
2025-12-15 19:48:00 - models.bert_model - INFO - Epoch 3/10 - Batch 9040/10125 - Loss: 0.3855 - Acc: 92.16% - LR: 1.40e-05
2025-12-15 19:48:15 - models.bert_model - INFO - Epoch 3/10 - Batch 9080/10125 - Loss: 0.3946 - Acc: 92.16% - LR: 1.40e-05
2025-12-15 19:48:29 - models.bert_model - INFO - Epoch 3/10 - Batch 9120/10125 - Loss: 0.3705 - Acc: 92.17% - LR: 1.40e-05
2025-12-15 19:48:44 - models.bert_model - INFO - Epoch 3/10 - Batch 9160/10125 - Loss: 0.1386 - Acc: 92.17% - LR: 1.40e-05
2025-12-15 19:48:58 - models.bert_model - INFO - Epoch 3/10 - Batch 9200/10125 - Loss: 0.1650 - Acc: 92.17% - LR: 1.40e-05
2025-12-15 19:49:13 - models.bert_model - INFO - Epoch 3/10 - Batch 9240/10125 - Loss: 0.1783 - Acc: 92.18% - LR: 1.40e-05
2025-12-15 19:49:27 - models.bert_model - INFO - Epoch 3/10 - Batch 9280/10125 - Loss: 0.4431 - Acc: 92.18% - LR: 1.40e-05
2025-12-15 19:49:42 - models.bert_model - INFO - Epoch 3/10 - Batch 9320/10125 - Loss: 0.1871 - Acc: 92.18% - LR: 1.40e-05
2025-12-15 19:49:56 - models.bert_model - INFO - Epoch 3/10 - Batch 9360/10125 - Loss: 0.1688 - Acc: 92.19% - LR: 1.40e-05
2025-12-15 19:50:11 - models.bert_model - INFO - Epoch 3/10 - Batch 9400/10125 - Loss: 0.4427 - Acc: 92.20% - LR: 1.40e-05
2025-12-15 19:50:26 - models.bert_model - INFO - Epoch 3/10 - Batch 9440/10125 - Loss: 0.1626 - Acc: 92.21% - LR: 1.40e-05
2025-12-15 19:50:40 - models.bert_model - INFO - Epoch 3/10 - Batch 9480/10125 - Loss: 0.3785 - Acc: 92.21% - LR: 1.40e-05
2025-12-15 19:50:55 - models.bert_model - INFO - Epoch 3/10 - Batch 9520/10125 - Loss: 0.4332 - Acc: 92.21% - LR: 1.40e-05
2025-12-15 19:51:09 - models.bert_model - INFO - Epoch 3/10 - Batch 9560/10125 - Loss: 0.1939 - Acc: 92.21% - LR: 1.40e-05
2025-12-15 19:51:24 - models.bert_model - INFO - Epoch 3/10 - Batch 9600/10125 - Loss: 0.2668 - Acc: 92.21% - LR: 1.40e-05
2025-12-15 19:51:38 - models.bert_model - INFO - Epoch 3/10 - Batch 9640/10125 - Loss: 0.1755 - Acc: 92.22% - LR: 1.39e-05
2025-12-15 19:51:53 - models.bert_model - INFO - Epoch 3/10 - Batch 9680/10125 - Loss: 0.2255 - Acc: 92.22% - LR: 1.39e-05
2025-12-15 19:52:07 - models.bert_model - INFO - Epoch 3/10 - Batch 9720/10125 - Loss: 0.5196 - Acc: 92.22% - LR: 1.39e-05
2025-12-15 19:52:22 - models.bert_model - INFO - Epoch 3/10 - Batch 9760/10125 - Loss: 0.4862 - Acc: 92.22% - LR: 1.39e-05
2025-12-15 19:52:36 - models.bert_model - INFO - Epoch 3/10 - Batch 9800/10125 - Loss: 0.1469 - Acc: 92.22% - LR: 1.39e-05
2025-12-15 19:52:51 - models.bert_model - INFO - Epoch 3/10 - Batch 9840/10125 - Loss: 0.3591 - Acc: 92.23% - LR: 1.39e-05
2025-12-15 19:53:05 - models.bert_model - INFO - Epoch 3/10 - Batch 9880/10125 - Loss: 0.2251 - Acc: 92.24% - LR: 1.39e-05
2025-12-15 19:53:20 - models.bert_model - INFO - Epoch 3/10 - Batch 9920/10125 - Loss: 0.3323 - Acc: 92.24% - LR: 1.39e-05
2025-12-15 19:53:34 - models.bert_model - INFO - Epoch 3/10 - Batch 9960/10125 - Loss: 0.1381 - Acc: 92.25% - LR: 1.39e-05
2025-12-15 19:53:49 - models.bert_model - INFO - Epoch 3/10 - Batch 10000/10125 - Loss: 0.1296 - Acc: 92.24% - LR: 1.39e-05
2025-12-15 19:54:03 - models.bert_model - INFO - Epoch 3/10 - Batch 10040/10125 - Loss: 0.2417 - Acc: 92.24% - LR: 1.39e-05
2025-12-15 19:54:18 - models.bert_model - INFO - Epoch 3/10 - Batch 10080/10125 - Loss: 0.1131 - Acc: 92.25% - LR: 1.39e-05
2025-12-15 19:54:32 - models.bert_model - INFO - Epoch 3/10 - Batch 10120/10125 - Loss: 0.1215 - Acc: 92.24% - LR: 1.39e-05
2025-12-15 19:56:51 - models.bert_model - INFO - Epoch 3/10 - Train Loss: 0.2743, Train Acc: 92.24% - Val Loss: 0.2399, Val Acc: 93.65%
2025-12-15 19:56:51 - models.bert_model - INFO - New best validation accuracy: 93.65%
2025-12-15 19:57:05 - models.bert_model - INFO - Epoch 4/10 - Batch 40/10125 - Loss: 0.3220 - Acc: 94.06% - LR: 1.39e-05
2025-12-15 19:57:20 - models.bert_model - INFO - Epoch 4/10 - Batch 80/10125 - Loss: 0.1615 - Acc: 93.75% - LR: 1.39e-05
2025-12-15 19:57:34 - models.bert_model - INFO - Epoch 4/10 - Batch 120/10125 - Loss: 0.1453 - Acc: 93.91% - LR: 1.39e-05
2025-12-15 19:57:49 - models.bert_model - INFO - Epoch 4/10 - Batch 160/10125 - Loss: 0.2383 - Acc: 93.52% - LR: 1.39e-05
2025-12-15 19:58:03 - models.bert_model - INFO - Epoch 4/10 - Batch 200/10125 - Loss: 0.1419 - Acc: 93.00% - LR: 1.38e-05
2025-12-15 19:58:18 - models.bert_model - INFO - Epoch 4/10 - Batch 240/10125 - Loss: 0.4777 - Acc: 93.07% - LR: 1.38e-05
2025-12-15 19:58:32 - models.bert_model - INFO - Epoch 4/10 - Batch 280/10125 - Loss: 0.1598 - Acc: 92.97% - LR: 1.38e-05
2025-12-15 19:58:47 - models.bert_model - INFO - Epoch 4/10 - Batch 320/10125 - Loss: 0.1162 - Acc: 93.18% - LR: 1.38e-05
2025-12-15 19:59:01 - models.bert_model - INFO - Epoch 4/10 - Batch 360/10125 - Loss: 0.2645 - Acc: 93.19% - LR: 1.38e-05
2025-12-15 19:59:16 - models.bert_model - INFO - Epoch 4/10 - Batch 400/10125 - Loss: 0.1311 - Acc: 93.36% - LR: 1.38e-05
2025-12-15 19:59:30 - models.bert_model - INFO - Epoch 4/10 - Batch 440/10125 - Loss: 0.1293 - Acc: 93.35% - LR: 1.38e-05
2025-12-15 19:59:45 - models.bert_model - INFO - Epoch 4/10 - Batch 480/10125 - Loss: 0.1201 - Acc: 93.41% - LR: 1.38e-05
2025-12-15 19:59:59 - models.bert_model - INFO - Epoch 4/10 - Batch 520/10125 - Loss: 0.2459 - Acc: 93.19% - LR: 1.38e-05
2025-12-15 20:00:14 - models.bert_model - INFO - Epoch 4/10 - Batch 560/10125 - Loss: 0.1377 - Acc: 93.14% - LR: 1.38e-05
2025-12-15 20:00:28 - models.bert_model - INFO - Epoch 4/10 - Batch 600/10125 - Loss: 0.1107 - Acc: 93.11% - LR: 1.38e-05
2025-12-15 20:00:43 - models.bert_model - INFO - Epoch 4/10 - Batch 640/10125 - Loss: 0.1548 - Acc: 93.12% - LR: 1.38e-05
2025-12-15 20:00:57 - models.bert_model - INFO - Epoch 4/10 - Batch 680/10125 - Loss: 0.2948 - Acc: 93.07% - LR: 1.38e-05
2025-12-15 20:01:12 - models.bert_model - INFO - Epoch 4/10 - Batch 720/10125 - Loss: 0.1758 - Acc: 93.06% - LR: 1.38e-05
2025-12-15 20:01:27 - models.bert_model - INFO - Epoch 4/10 - Batch 760/10125 - Loss: 0.2087 - Acc: 93.08% - LR: 1.38e-05
2025-12-15 20:01:41 - models.bert_model - INFO - Epoch 4/10 - Batch 800/10125 - Loss: 0.1343 - Acc: 93.17% - LR: 1.38e-05
2025-12-15 20:01:56 - models.bert_model - INFO - Epoch 4/10 - Batch 840/10125 - Loss: 0.1119 - Acc: 93.20% - LR: 1.38e-05
2025-12-15 20:02:10 - models.bert_model - INFO - Epoch 4/10 - Batch 880/10125 - Loss: 0.1258 - Acc: 93.24% - LR: 1.37e-05
2025-12-15 20:02:25 - models.bert_model - INFO - Epoch 4/10 - Batch 920/10125 - Loss: 0.2475 - Acc: 93.20% - LR: 1.37e-05
2025-12-15 20:02:39 - models.bert_model - INFO - Epoch 4/10 - Batch 960/10125 - Loss: 0.2102 - Acc: 93.16% - LR: 1.37e-05
2025-12-15 20:02:54 - models.bert_model - INFO - Epoch 4/10 - Batch 1000/10125 - Loss: 0.1609 - Acc: 93.16% - LR: 1.37e-05
2025-12-15 20:03:08 - models.bert_model - INFO - Epoch 4/10 - Batch 1040/10125 - Loss: 0.1594 - Acc: 93.08% - LR: 1.37e-05
2025-12-15 20:03:23 - models.bert_model - INFO - Epoch 4/10 - Batch 1080/10125 - Loss: 0.1508 - Acc: 93.04% - LR: 1.37e-05
2025-12-15 20:03:37 - models.bert_model - INFO - Epoch 4/10 - Batch 1120/10125 - Loss: 0.1897 - Acc: 93.05% - LR: 1.37e-05
2025-12-15 20:03:52 - models.bert_model - INFO - Epoch 4/10 - Batch 1160/10125 - Loss: 0.1925 - Acc: 93.07% - LR: 1.37e-05
2025-12-15 20:04:06 - models.bert_model - INFO - Epoch 4/10 - Batch 1200/10125 - Loss: 0.2549 - Acc: 93.02% - LR: 1.37e-05
2025-12-15 20:04:21 - models.bert_model - INFO - Epoch 4/10 - Batch 1240/10125 - Loss: 0.4102 - Acc: 93.03% - LR: 1.37e-05
2025-12-15 20:04:35 - models.bert_model - INFO - Epoch 4/10 - Batch 1280/10125 - Loss: 0.1686 - Acc: 93.04% - LR: 1.37e-05
2025-12-15 20:04:50 - models.bert_model - INFO - Epoch 4/10 - Batch 1320/10125 - Loss: 0.2069 - Acc: 93.04% - LR: 1.37e-05
2025-12-15 20:05:05 - models.bert_model - INFO - Epoch 4/10 - Batch 1360/10125 - Loss: 0.1422 - Acc: 93.05% - LR: 1.37e-05
2025-12-15 20:05:19 - models.bert_model - INFO - Epoch 4/10 - Batch 1400/10125 - Loss: 0.1972 - Acc: 93.06% - LR: 1.37e-05
2025-12-15 20:05:34 - models.bert_model - INFO - Epoch 4/10 - Batch 1440/10125 - Loss: 0.3891 - Acc: 93.01% - LR: 1.37e-05
2025-12-15 20:05:48 - models.bert_model - INFO - Epoch 4/10 - Batch 1480/10125 - Loss: 0.1834 - Acc: 92.99% - LR: 1.37e-05
2025-12-15 20:06:03 - models.bert_model - INFO - Epoch 4/10 - Batch 1520/10125 - Loss: 0.3253 - Acc: 93.02% - LR: 1.36e-05
2025-12-15 20:06:17 - models.bert_model - INFO - Epoch 4/10 - Batch 1560/10125 - Loss: 0.3369 - Acc: 93.02% - LR: 1.36e-05
2025-12-15 20:06:32 - models.bert_model - INFO - Epoch 4/10 - Batch 1600/10125 - Loss: 0.3180 - Acc: 93.02% - LR: 1.36e-05
2025-12-15 20:06:46 - models.bert_model - INFO - Epoch 4/10 - Batch 1640/10125 - Loss: 0.2102 - Acc: 93.05% - LR: 1.36e-05
2025-12-15 20:07:01 - models.bert_model - INFO - Epoch 4/10 - Batch 1680/10125 - Loss: 0.1918 - Acc: 93.04% - LR: 1.36e-05
2025-12-15 20:07:15 - models.bert_model - INFO - Epoch 4/10 - Batch 1720/10125 - Loss: 0.2810 - Acc: 93.07% - LR: 1.36e-05
2025-12-15 20:07:30 - models.bert_model - INFO - Epoch 4/10 - Batch 1760/10125 - Loss: 0.3468 - Acc: 93.08% - LR: 1.36e-05
2025-12-15 20:07:44 - models.bert_model - INFO - Epoch 4/10 - Batch 1800/10125 - Loss: 0.1635 - Acc: 93.09% - LR: 1.36e-05
2025-12-15 20:07:59 - models.bert_model - INFO - Epoch 4/10 - Batch 1840/10125 - Loss: 0.1509 - Acc: 93.06% - LR: 1.36e-05
2025-12-15 20:08:13 - models.bert_model - INFO - Epoch 4/10 - Batch 1880/10125 - Loss: 0.2599 - Acc: 93.08% - LR: 1.36e-05
2025-12-15 20:08:28 - models.bert_model - INFO - Epoch 4/10 - Batch 1920/10125 - Loss: 0.1215 - Acc: 93.06% - LR: 1.36e-05
2025-12-15 20:08:42 - models.bert_model - INFO - Epoch 4/10 - Batch 1960/10125 - Loss: 0.1473 - Acc: 93.05% - LR: 1.36e-05
2025-12-15 20:08:57 - models.bert_model - INFO - Epoch 4/10 - Batch 2000/10125 - Loss: 0.3266 - Acc: 93.06% - LR: 1.36e-05
2025-12-15 20:09:11 - models.bert_model - INFO - Epoch 4/10 - Batch 2040/10125 - Loss: 0.3038 - Acc: 93.05% - LR: 1.36e-05
2025-12-15 20:09:26 - models.bert_model - INFO - Epoch 4/10 - Batch 2080/10125 - Loss: 0.1350 - Acc: 93.08% - LR: 1.36e-05
2025-12-15 20:09:40 - models.bert_model - INFO - Epoch 4/10 - Batch 2120/10125 - Loss: 0.1898 - Acc: 93.09% - LR: 1.36e-05
2025-12-15 20:09:55 - models.bert_model - INFO - Epoch 4/10 - Batch 2160/10125 - Loss: 0.1920 - Acc: 93.13% - LR: 1.35e-05
2025-12-15 20:10:10 - models.bert_model - INFO - Epoch 4/10 - Batch 2200/10125 - Loss: 0.4155 - Acc: 93.15% - LR: 1.35e-05
2025-12-15 20:10:24 - models.bert_model - INFO - Epoch 4/10 - Batch 2240/10125 - Loss: 0.4201 - Acc: 93.18% - LR: 1.35e-05
2025-12-15 20:10:39 - models.bert_model - INFO - Epoch 4/10 - Batch 2280/10125 - Loss: 0.1211 - Acc: 93.17% - LR: 1.35e-05
2025-12-15 20:10:53 - models.bert_model - INFO - Epoch 4/10 - Batch 2320/10125 - Loss: 0.1517 - Acc: 93.19% - LR: 1.35e-05
2025-12-15 20:11:08 - models.bert_model - INFO - Epoch 4/10 - Batch 2360/10125 - Loss: 0.3776 - Acc: 93.18% - LR: 1.35e-05
2025-12-15 20:11:22 - models.bert_model - INFO - Epoch 4/10 - Batch 2400/10125 - Loss: 0.1492 - Acc: 93.19% - LR: 1.35e-05
2025-12-15 20:11:37 - models.bert_model - INFO - Epoch 4/10 - Batch 2440/10125 - Loss: 0.3955 - Acc: 93.19% - LR: 1.35e-05
2025-12-15 20:11:52 - models.bert_model - INFO - Epoch 4/10 - Batch 2480/10125 - Loss: 0.1992 - Acc: 93.22% - LR: 1.35e-05
2025-12-15 20:12:06 - models.bert_model - INFO - Epoch 4/10 - Batch 2520/10125 - Loss: 0.5465 - Acc: 93.23% - LR: 1.35e-05
2025-12-15 20:12:20 - models.bert_model - INFO - Epoch 4/10 - Batch 2560/10125 - Loss: 0.2902 - Acc: 93.24% - LR: 1.35e-05
2025-12-15 20:12:35 - models.bert_model - INFO - Epoch 4/10 - Batch 2600/10125 - Loss: 0.1113 - Acc: 93.23% - LR: 1.35e-05
2025-12-15 20:12:49 - models.bert_model - INFO - Epoch 4/10 - Batch 2640/10125 - Loss: 0.1147 - Acc: 93.24% - LR: 1.35e-05
2025-12-15 20:13:04 - models.bert_model - INFO - Epoch 4/10 - Batch 2680/10125 - Loss: 0.1595 - Acc: 93.23% - LR: 1.35e-05
2025-12-15 20:13:19 - models.bert_model - INFO - Epoch 4/10 - Batch 2720/10125 - Loss: 0.1659 - Acc: 93.23% - LR: 1.35e-05
2025-12-15 20:13:33 - models.bert_model - INFO - Epoch 4/10 - Batch 2760/10125 - Loss: 0.3874 - Acc: 93.24% - LR: 1.34e-05
2025-12-15 20:13:48 - models.bert_model - INFO - Epoch 4/10 - Batch 2800/10125 - Loss: 0.2686 - Acc: 93.24% - LR: 1.34e-05
2025-12-15 20:14:02 - models.bert_model - INFO - Epoch 4/10 - Batch 2840/10125 - Loss: 0.2970 - Acc: 93.26% - LR: 1.34e-05
2025-12-15 20:14:17 - models.bert_model - INFO - Epoch 4/10 - Batch 2880/10125 - Loss: 0.4521 - Acc: 93.26% - LR: 1.34e-05
2025-12-15 20:14:31 - models.bert_model - INFO - Epoch 4/10 - Batch 2920/10125 - Loss: 0.3934 - Acc: 93.26% - LR: 1.34e-05
2025-12-15 20:14:46 - models.bert_model - INFO - Epoch 4/10 - Batch 2960/10125 - Loss: 0.1206 - Acc: 93.27% - LR: 1.34e-05
2025-12-15 20:15:00 - models.bert_model - INFO - Epoch 4/10 - Batch 3000/10125 - Loss: 0.2025 - Acc: 93.28% - LR: 1.34e-05
2025-12-15 20:15:15 - models.bert_model - INFO - Epoch 4/10 - Batch 3040/10125 - Loss: 0.1546 - Acc: 93.28% - LR: 1.34e-05
2025-12-15 20:15:29 - models.bert_model - INFO - Epoch 4/10 - Batch 3080/10125 - Loss: 0.1373 - Acc: 93.27% - LR: 1.34e-05
2025-12-15 20:15:44 - models.bert_model - INFO - Epoch 4/10 - Batch 3120/10125 - Loss: 0.1218 - Acc: 93.26% - LR: 1.34e-05
2025-12-15 20:15:58 - models.bert_model - INFO - Epoch 4/10 - Batch 3160/10125 - Loss: 0.1746 - Acc: 93.28% - LR: 1.34e-05
2025-12-15 20:16:13 - models.bert_model - INFO - Epoch 4/10 - Batch 3200/10125 - Loss: 0.5197 - Acc: 93.26% - LR: 1.34e-05
2025-12-15 20:16:27 - models.bert_model - INFO - Epoch 4/10 - Batch 3240/10125 - Loss: 0.2640 - Acc: 93.25% - LR: 1.34e-05
2025-12-15 20:16:42 - models.bert_model - INFO - Epoch 4/10 - Batch 3280/10125 - Loss: 0.2752 - Acc: 93.26% - LR: 1.34e-05
2025-12-15 20:16:57 - models.bert_model - INFO - Epoch 4/10 - Batch 3320/10125 - Loss: 0.3111 - Acc: 93.25% - LR: 1.34e-05
2025-12-15 20:17:11 - models.bert_model - INFO - Epoch 4/10 - Batch 3360/10125 - Loss: 0.5775 - Acc: 93.20% - LR: 1.33e-05
2025-12-15 20:17:26 - models.bert_model - INFO - Epoch 4/10 - Batch 3400/10125 - Loss: 0.1732 - Acc: 93.21% - LR: 1.33e-05
2025-12-15 20:17:40 - models.bert_model - INFO - Epoch 4/10 - Batch 3440/10125 - Loss: 0.3282 - Acc: 93.20% - LR: 1.33e-05
2025-12-15 20:17:55 - models.bert_model - INFO - Epoch 4/10 - Batch 3480/10125 - Loss: 0.3418 - Acc: 93.21% - LR: 1.33e-05
2025-12-15 20:18:09 - models.bert_model - INFO - Epoch 4/10 - Batch 3520/10125 - Loss: 0.2290 - Acc: 93.22% - LR: 1.33e-05
2025-12-15 20:18:24 - models.bert_model - INFO - Epoch 4/10 - Batch 3560/10125 - Loss: 0.1272 - Acc: 93.22% - LR: 1.33e-05
2025-12-15 20:18:38 - models.bert_model - INFO - Epoch 4/10 - Batch 3600/10125 - Loss: 0.1675 - Acc: 93.22% - LR: 1.33e-05
2025-12-15 20:18:53 - models.bert_model - INFO - Epoch 4/10 - Batch 3640/10125 - Loss: 0.2662 - Acc: 93.21% - LR: 1.33e-05
2025-12-15 20:19:07 - models.bert_model - INFO - Epoch 4/10 - Batch 3680/10125 - Loss: 0.2956 - Acc: 93.19% - LR: 1.33e-05
2025-12-15 20:19:22 - models.bert_model - INFO - Epoch 4/10 - Batch 3720/10125 - Loss: 0.1397 - Acc: 93.20% - LR: 1.33e-05
2025-12-15 20:19:36 - models.bert_model - INFO - Epoch 4/10 - Batch 3760/10125 - Loss: 0.1097 - Acc: 93.20% - LR: 1.33e-05
2025-12-15 20:19:51 - models.bert_model - INFO - Epoch 4/10 - Batch 3800/10125 - Loss: 0.3778 - Acc: 93.20% - LR: 1.33e-05
2025-12-15 20:20:05 - models.bert_model - INFO - Epoch 4/10 - Batch 3840/10125 - Loss: 0.3842 - Acc: 93.20% - LR: 1.33e-05
2025-12-15 20:20:20 - models.bert_model - INFO - Epoch 4/10 - Batch 3880/10125 - Loss: 0.4409 - Acc: 93.21% - LR: 1.33e-05
2025-12-15 20:20:34 - models.bert_model - INFO - Epoch 4/10 - Batch 3920/10125 - Loss: 0.1971 - Acc: 93.22% - LR: 1.32e-05
2025-12-15 20:20:49 - models.bert_model - INFO - Epoch 4/10 - Batch 3960/10125 - Loss: 0.3664 - Acc: 93.22% - LR: 1.32e-05
2025-12-15 20:21:03 - models.bert_model - INFO - Epoch 4/10 - Batch 4000/10125 - Loss: 0.1507 - Acc: 93.23% - LR: 1.32e-05
2025-12-15 20:21:18 - models.bert_model - INFO - Epoch 4/10 - Batch 4040/10125 - Loss: 0.1801 - Acc: 93.24% - LR: 1.32e-05
2025-12-15 20:21:32 - models.bert_model - INFO - Epoch 4/10 - Batch 4080/10125 - Loss: 0.1334 - Acc: 93.24% - LR: 1.32e-05
2025-12-15 20:21:47 - models.bert_model - INFO - Epoch 4/10 - Batch 4120/10125 - Loss: 0.1832 - Acc: 93.25% - LR: 1.32e-05
2025-12-15 20:22:01 - models.bert_model - INFO - Epoch 4/10 - Batch 4160/10125 - Loss: 0.1132 - Acc: 93.25% - LR: 1.32e-05
2025-12-15 20:22:16 - models.bert_model - INFO - Epoch 4/10 - Batch 4200/10125 - Loss: 0.1340 - Acc: 93.25% - LR: 1.32e-05
2025-12-15 20:22:31 - models.bert_model - INFO - Epoch 4/10 - Batch 4240/10125 - Loss: 0.2059 - Acc: 93.26% - LR: 1.32e-05
2025-12-15 20:22:45 - models.bert_model - INFO - Epoch 4/10 - Batch 4280/10125 - Loss: 0.1331 - Acc: 93.27% - LR: 1.32e-05
2025-12-15 20:23:00 - models.bert_model - INFO - Epoch 4/10 - Batch 4320/10125 - Loss: 0.1227 - Acc: 93.26% - LR: 1.32e-05
2025-12-15 20:23:14 - models.bert_model - INFO - Epoch 4/10 - Batch 4360/10125 - Loss: 0.3163 - Acc: 93.26% - LR: 1.32e-05
2025-12-15 20:23:29 - models.bert_model - INFO - Epoch 4/10 - Batch 4400/10125 - Loss: 0.1942 - Acc: 93.26% - LR: 1.32e-05
2025-12-15 20:23:43 - models.bert_model - INFO - Epoch 4/10 - Batch 4440/10125 - Loss: 0.2463 - Acc: 93.27% - LR: 1.32e-05
2025-12-15 20:23:58 - models.bert_model - INFO - Epoch 4/10 - Batch 4480/10125 - Loss: 0.1589 - Acc: 93.28% - LR: 1.31e-05
2025-12-15 20:24:12 - models.bert_model - INFO - Epoch 4/10 - Batch 4520/10125 - Loss: 0.2147 - Acc: 93.29% - LR: 1.31e-05
2025-12-15 20:24:27 - models.bert_model - INFO - Epoch 4/10 - Batch 4560/10125 - Loss: 0.2627 - Acc: 93.28% - LR: 1.31e-05
2025-12-15 20:24:41 - models.bert_model - INFO - Epoch 4/10 - Batch 4600/10125 - Loss: 0.1976 - Acc: 93.27% - LR: 1.31e-05
2025-12-15 20:24:56 - models.bert_model - INFO - Epoch 4/10 - Batch 4640/10125 - Loss: 0.1186 - Acc: 93.28% - LR: 1.31e-05
2025-12-15 20:25:10 - models.bert_model - INFO - Epoch 4/10 - Batch 4680/10125 - Loss: 0.2056 - Acc: 93.28% - LR: 1.31e-05
2025-12-15 20:25:25 - models.bert_model - INFO - Epoch 4/10 - Batch 4720/10125 - Loss: 0.2235 - Acc: 93.30% - LR: 1.31e-05
2025-12-15 20:25:40 - models.bert_model - INFO - Epoch 4/10 - Batch 4760/10125 - Loss: 0.3077 - Acc: 93.29% - LR: 1.31e-05
2025-12-15 20:25:54 - models.bert_model - INFO - Epoch 4/10 - Batch 4800/10125 - Loss: 0.2889 - Acc: 93.29% - LR: 1.31e-05
2025-12-15 20:26:09 - models.bert_model - INFO - Epoch 4/10 - Batch 4840/10125 - Loss: 0.2623 - Acc: 93.29% - LR: 1.31e-05
2025-12-15 20:26:23 - models.bert_model - INFO - Epoch 4/10 - Batch 4880/10125 - Loss: 0.1183 - Acc: 93.30% - LR: 1.31e-05
2025-12-15 20:26:38 - models.bert_model - INFO - Epoch 4/10 - Batch 4920/10125 - Loss: 0.1916 - Acc: 93.30% - LR: 1.31e-05
2025-12-15 20:26:52 - models.bert_model - INFO - Epoch 4/10 - Batch 4960/10125 - Loss: 0.1369 - Acc: 93.28% - LR: 1.31e-05
2025-12-15 20:27:07 - models.bert_model - INFO - Epoch 4/10 - Batch 5000/10125 - Loss: 0.1414 - Acc: 93.28% - LR: 1.31e-05
2025-12-15 20:27:21 - models.bert_model - INFO - Epoch 4/10 - Batch 5040/10125 - Loss: 0.3778 - Acc: 93.28% - LR: 1.30e-05
2025-12-15 20:27:36 - models.bert_model - INFO - Epoch 4/10 - Batch 5080/10125 - Loss: 0.2522 - Acc: 93.30% - LR: 1.30e-05
2025-12-15 20:27:50 - models.bert_model - INFO - Epoch 4/10 - Batch 5120/10125 - Loss: 0.4691 - Acc: 93.30% - LR: 1.30e-05
2025-12-15 20:28:05 - models.bert_model - INFO - Epoch 4/10 - Batch 5160/10125 - Loss: 0.2696 - Acc: 93.31% - LR: 1.30e-05
2025-12-15 20:28:19 - models.bert_model - INFO - Epoch 4/10 - Batch 5200/10125 - Loss: 0.2881 - Acc: 93.33% - LR: 1.30e-05
2025-12-15 20:28:34 - models.bert_model - INFO - Epoch 4/10 - Batch 5240/10125 - Loss: 0.1726 - Acc: 93.33% - LR: 1.30e-05
2025-12-15 20:28:48 - models.bert_model - INFO - Epoch 4/10 - Batch 5280/10125 - Loss: 0.2430 - Acc: 93.32% - LR: 1.30e-05
2025-12-15 20:29:03 - models.bert_model - INFO - Epoch 4/10 - Batch 5320/10125 - Loss: 0.1165 - Acc: 93.32% - LR: 1.30e-05
2025-12-15 20:29:18 - models.bert_model - INFO - Epoch 4/10 - Batch 5360/10125 - Loss: 0.1303 - Acc: 93.34% - LR: 1.30e-05
2025-12-15 20:29:32 - models.bert_model - INFO - Epoch 4/10 - Batch 5400/10125 - Loss: 0.2023 - Acc: 93.33% - LR: 1.30e-05
2025-12-15 20:29:47 - models.bert_model - INFO - Epoch 4/10 - Batch 5440/10125 - Loss: 0.3079 - Acc: 93.33% - LR: 1.30e-05
2025-12-15 20:30:01 - models.bert_model - INFO - Epoch 4/10 - Batch 5480/10125 - Loss: 0.1125 - Acc: 93.34% - LR: 1.30e-05
2025-12-15 20:30:16 - models.bert_model - INFO - Epoch 4/10 - Batch 5520/10125 - Loss: 0.2321 - Acc: 93.35% - LR: 1.30e-05
2025-12-15 20:30:30 - models.bert_model - INFO - Epoch 4/10 - Batch 5560/10125 - Loss: 0.3486 - Acc: 93.36% - LR: 1.29e-05
2025-12-15 20:30:45 - models.bert_model - INFO - Epoch 4/10 - Batch 5600/10125 - Loss: 0.4256 - Acc: 93.36% - LR: 1.29e-05
2025-12-15 20:30:59 - models.bert_model - INFO - Epoch 4/10 - Batch 5640/10125 - Loss: 0.2857 - Acc: 93.37% - LR: 1.29e-05
2025-12-15 20:31:14 - models.bert_model - INFO - Epoch 4/10 - Batch 5680/10125 - Loss: 0.3364 - Acc: 93.37% - LR: 1.29e-05
2025-12-15 20:31:28 - models.bert_model - INFO - Epoch 4/10 - Batch 5720/10125 - Loss: 0.4038 - Acc: 93.38% - LR: 1.29e-05
2025-12-15 20:31:43 - models.bert_model - INFO - Epoch 4/10 - Batch 5760/10125 - Loss: 0.2562 - Acc: 93.39% - LR: 1.29e-05
2025-12-15 20:31:57 - models.bert_model - INFO - Epoch 4/10 - Batch 5800/10125 - Loss: 0.3818 - Acc: 93.39% - LR: 1.29e-05
2025-12-15 20:32:12 - models.bert_model - INFO - Epoch 4/10 - Batch 5840/10125 - Loss: 0.3196 - Acc: 93.40% - LR: 1.29e-05
2025-12-15 20:32:26 - models.bert_model - INFO - Epoch 4/10 - Batch 5880/10125 - Loss: 0.4813 - Acc: 93.40% - LR: 1.29e-05
2025-12-15 20:32:41 - models.bert_model - INFO - Epoch 4/10 - Batch 5920/10125 - Loss: 0.4226 - Acc: 93.39% - LR: 1.29e-05
2025-12-15 20:32:55 - models.bert_model - INFO - Epoch 4/10 - Batch 5960/10125 - Loss: 0.1388 - Acc: 93.39% - LR: 1.29e-05
2025-12-15 20:33:10 - models.bert_model - INFO - Epoch 4/10 - Batch 6000/10125 - Loss: 0.2461 - Acc: 93.38% - LR: 1.29e-05
2025-12-15 20:33:25 - models.bert_model - INFO - Epoch 4/10 - Batch 6040/10125 - Loss: 0.1100 - Acc: 93.39% - LR: 1.29e-05
2025-12-15 20:33:39 - models.bert_model - INFO - Epoch 4/10 - Batch 6080/10125 - Loss: 0.1995 - Acc: 93.39% - LR: 1.29e-05
2025-12-15 20:33:54 - models.bert_model - INFO - Epoch 4/10 - Batch 6120/10125 - Loss: 0.1110 - Acc: 93.39% - LR: 1.28e-05
2025-12-15 20:34:08 - models.bert_model - INFO - Epoch 4/10 - Batch 6160/10125 - Loss: 0.2667 - Acc: 93.40% - LR: 1.28e-05
2025-12-15 20:34:23 - models.bert_model - INFO - Epoch 4/10 - Batch 6200/10125 - Loss: 0.4684 - Acc: 93.40% - LR: 1.28e-05
2025-12-15 20:34:37 - models.bert_model - INFO - Epoch 4/10 - Batch 6240/10125 - Loss: 0.2729 - Acc: 93.41% - LR: 1.28e-05
2025-12-15 20:34:52 - models.bert_model - INFO - Epoch 4/10 - Batch 6280/10125 - Loss: 0.2409 - Acc: 93.41% - LR: 1.28e-05
2025-12-15 20:35:06 - models.bert_model - INFO - Epoch 4/10 - Batch 6320/10125 - Loss: 0.2730 - Acc: 93.41% - LR: 1.28e-05
2025-12-15 20:35:21 - models.bert_model - INFO - Epoch 4/10 - Batch 6360/10125 - Loss: 0.1164 - Acc: 93.41% - LR: 1.28e-05
2025-12-15 20:35:35 - models.bert_model - INFO - Epoch 4/10 - Batch 6400/10125 - Loss: 0.2166 - Acc: 93.42% - LR: 1.28e-05
2025-12-15 20:35:50 - models.bert_model - INFO - Epoch 4/10 - Batch 6440/10125 - Loss: 0.2222 - Acc: 93.42% - LR: 1.28e-05
2025-12-15 20:36:04 - models.bert_model - INFO - Epoch 4/10 - Batch 6480/10125 - Loss: 0.3596 - Acc: 93.42% - LR: 1.28e-05
2025-12-15 20:36:19 - models.bert_model - INFO - Epoch 4/10 - Batch 6520/10125 - Loss: 0.5908 - Acc: 93.41% - LR: 1.28e-05
2025-12-15 20:36:33 - models.bert_model - INFO - Epoch 4/10 - Batch 6560/10125 - Loss: 0.1936 - Acc: 93.41% - LR: 1.28e-05
2025-12-15 20:36:48 - models.bert_model - INFO - Epoch 4/10 - Batch 6600/10125 - Loss: 0.1592 - Acc: 93.41% - LR: 1.28e-05
2025-12-15 20:37:03 - models.bert_model - INFO - Epoch 4/10 - Batch 6640/10125 - Loss: 0.2032 - Acc: 93.40% - LR: 1.27e-05
2025-12-15 20:37:17 - models.bert_model - INFO - Epoch 4/10 - Batch 6680/10125 - Loss: 0.1393 - Acc: 93.40% - LR: 1.27e-05
2025-12-15 20:37:32 - models.bert_model - INFO - Epoch 4/10 - Batch 6720/10125 - Loss: 0.3859 - Acc: 93.40% - LR: 1.27e-05
2025-12-15 20:37:46 - models.bert_model - INFO - Epoch 4/10 - Batch 6760/10125 - Loss: 0.4614 - Acc: 93.41% - LR: 1.27e-05
2025-12-15 20:38:01 - models.bert_model - INFO - Epoch 4/10 - Batch 6800/10125 - Loss: 0.3426 - Acc: 93.41% - LR: 1.27e-05
2025-12-15 20:38:15 - models.bert_model - INFO - Epoch 4/10 - Batch 6840/10125 - Loss: 0.3848 - Acc: 93.41% - LR: 1.27e-05
2025-12-15 20:38:30 - models.bert_model - INFO - Epoch 4/10 - Batch 6880/10125 - Loss: 0.2277 - Acc: 93.42% - LR: 1.27e-05
2025-12-15 20:38:44 - models.bert_model - INFO - Epoch 4/10 - Batch 6920/10125 - Loss: 0.2801 - Acc: 93.42% - LR: 1.27e-05
2025-12-15 20:38:59 - models.bert_model - INFO - Epoch 4/10 - Batch 6960/10125 - Loss: 0.1988 - Acc: 93.42% - LR: 1.27e-05
2025-12-15 20:39:13 - models.bert_model - INFO - Epoch 4/10 - Batch 7000/10125 - Loss: 0.3253 - Acc: 93.42% - LR: 1.27e-05
2025-12-15 20:39:28 - models.bert_model - INFO - Epoch 4/10 - Batch 7040/10125 - Loss: 0.4688 - Acc: 93.41% - LR: 1.27e-05
2025-12-15 20:39:42 - models.bert_model - INFO - Epoch 4/10 - Batch 7080/10125 - Loss: 0.4277 - Acc: 93.41% - LR: 1.27e-05
2025-12-15 20:39:57 - models.bert_model - INFO - Epoch 4/10 - Batch 7120/10125 - Loss: 0.1143 - Acc: 93.41% - LR: 1.26e-05
2025-12-15 20:40:11 - models.bert_model - INFO - Epoch 4/10 - Batch 7160/10125 - Loss: 0.1674 - Acc: 93.41% - LR: 1.26e-05
2025-12-15 20:40:26 - models.bert_model - INFO - Epoch 4/10 - Batch 7200/10125 - Loss: 0.4161 - Acc: 93.40% - LR: 1.26e-05
2025-12-15 20:40:40 - models.bert_model - INFO - Epoch 4/10 - Batch 7240/10125 - Loss: 0.2291 - Acc: 93.40% - LR: 1.26e-05
2025-12-15 20:40:55 - models.bert_model - INFO - Epoch 4/10 - Batch 7280/10125 - Loss: 0.2785 - Acc: 93.40% - LR: 1.26e-05
2025-12-15 20:41:09 - models.bert_model - INFO - Epoch 4/10 - Batch 7320/10125 - Loss: 0.1076 - Acc: 93.41% - LR: 1.26e-05
2025-12-15 20:41:24 - models.bert_model - INFO - Epoch 4/10 - Batch 7360/10125 - Loss: 0.1945 - Acc: 93.41% - LR: 1.26e-05
2025-12-15 20:41:39 - models.bert_model - INFO - Epoch 4/10 - Batch 7400/10125 - Loss: 0.1250 - Acc: 93.41% - LR: 1.26e-05
2025-12-15 20:41:53 - models.bert_model - INFO - Epoch 4/10 - Batch 7440/10125 - Loss: 0.2379 - Acc: 93.40% - LR: 1.26e-05
2025-12-15 20:42:08 - models.bert_model - INFO - Epoch 4/10 - Batch 7480/10125 - Loss: 0.1091 - Acc: 93.41% - LR: 1.26e-05
2025-12-15 20:42:22 - models.bert_model - INFO - Epoch 4/10 - Batch 7520/10125 - Loss: 0.1492 - Acc: 93.41% - LR: 1.26e-05
2025-12-15 20:42:37 - models.bert_model - INFO - Epoch 4/10 - Batch 7560/10125 - Loss: 0.1437 - Acc: 93.42% - LR: 1.26e-05
2025-12-15 20:42:51 - models.bert_model - INFO - Epoch 4/10 - Batch 7600/10125 - Loss: 0.3637 - Acc: 93.42% - LR: 1.26e-05
2025-12-15 20:43:06 - models.bert_model - INFO - Epoch 4/10 - Batch 7640/10125 - Loss: 0.1950 - Acc: 93.42% - LR: 1.25e-05
2025-12-15 20:43:20 - models.bert_model - INFO - Epoch 4/10 - Batch 7680/10125 - Loss: 0.3185 - Acc: 93.41% - LR: 1.25e-05
2025-12-15 20:43:35 - models.bert_model - INFO - Epoch 4/10 - Batch 7720/10125 - Loss: 0.1430 - Acc: 93.42% - LR: 1.25e-05
2025-12-15 20:43:49 - models.bert_model - INFO - Epoch 4/10 - Batch 7760/10125 - Loss: 0.3768 - Acc: 93.42% - LR: 1.25e-05
2025-12-15 20:44:04 - models.bert_model - INFO - Epoch 4/10 - Batch 7800/10125 - Loss: 0.1698 - Acc: 93.42% - LR: 1.25e-05
2025-12-15 20:44:18 - models.bert_model - INFO - Epoch 4/10 - Batch 7840/10125 - Loss: 0.1346 - Acc: 93.43% - LR: 1.25e-05
2025-12-15 20:44:33 - models.bert_model - INFO - Epoch 4/10 - Batch 7880/10125 - Loss: 0.2369 - Acc: 93.43% - LR: 1.25e-05
2025-12-15 20:44:47 - models.bert_model - INFO - Epoch 4/10 - Batch 7920/10125 - Loss: 0.1693 - Acc: 93.43% - LR: 1.25e-05
2025-12-15 20:45:02 - models.bert_model - INFO - Epoch 4/10 - Batch 7960/10125 - Loss: 0.2098 - Acc: 93.43% - LR: 1.25e-05
2025-12-15 20:45:17 - models.bert_model - INFO - Epoch 4/10 - Batch 8000/10125 - Loss: 0.1289 - Acc: 93.43% - LR: 1.25e-05
2025-12-15 20:45:31 - models.bert_model - INFO - Epoch 4/10 - Batch 8040/10125 - Loss: 0.1368 - Acc: 93.43% - LR: 1.25e-05
2025-12-15 20:45:46 - models.bert_model - INFO - Epoch 4/10 - Batch 8080/10125 - Loss: 0.1386 - Acc: 93.43% - LR: 1.25e-05
2025-12-15 20:46:00 - models.bert_model - INFO - Epoch 4/10 - Batch 8120/10125 - Loss: 0.3851 - Acc: 93.43% - LR: 1.24e-05
2025-12-15 20:46:15 - models.bert_model - INFO - Epoch 4/10 - Batch 8160/10125 - Loss: 0.2586 - Acc: 93.42% - LR: 1.24e-05
2025-12-15 20:46:29 - models.bert_model - INFO - Epoch 4/10 - Batch 8200/10125 - Loss: 0.1696 - Acc: 93.42% - LR: 1.24e-05
2025-12-15 20:46:44 - models.bert_model - INFO - Epoch 4/10 - Batch 8240/10125 - Loss: 0.1615 - Acc: 93.42% - LR: 1.24e-05
2025-12-15 20:46:58 - models.bert_model - INFO - Epoch 4/10 - Batch 8280/10125 - Loss: 0.2049 - Acc: 93.42% - LR: 1.24e-05
2025-12-15 20:47:13 - models.bert_model - INFO - Epoch 4/10 - Batch 8320/10125 - Loss: 0.3117 - Acc: 93.42% - LR: 1.24e-05
2025-12-15 20:47:27 - models.bert_model - INFO - Epoch 4/10 - Batch 8360/10125 - Loss: 0.1565 - Acc: 93.42% - LR: 1.24e-05
2025-12-15 20:47:42 - models.bert_model - INFO - Epoch 4/10 - Batch 8400/10125 - Loss: 0.1849 - Acc: 93.43% - LR: 1.24e-05
2025-12-15 20:47:56 - models.bert_model - INFO - Epoch 4/10 - Batch 8440/10125 - Loss: 0.1774 - Acc: 93.42% - LR: 1.24e-05
2025-12-15 20:48:11 - models.bert_model - INFO - Epoch 4/10 - Batch 8480/10125 - Loss: 0.1478 - Acc: 93.43% - LR: 1.24e-05
2025-12-15 20:48:25 - models.bert_model - INFO - Epoch 4/10 - Batch 8520/10125 - Loss: 0.2001 - Acc: 93.44% - LR: 1.24e-05
2025-12-15 20:48:40 - models.bert_model - INFO - Epoch 4/10 - Batch 8560/10125 - Loss: 0.1045 - Acc: 93.43% - LR: 1.24e-05
2025-12-15 20:48:55 - models.bert_model - INFO - Epoch 4/10 - Batch 8600/10125 - Loss: 0.1798 - Acc: 93.43% - LR: 1.23e-05
2025-12-15 20:49:09 - models.bert_model - INFO - Epoch 4/10 - Batch 8640/10125 - Loss: 0.5981 - Acc: 93.43% - LR: 1.23e-05
2025-12-15 20:49:24 - models.bert_model - INFO - Epoch 4/10 - Batch 8680/10125 - Loss: 0.2068 - Acc: 93.43% - LR: 1.23e-05
2025-12-15 20:49:38 - models.bert_model - INFO - Epoch 4/10 - Batch 8720/10125 - Loss: 0.2954 - Acc: 93.43% - LR: 1.23e-05
2025-12-15 20:49:53 - models.bert_model - INFO - Epoch 4/10 - Batch 8760/10125 - Loss: 0.1495 - Acc: 93.43% - LR: 1.23e-05
2025-12-15 20:50:07 - models.bert_model - INFO - Epoch 4/10 - Batch 8800/10125 - Loss: 0.1193 - Acc: 93.43% - LR: 1.23e-05
2025-12-15 20:50:22 - models.bert_model - INFO - Epoch 4/10 - Batch 8840/10125 - Loss: 0.3286 - Acc: 93.43% - LR: 1.23e-05
2025-12-15 20:50:36 - models.bert_model - INFO - Epoch 4/10 - Batch 8880/10125 - Loss: 0.1669 - Acc: 93.43% - LR: 1.23e-05
2025-12-15 20:50:51 - models.bert_model - INFO - Epoch 4/10 - Batch 8920/10125 - Loss: 0.2906 - Acc: 93.43% - LR: 1.23e-05
2025-12-15 20:51:05 - models.bert_model - INFO - Epoch 4/10 - Batch 8960/10125 - Loss: 0.1415 - Acc: 93.43% - LR: 1.23e-05
2025-12-15 20:51:20 - models.bert_model - INFO - Epoch 4/10 - Batch 9000/10125 - Loss: 0.1610 - Acc: 93.43% - LR: 1.23e-05
2025-12-15 20:51:34 - models.bert_model - INFO - Epoch 4/10 - Batch 9040/10125 - Loss: 0.2290 - Acc: 93.43% - LR: 1.23e-05
2025-12-15 20:51:49 - models.bert_model - INFO - Epoch 4/10 - Batch 9080/10125 - Loss: 0.1201 - Acc: 93.44% - LR: 1.22e-05
2025-12-15 20:52:03 - models.bert_model - INFO - Epoch 4/10 - Batch 9120/10125 - Loss: 0.1198 - Acc: 93.44% - LR: 1.22e-05
2025-12-15 20:52:18 - models.bert_model - INFO - Epoch 4/10 - Batch 9160/10125 - Loss: 0.1219 - Acc: 93.44% - LR: 1.22e-05
2025-12-15 20:52:32 - models.bert_model - INFO - Epoch 4/10 - Batch 9200/10125 - Loss: 0.2914 - Acc: 93.44% - LR: 1.22e-05
2025-12-15 20:52:47 - models.bert_model - INFO - Epoch 4/10 - Batch 9240/10125 - Loss: 0.3790 - Acc: 93.44% - LR: 1.22e-05
2025-12-15 20:53:02 - models.bert_model - INFO - Epoch 4/10 - Batch 9280/10125 - Loss: 0.2344 - Acc: 93.45% - LR: 1.22e-05
2025-12-15 20:53:16 - models.bert_model - INFO - Epoch 4/10 - Batch 9320/10125 - Loss: 0.2872 - Acc: 93.45% - LR: 1.22e-05
2025-12-15 20:53:31 - models.bert_model - INFO - Epoch 4/10 - Batch 9360/10125 - Loss: 0.4069 - Acc: 93.46% - LR: 1.22e-05
2025-12-15 20:53:45 - models.bert_model - INFO - Epoch 4/10 - Batch 9400/10125 - Loss: 0.4941 - Acc: 93.46% - LR: 1.22e-05
2025-12-15 20:54:00 - models.bert_model - INFO - Epoch 4/10 - Batch 9440/10125 - Loss: 0.2773 - Acc: 93.46% - LR: 1.22e-05
2025-12-15 20:54:14 - models.bert_model - INFO - Epoch 4/10 - Batch 9480/10125 - Loss: 0.2804 - Acc: 93.45% - LR: 1.22e-05
2025-12-15 20:54:29 - models.bert_model - INFO - Epoch 4/10 - Batch 9520/10125 - Loss: 0.3701 - Acc: 93.45% - LR: 1.22e-05
2025-12-15 20:54:43 - models.bert_model - INFO - Epoch 4/10 - Batch 9560/10125 - Loss: 0.2724 - Acc: 93.44% - LR: 1.21e-05
2025-12-15 20:54:58 - models.bert_model - INFO - Epoch 4/10 - Batch 9600/10125 - Loss: 0.3777 - Acc: 93.45% - LR: 1.21e-05
2025-12-15 20:55:12 - models.bert_model - INFO - Epoch 4/10 - Batch 9640/10125 - Loss: 0.2682 - Acc: 93.45% - LR: 1.21e-05
2025-12-15 20:55:27 - models.bert_model - INFO - Epoch 4/10 - Batch 9680/10125 - Loss: 0.3149 - Acc: 93.45% - LR: 1.21e-05
2025-12-15 20:55:41 - models.bert_model - INFO - Epoch 4/10 - Batch 9720/10125 - Loss: 0.2590 - Acc: 93.45% - LR: 1.21e-05
2025-12-15 20:55:56 - models.bert_model - INFO - Epoch 4/10 - Batch 9760/10125 - Loss: 0.2027 - Acc: 93.46% - LR: 1.21e-05
2025-12-15 20:56:10 - models.bert_model - INFO - Epoch 4/10 - Batch 9800/10125 - Loss: 0.1615 - Acc: 93.46% - LR: 1.21e-05
2025-12-15 20:56:25 - models.bert_model - INFO - Epoch 4/10 - Batch 9840/10125 - Loss: 0.2021 - Acc: 93.45% - LR: 1.21e-05
2025-12-15 20:56:40 - models.bert_model - INFO - Epoch 4/10 - Batch 9880/10125 - Loss: 0.3517 - Acc: 93.45% - LR: 1.21e-05
2025-12-15 20:56:54 - models.bert_model - INFO - Epoch 4/10 - Batch 9920/10125 - Loss: 0.2704 - Acc: 93.46% - LR: 1.21e-05
2025-12-15 20:57:09 - models.bert_model - INFO - Epoch 4/10 - Batch 9960/10125 - Loss: 0.1625 - Acc: 93.46% - LR: 1.21e-05
2025-12-15 20:57:23 - models.bert_model - INFO - Epoch 4/10 - Batch 10000/10125 - Loss: 0.5605 - Acc: 93.46% - LR: 1.20e-05
2025-12-15 20:57:38 - models.bert_model - INFO - Epoch 4/10 - Batch 10040/10125 - Loss: 0.2194 - Acc: 93.46% - LR: 1.20e-05
2025-12-15 20:57:52 - models.bert_model - INFO - Epoch 4/10 - Batch 10080/10125 - Loss: 0.3420 - Acc: 93.46% - LR: 1.20e-05
2025-12-15 20:58:07 - models.bert_model - INFO - Epoch 4/10 - Batch 10120/10125 - Loss: 0.1155 - Acc: 93.47% - LR: 1.20e-05
2025-12-15 21:00:25 - models.bert_model - INFO - Epoch 4/10 - Train Loss: 0.2440, Train Acc: 93.47% - Val Loss: 0.2279, Val Acc: 93.99%
2025-12-15 21:00:25 - models.bert_model - INFO - New best validation accuracy: 93.99%
2025-12-15 21:00:39 - models.bert_model - INFO - Epoch 5/10 - Batch 40/10125 - Loss: 0.1887 - Acc: 94.22% - LR: 1.20e-05
2025-12-15 21:00:54 - models.bert_model - INFO - Epoch 5/10 - Batch 80/10125 - Loss: 0.1978 - Acc: 94.30% - LR: 1.20e-05
2025-12-15 21:01:08 - models.bert_model - INFO - Epoch 5/10 - Batch 120/10125 - Loss: 0.4840 - Acc: 94.48% - LR: 1.20e-05
2025-12-15 21:01:23 - models.bert_model - INFO - Epoch 5/10 - Batch 160/10125 - Loss: 0.2595 - Acc: 94.45% - LR: 1.20e-05
2025-12-15 21:01:37 - models.bert_model - INFO - Epoch 5/10 - Batch 200/10125 - Loss: 0.3096 - Acc: 94.44% - LR: 1.20e-05
2025-12-15 21:01:52 - models.bert_model - INFO - Epoch 5/10 - Batch 240/10125 - Loss: 0.2114 - Acc: 94.61% - LR: 1.20e-05
2025-12-15 21:02:06 - models.bert_model - INFO - Epoch 5/10 - Batch 280/10125 - Loss: 0.1509 - Acc: 94.53% - LR: 1.20e-05
2025-12-15 21:02:21 - models.bert_model - INFO - Epoch 5/10 - Batch 320/10125 - Loss: 0.1607 - Acc: 94.55% - LR: 1.19e-05
2025-12-15 21:02:35 - models.bert_model - INFO - Epoch 5/10 - Batch 360/10125 - Loss: 0.1142 - Acc: 94.51% - LR: 1.19e-05
2025-12-15 21:02:50 - models.bert_model - INFO - Epoch 5/10 - Batch 400/10125 - Loss: 0.1246 - Acc: 94.45% - LR: 1.19e-05
2025-12-15 21:03:04 - models.bert_model - INFO - Epoch 5/10 - Batch 440/10125 - Loss: 0.1533 - Acc: 94.42% - LR: 1.19e-05
2025-12-15 21:03:19 - models.bert_model - INFO - Epoch 5/10 - Batch 480/10125 - Loss: 0.3430 - Acc: 94.40% - LR: 1.19e-05
2025-12-15 21:03:33 - models.bert_model - INFO - Epoch 5/10 - Batch 520/10125 - Loss: 0.3486 - Acc: 94.41% - LR: 1.19e-05
2025-12-15 21:03:48 - models.bert_model - INFO - Epoch 5/10 - Batch 560/10125 - Loss: 0.1869 - Acc: 94.42% - LR: 1.19e-05
2025-12-15 21:04:02 - models.bert_model - INFO - Epoch 5/10 - Batch 600/10125 - Loss: 0.1863 - Acc: 94.45% - LR: 1.19e-05
2025-12-15 21:04:17 - models.bert_model - INFO - Epoch 5/10 - Batch 640/10125 - Loss: 0.1615 - Acc: 94.46% - LR: 1.19e-05
2025-12-15 21:04:31 - models.bert_model - INFO - Epoch 5/10 - Batch 680/10125 - Loss: 0.4889 - Acc: 94.46% - LR: 1.19e-05
2025-12-15 21:04:46 - models.bert_model - INFO - Epoch 5/10 - Batch 720/10125 - Loss: 0.1323 - Acc: 94.42% - LR: 1.19e-05
2025-12-15 21:05:00 - models.bert_model - INFO - Epoch 5/10 - Batch 760/10125 - Loss: 0.1968 - Acc: 94.43% - LR: 1.19e-05
2025-12-15 21:05:15 - models.bert_model - INFO - Epoch 5/10 - Batch 800/10125 - Loss: 0.5222 - Acc: 94.40% - LR: 1.18e-05
2025-12-15 21:05:30 - models.bert_model - INFO - Epoch 5/10 - Batch 840/10125 - Loss: 0.1960 - Acc: 94.32% - LR: 1.18e-05
2025-12-15 21:05:44 - models.bert_model - INFO - Epoch 5/10 - Batch 880/10125 - Loss: 0.4443 - Acc: 94.36% - LR: 1.18e-05
2025-12-15 21:05:59 - models.bert_model - INFO - Epoch 5/10 - Batch 920/10125 - Loss: 0.1359 - Acc: 94.38% - LR: 1.18e-05
2025-12-15 21:06:13 - models.bert_model - INFO - Epoch 5/10 - Batch 960/10125 - Loss: 0.2165 - Acc: 94.40% - LR: 1.18e-05
2025-12-15 21:06:28 - models.bert_model - INFO - Epoch 5/10 - Batch 1000/10125 - Loss: 0.1568 - Acc: 94.42% - LR: 1.18e-05
2025-12-15 21:06:42 - models.bert_model - INFO - Epoch 5/10 - Batch 1040/10125 - Loss: 0.1533 - Acc: 94.46% - LR: 1.18e-05
2025-12-15 21:06:57 - models.bert_model - INFO - Epoch 5/10 - Batch 1080/10125 - Loss: 0.2163 - Acc: 94.41% - LR: 1.18e-05
2025-12-15 21:07:11 - models.bert_model - INFO - Epoch 5/10 - Batch 1120/10125 - Loss: 0.1183 - Acc: 94.37% - LR: 1.18e-05
2025-12-15 21:07:26 - models.bert_model - INFO - Epoch 5/10 - Batch 1160/10125 - Loss: 0.1788 - Acc: 94.43% - LR: 1.18e-05
2025-12-15 21:07:40 - models.bert_model - INFO - Epoch 5/10 - Batch 1200/10125 - Loss: 0.2044 - Acc: 94.42% - LR: 1.18e-05
2025-12-15 21:07:55 - models.bert_model - INFO - Epoch 5/10 - Batch 1240/10125 - Loss: 0.1198 - Acc: 94.45% - LR: 1.17e-05
2025-12-15 21:08:09 - models.bert_model - INFO - Epoch 5/10 - Batch 1280/10125 - Loss: 0.5581 - Acc: 94.43% - LR: 1.17e-05
2025-12-15 21:08:24 - models.bert_model - INFO - Epoch 5/10 - Batch 1320/10125 - Loss: 0.1555 - Acc: 94.41% - LR: 1.17e-05
2025-12-15 21:08:38 - models.bert_model - INFO - Epoch 5/10 - Batch 1360/10125 - Loss: 0.1155 - Acc: 94.44% - LR: 1.17e-05
2025-12-15 21:08:53 - models.bert_model - INFO - Epoch 5/10 - Batch 1400/10125 - Loss: 0.2341 - Acc: 94.46% - LR: 1.17e-05
2025-12-15 21:09:07 - models.bert_model - INFO - Epoch 5/10 - Batch 1440/10125 - Loss: 0.2331 - Acc: 94.48% - LR: 1.17e-05
2025-12-15 21:09:22 - models.bert_model - INFO - Epoch 5/10 - Batch 1480/10125 - Loss: 0.8210 - Acc: 94.46% - LR: 1.17e-05
2025-12-15 21:09:37 - models.bert_model - INFO - Epoch 5/10 - Batch 1520/10125 - Loss: 0.1744 - Acc: 94.50% - LR: 1.17e-05
2025-12-15 21:09:51 - models.bert_model - INFO - Epoch 5/10 - Batch 1560/10125 - Loss: 0.1207 - Acc: 94.42% - LR: 1.17e-05
2025-12-15 21:10:06 - models.bert_model - INFO - Epoch 5/10 - Batch 1600/10125 - Loss: 0.2145 - Acc: 94.41% - LR: 1.17e-05
2025-12-15 21:10:20 - models.bert_model - INFO - Epoch 5/10 - Batch 1640/10125 - Loss: 0.1135 - Acc: 94.43% - LR: 1.17e-05
2025-12-15 21:10:35 - models.bert_model - INFO - Epoch 5/10 - Batch 1680/10125 - Loss: 0.3495 - Acc: 94.40% - LR: 1.16e-05
2025-12-15 21:10:49 - models.bert_model - INFO - Epoch 5/10 - Batch 1720/10125 - Loss: 0.4137 - Acc: 94.41% - LR: 1.16e-05
2025-12-15 21:11:04 - models.bert_model - INFO - Epoch 5/10 - Batch 1760/10125 - Loss: 0.1555 - Acc: 94.42% - LR: 1.16e-05
2025-12-15 21:11:18 - models.bert_model - INFO - Epoch 5/10 - Batch 1800/10125 - Loss: 0.4349 - Acc: 94.41% - LR: 1.16e-05
2025-12-15 21:11:33 - models.bert_model - INFO - Epoch 5/10 - Batch 1840/10125 - Loss: 0.1144 - Acc: 94.42% - LR: 1.16e-05
2025-12-15 21:11:47 - models.bert_model - INFO - Epoch 5/10 - Batch 1880/10125 - Loss: 0.2237 - Acc: 94.40% - LR: 1.16e-05
2025-12-15 21:12:02 - models.bert_model - INFO - Epoch 5/10 - Batch 1920/10125 - Loss: 0.1534 - Acc: 94.40% - LR: 1.16e-05
2025-12-15 21:12:17 - models.bert_model - INFO - Epoch 5/10 - Batch 1960/10125 - Loss: 0.6046 - Acc: 94.40% - LR: 1.16e-05
2025-12-15 21:12:31 - models.bert_model - INFO - Epoch 5/10 - Batch 2000/10125 - Loss: 0.1899 - Acc: 94.39% - LR: 1.16e-05
2025-12-15 21:12:46 - models.bert_model - INFO - Epoch 5/10 - Batch 2040/10125 - Loss: 0.3158 - Acc: 94.39% - LR: 1.16e-05
2025-12-15 21:13:00 - models.bert_model - INFO - Epoch 5/10 - Batch 2080/10125 - Loss: 0.1342 - Acc: 94.38% - LR: 1.16e-05
2025-12-15 21:13:15 - models.bert_model - INFO - Epoch 5/10 - Batch 2120/10125 - Loss: 0.2260 - Acc: 94.36% - LR: 1.15e-05
2025-12-15 21:13:29 - models.bert_model - INFO - Epoch 5/10 - Batch 2160/10125 - Loss: 0.1632 - Acc: 94.36% - LR: 1.15e-05
2025-12-15 21:13:43 - models.bert_model - INFO - Epoch 5/10 - Batch 2200/10125 - Loss: 0.5375 - Acc: 94.36% - LR: 1.15e-05
2025-12-15 21:13:58 - models.bert_model - INFO - Epoch 5/10 - Batch 2240/10125 - Loss: 0.1652 - Acc: 94.31% - LR: 1.15e-05
2025-12-15 21:14:13 - models.bert_model - INFO - Epoch 5/10 - Batch 2280/10125 - Loss: 0.2176 - Acc: 94.31% - LR: 1.15e-05
2025-12-15 21:14:27 - models.bert_model - INFO - Epoch 5/10 - Batch 2320/10125 - Loss: 0.1999 - Acc: 94.29% - LR: 1.15e-05
2025-12-15 21:14:42 - models.bert_model - INFO - Epoch 5/10 - Batch 2360/10125 - Loss: 0.1764 - Acc: 94.26% - LR: 1.15e-05
2025-12-15 21:14:56 - models.bert_model - INFO - Epoch 5/10 - Batch 2400/10125 - Loss: 0.1367 - Acc: 94.26% - LR: 1.15e-05
2025-12-15 21:15:11 - models.bert_model - INFO - Epoch 5/10 - Batch 2440/10125 - Loss: 0.2353 - Acc: 94.26% - LR: 1.15e-05
2025-12-15 21:15:25 - models.bert_model - INFO - Epoch 5/10 - Batch 2480/10125 - Loss: 0.2274 - Acc: 94.26% - LR: 1.15e-05
2025-12-15 21:15:40 - models.bert_model - INFO - Epoch 5/10 - Batch 2520/10125 - Loss: 0.3469 - Acc: 94.24% - LR: 1.15e-05
2025-12-15 21:15:54 - models.bert_model - INFO - Epoch 5/10 - Batch 2560/10125 - Loss: 0.1397 - Acc: 94.23% - LR: 1.14e-05
2025-12-15 21:16:09 - models.bert_model - INFO - Epoch 5/10 - Batch 2600/10125 - Loss: 0.1375 - Acc: 94.25% - LR: 1.14e-05
2025-12-15 21:16:24 - models.bert_model - INFO - Epoch 5/10 - Batch 2640/10125 - Loss: 0.1386 - Acc: 94.24% - LR: 1.14e-05
2025-12-15 21:16:38 - models.bert_model - INFO - Epoch 5/10 - Batch 2680/10125 - Loss: 0.1330 - Acc: 94.25% - LR: 1.14e-05
2025-12-15 21:16:52 - models.bert_model - INFO - Epoch 5/10 - Batch 2720/10125 - Loss: 0.2802 - Acc: 94.24% - LR: 1.14e-05
2025-12-15 21:17:07 - models.bert_model - INFO - Epoch 5/10 - Batch 2760/10125 - Loss: 0.1326 - Acc: 94.23% - LR: 1.14e-05
2025-12-15 21:17:21 - models.bert_model - INFO - Epoch 5/10 - Batch 2800/10125 - Loss: 0.2406 - Acc: 94.20% - LR: 1.14e-05
2025-12-15 21:17:36 - models.bert_model - INFO - Epoch 5/10 - Batch 2840/10125 - Loss: 0.2976 - Acc: 94.19% - LR: 1.14e-05
2025-12-15 21:17:51 - models.bert_model - INFO - Epoch 5/10 - Batch 2880/10125 - Loss: 0.1702 - Acc: 94.19% - LR: 1.14e-05
2025-12-15 21:18:05 - models.bert_model - INFO - Epoch 5/10 - Batch 2920/10125 - Loss: 0.1289 - Acc: 94.19% - LR: 1.14e-05
2025-12-15 21:18:20 - models.bert_model - INFO - Epoch 5/10 - Batch 2960/10125 - Loss: 0.5832 - Acc: 94.19% - LR: 1.13e-05
2025-12-15 21:18:34 - models.bert_model - INFO - Epoch 5/10 - Batch 3000/10125 - Loss: 0.2126 - Acc: 94.20% - LR: 1.13e-05
2025-12-15 21:18:49 - models.bert_model - INFO - Epoch 5/10 - Batch 3040/10125 - Loss: 0.1519 - Acc: 94.18% - LR: 1.13e-05
2025-12-15 21:19:03 - models.bert_model - INFO - Epoch 5/10 - Batch 3080/10125 - Loss: 0.1263 - Acc: 94.20% - LR: 1.13e-05
2025-12-15 21:19:18 - models.bert_model - INFO - Epoch 5/10 - Batch 3120/10125 - Loss: 0.1439 - Acc: 94.20% - LR: 1.13e-05
2025-12-15 21:19:32 - models.bert_model - INFO - Epoch 5/10 - Batch 3160/10125 - Loss: 0.1203 - Acc: 94.21% - LR: 1.13e-05
2025-12-15 21:19:47 - models.bert_model - INFO - Epoch 5/10 - Batch 3200/10125 - Loss: 0.6289 - Acc: 94.17% - LR: 1.13e-05
2025-12-15 21:20:01 - models.bert_model - INFO - Epoch 5/10 - Batch 3240/10125 - Loss: 0.1362 - Acc: 94.17% - LR: 1.13e-05
2025-12-15 21:20:16 - models.bert_model - INFO - Epoch 5/10 - Batch 3280/10125 - Loss: 0.1110 - Acc: 94.17% - LR: 1.13e-05
2025-12-15 21:20:30 - models.bert_model - INFO - Epoch 5/10 - Batch 3320/10125 - Loss: 0.2269 - Acc: 94.15% - LR: 1.13e-05
2025-12-15 21:20:45 - models.bert_model - INFO - Epoch 5/10 - Batch 3360/10125 - Loss: 0.3872 - Acc: 94.15% - LR: 1.13e-05
2025-12-15 21:20:59 - models.bert_model - INFO - Epoch 5/10 - Batch 3400/10125 - Loss: 0.1938 - Acc: 94.15% - LR: 1.12e-05
2025-12-15 21:21:14 - models.bert_model - INFO - Epoch 5/10 - Batch 3440/10125 - Loss: 0.1168 - Acc: 94.14% - LR: 1.12e-05
2025-12-15 21:21:28 - models.bert_model - INFO - Epoch 5/10 - Batch 3480/10125 - Loss: 0.1407 - Acc: 94.15% - LR: 1.12e-05
2025-12-15 21:21:43 - models.bert_model - INFO - Epoch 5/10 - Batch 3520/10125 - Loss: 0.1193 - Acc: 94.17% - LR: 1.12e-05
2025-12-15 21:21:57 - models.bert_model - INFO - Epoch 5/10 - Batch 3560/10125 - Loss: 0.1427 - Acc: 94.18% - LR: 1.12e-05
2025-12-15 21:22:12 - models.bert_model - INFO - Epoch 5/10 - Batch 3600/10125 - Loss: 0.1905 - Acc: 94.19% - LR: 1.12e-05
2025-12-15 21:22:26 - models.bert_model - INFO - Epoch 5/10 - Batch 3640/10125 - Loss: 0.1413 - Acc: 94.18% - LR: 1.12e-05
2025-12-15 21:22:41 - models.bert_model - INFO - Epoch 5/10 - Batch 3680/10125 - Loss: 0.2470 - Acc: 94.19% - LR: 1.12e-05
2025-12-15 21:22:55 - models.bert_model - INFO - Epoch 5/10 - Batch 3720/10125 - Loss: 0.3381 - Acc: 94.18% - LR: 1.12e-05
2025-12-15 21:23:10 - models.bert_model - INFO - Epoch 5/10 - Batch 3760/10125 - Loss: 0.1804 - Acc: 94.18% - LR: 1.12e-05
2025-12-15 21:23:24 - models.bert_model - INFO - Epoch 5/10 - Batch 3800/10125 - Loss: 0.1193 - Acc: 94.18% - LR: 1.11e-05
2025-12-15 21:23:39 - models.bert_model - INFO - Epoch 5/10 - Batch 3840/10125 - Loss: 0.1477 - Acc: 94.18% - LR: 1.11e-05
2025-12-15 21:23:54 - models.bert_model - INFO - Epoch 5/10 - Batch 3880/10125 - Loss: 0.1750 - Acc: 94.17% - LR: 1.11e-05
2025-12-15 21:24:08 - models.bert_model - INFO - Epoch 5/10 - Batch 3920/10125 - Loss: 0.1546 - Acc: 94.17% - LR: 1.11e-05
2025-12-15 21:24:23 - models.bert_model - INFO - Epoch 5/10 - Batch 3960/10125 - Loss: 0.1932 - Acc: 94.16% - LR: 1.11e-05
2025-12-15 21:24:37 - models.bert_model - INFO - Epoch 5/10 - Batch 4000/10125 - Loss: 0.1419 - Acc: 94.16% - LR: 1.11e-05
2025-12-15 21:24:52 - models.bert_model - INFO - Epoch 5/10 - Batch 4040/10125 - Loss: 0.1374 - Acc: 94.17% - LR: 1.11e-05
2025-12-15 21:25:06 - models.bert_model - INFO - Epoch 5/10 - Batch 4080/10125 - Loss: 0.1216 - Acc: 94.17% - LR: 1.11e-05
2025-12-15 21:25:21 - models.bert_model - INFO - Epoch 5/10 - Batch 4120/10125 - Loss: 0.1663 - Acc: 94.17% - LR: 1.11e-05
2025-12-15 21:25:35 - models.bert_model - INFO - Epoch 5/10 - Batch 4160/10125 - Loss: 0.2355 - Acc: 94.18% - LR: 1.11e-05
2025-12-15 21:25:50 - models.bert_model - INFO - Epoch 5/10 - Batch 4200/10125 - Loss: 0.1795 - Acc: 94.18% - LR: 1.11e-05
2025-12-15 21:26:05 - models.bert_model - INFO - Epoch 5/10 - Batch 4240/10125 - Loss: 0.1886 - Acc: 94.19% - LR: 1.10e-05
2025-12-15 21:26:19 - models.bert_model - INFO - Epoch 5/10 - Batch 4280/10125 - Loss: 0.2720 - Acc: 94.19% - LR: 1.10e-05
2025-12-15 21:26:34 - models.bert_model - INFO - Epoch 5/10 - Batch 4320/10125 - Loss: 0.2958 - Acc: 94.18% - LR: 1.10e-05
2025-12-15 21:26:48 - models.bert_model - INFO - Epoch 5/10 - Batch 4360/10125 - Loss: 0.1197 - Acc: 94.18% - LR: 1.10e-05
2025-12-15 21:27:03 - models.bert_model - INFO - Epoch 5/10 - Batch 4400/10125 - Loss: 0.4391 - Acc: 94.18% - LR: 1.10e-05
2025-12-15 21:27:17 - models.bert_model - INFO - Epoch 5/10 - Batch 4440/10125 - Loss: 0.4839 - Acc: 94.17% - LR: 1.10e-05
2025-12-15 21:27:32 - models.bert_model - INFO - Epoch 5/10 - Batch 4480/10125 - Loss: 0.1056 - Acc: 94.18% - LR: 1.10e-05
2025-12-15 21:27:46 - models.bert_model - INFO - Epoch 5/10 - Batch 4520/10125 - Loss: 0.3712 - Acc: 94.19% - LR: 1.10e-05
2025-12-15 21:28:01 - models.bert_model - INFO - Epoch 5/10 - Batch 4560/10125 - Loss: 0.2279 - Acc: 94.18% - LR: 1.10e-05
2025-12-15 21:28:15 - models.bert_model - INFO - Epoch 5/10 - Batch 4600/10125 - Loss: 0.2580 - Acc: 94.17% - LR: 1.10e-05
2025-12-15 21:28:30 - models.bert_model - INFO - Epoch 5/10 - Batch 4640/10125 - Loss: 0.1095 - Acc: 94.16% - LR: 1.09e-05
2025-12-15 21:28:44 - models.bert_model - INFO - Epoch 5/10 - Batch 4680/10125 - Loss: 0.2390 - Acc: 94.17% - LR: 1.09e-05
2025-12-15 21:28:59 - models.bert_model - INFO - Epoch 5/10 - Batch 4720/10125 - Loss: 0.1795 - Acc: 94.19% - LR: 1.09e-05
2025-12-15 21:29:13 - models.bert_model - INFO - Epoch 5/10 - Batch 4760/10125 - Loss: 0.3018 - Acc: 94.19% - LR: 1.09e-05
2025-12-15 21:29:28 - models.bert_model - INFO - Epoch 5/10 - Batch 4800/10125 - Loss: 0.1564 - Acc: 94.18% - LR: 1.09e-05
2025-12-15 21:29:43 - models.bert_model - INFO - Epoch 5/10 - Batch 4840/10125 - Loss: 0.1225 - Acc: 94.17% - LR: 1.09e-05
2025-12-15 21:29:57 - models.bert_model - INFO - Epoch 5/10 - Batch 4880/10125 - Loss: 0.1370 - Acc: 94.17% - LR: 1.09e-05
2025-12-15 21:30:12 - models.bert_model - INFO - Epoch 5/10 - Batch 4920/10125 - Loss: 0.1055 - Acc: 94.15% - LR: 1.09e-05
2025-12-15 21:30:26 - models.bert_model - INFO - Epoch 5/10 - Batch 4960/10125 - Loss: 0.1308 - Acc: 94.16% - LR: 1.09e-05
2025-12-15 21:30:41 - models.bert_model - INFO - Epoch 5/10 - Batch 5000/10125 - Loss: 0.1360 - Acc: 94.16% - LR: 1.09e-05
2025-12-15 21:30:55 - models.bert_model - INFO - Epoch 5/10 - Batch 5040/10125 - Loss: 0.5313 - Acc: 94.15% - LR: 1.08e-05
2025-12-15 21:31:10 - models.bert_model - INFO - Epoch 5/10 - Batch 5080/10125 - Loss: 0.4049 - Acc: 94.15% - LR: 1.08e-05
2025-12-15 21:31:24 - models.bert_model - INFO - Epoch 5/10 - Batch 5120/10125 - Loss: 0.2197 - Acc: 94.15% - LR: 1.08e-05
2025-12-15 21:31:39 - models.bert_model - INFO - Epoch 5/10 - Batch 5160/10125 - Loss: 0.2439 - Acc: 94.14% - LR: 1.08e-05
2025-12-15 21:31:53 - models.bert_model - INFO - Epoch 5/10 - Batch 5200/10125 - Loss: 0.5113 - Acc: 94.14% - LR: 1.08e-05
2025-12-15 21:32:08 - models.bert_model - INFO - Epoch 5/10 - Batch 5240/10125 - Loss: 0.1611 - Acc: 94.14% - LR: 1.08e-05
2025-12-15 21:32:22 - models.bert_model - INFO - Epoch 5/10 - Batch 5280/10125 - Loss: 0.2770 - Acc: 94.13% - LR: 1.08e-05
2025-12-15 21:32:37 - models.bert_model - INFO - Epoch 5/10 - Batch 5320/10125 - Loss: 0.4669 - Acc: 94.13% - LR: 1.08e-05
2025-12-15 21:32:51 - models.bert_model - INFO - Epoch 5/10 - Batch 5360/10125 - Loss: 0.1601 - Acc: 94.12% - LR: 1.08e-05
2025-12-15 21:33:06 - models.bert_model - INFO - Epoch 5/10 - Batch 5400/10125 - Loss: 0.2039 - Acc: 94.12% - LR: 1.08e-05
2025-12-15 21:33:20 - models.bert_model - INFO - Epoch 5/10 - Batch 5440/10125 - Loss: 0.1524 - Acc: 94.13% - LR: 1.08e-05
2025-12-15 21:33:35 - models.bert_model - INFO - Epoch 5/10 - Batch 5480/10125 - Loss: 0.2716 - Acc: 94.14% - LR: 1.07e-05
2025-12-15 21:33:49 - models.bert_model - INFO - Epoch 5/10 - Batch 5520/10125 - Loss: 0.3334 - Acc: 94.15% - LR: 1.07e-05
2025-12-15 21:34:04 - models.bert_model - INFO - Epoch 5/10 - Batch 5560/10125 - Loss: 0.2790 - Acc: 94.16% - LR: 1.07e-05
2025-12-15 21:34:18 - models.bert_model - INFO - Epoch 5/10 - Batch 5600/10125 - Loss: 0.2400 - Acc: 94.16% - LR: 1.07e-05
2025-12-15 21:34:33 - models.bert_model - INFO - Epoch 5/10 - Batch 5640/10125 - Loss: 0.1428 - Acc: 94.16% - LR: 1.07e-05
2025-12-15 21:34:47 - models.bert_model - INFO - Epoch 5/10 - Batch 5680/10125 - Loss: 0.2376 - Acc: 94.15% - LR: 1.07e-05
2025-12-15 21:35:02 - models.bert_model - INFO - Epoch 5/10 - Batch 5720/10125 - Loss: 0.2047 - Acc: 94.15% - LR: 1.07e-05
2025-12-15 21:35:17 - models.bert_model - INFO - Epoch 5/10 - Batch 5760/10125 - Loss: 0.1891 - Acc: 94.16% - LR: 1.07e-05
2025-12-15 21:35:31 - models.bert_model - INFO - Epoch 5/10 - Batch 5800/10125 - Loss: 0.3909 - Acc: 94.15% - LR: 1.07e-05
2025-12-15 21:35:46 - models.bert_model - INFO - Epoch 5/10 - Batch 5840/10125 - Loss: 0.2974 - Acc: 94.16% - LR: 1.07e-05
2025-12-15 21:36:00 - models.bert_model - INFO - Epoch 5/10 - Batch 5880/10125 - Loss: 0.1207 - Acc: 94.16% - LR: 1.06e-05
2025-12-15 21:36:15 - models.bert_model - INFO - Epoch 5/10 - Batch 5920/10125 - Loss: 0.1072 - Acc: 94.15% - LR: 1.06e-05
2025-12-15 21:36:29 - models.bert_model - INFO - Epoch 5/10 - Batch 5960/10125 - Loss: 0.1153 - Acc: 94.16% - LR: 1.06e-05
2025-12-15 21:36:44 - models.bert_model - INFO - Epoch 5/10 - Batch 6000/10125 - Loss: 0.3135 - Acc: 94.16% - LR: 1.06e-05
2025-12-15 21:36:58 - models.bert_model - INFO - Epoch 5/10 - Batch 6040/10125 - Loss: 0.1112 - Acc: 94.16% - LR: 1.06e-05
2025-12-15 21:37:13 - models.bert_model - INFO - Epoch 5/10 - Batch 6080/10125 - Loss: 0.2832 - Acc: 94.15% - LR: 1.06e-05
2025-12-15 21:37:27 - models.bert_model - INFO - Epoch 5/10 - Batch 6120/10125 - Loss: 0.1492 - Acc: 94.15% - LR: 1.06e-05
2025-12-15 21:37:42 - models.bert_model - INFO - Epoch 5/10 - Batch 6160/10125 - Loss: 0.5427 - Acc: 94.15% - LR: 1.06e-05
2025-12-15 21:37:56 - models.bert_model - INFO - Epoch 5/10 - Batch 6200/10125 - Loss: 0.1912 - Acc: 94.16% - LR: 1.06e-05
2025-12-15 21:38:11 - models.bert_model - INFO - Epoch 5/10 - Batch 6240/10125 - Loss: 0.4425 - Acc: 94.16% - LR: 1.06e-05
2025-12-15 21:38:25 - models.bert_model - INFO - Epoch 5/10 - Batch 6280/10125 - Loss: 0.1872 - Acc: 94.16% - LR: 1.05e-05
2025-12-15 21:38:40 - models.bert_model - INFO - Epoch 5/10 - Batch 6320/10125 - Loss: 0.5549 - Acc: 94.16% - LR: 1.05e-05
2025-12-15 21:38:54 - models.bert_model - INFO - Epoch 5/10 - Batch 6360/10125 - Loss: 0.1153 - Acc: 94.17% - LR: 1.05e-05
2025-12-15 21:39:09 - models.bert_model - INFO - Epoch 5/10 - Batch 6400/10125 - Loss: 0.1497 - Acc: 94.17% - LR: 1.05e-05
2025-12-15 21:39:24 - models.bert_model - INFO - Epoch 5/10 - Batch 6440/10125 - Loss: 0.2678 - Acc: 94.18% - LR: 1.05e-05
2025-12-15 21:39:38 - models.bert_model - INFO - Epoch 5/10 - Batch 6480/10125 - Loss: 0.2041 - Acc: 94.18% - LR: 1.05e-05
2025-12-15 21:39:53 - models.bert_model - INFO - Epoch 5/10 - Batch 6520/10125 - Loss: 0.2091 - Acc: 94.18% - LR: 1.05e-05
2025-12-15 21:40:07 - models.bert_model - INFO - Epoch 5/10 - Batch 6560/10125 - Loss: 0.1172 - Acc: 94.19% - LR: 1.05e-05
2025-12-15 21:40:22 - models.bert_model - INFO - Epoch 5/10 - Batch 6600/10125 - Loss: 0.1605 - Acc: 94.19% - LR: 1.05e-05
2025-12-15 21:40:36 - models.bert_model - INFO - Epoch 5/10 - Batch 6640/10125 - Loss: 0.1711 - Acc: 94.19% - LR: 1.05e-05
2025-12-15 21:40:51 - models.bert_model - INFO - Epoch 5/10 - Batch 6680/10125 - Loss: 0.4007 - Acc: 94.20% - LR: 1.04e-05
2025-12-15 21:41:05 - models.bert_model - INFO - Epoch 5/10 - Batch 6720/10125 - Loss: 0.1706 - Acc: 94.20% - LR: 1.04e-05
2025-12-15 21:41:20 - models.bert_model - INFO - Epoch 5/10 - Batch 6760/10125 - Loss: 0.1465 - Acc: 94.20% - LR: 1.04e-05
2025-12-15 21:41:34 - models.bert_model - INFO - Epoch 5/10 - Batch 6800/10125 - Loss: 0.1523 - Acc: 94.20% - LR: 1.04e-05
2025-12-15 21:41:49 - models.bert_model - INFO - Epoch 5/10 - Batch 6840/10125 - Loss: 0.3483 - Acc: 94.20% - LR: 1.04e-05
2025-12-15 21:42:03 - models.bert_model - INFO - Epoch 5/10 - Batch 6880/10125 - Loss: 0.2193 - Acc: 94.20% - LR: 1.04e-05
2025-12-15 21:42:18 - models.bert_model - INFO - Epoch 5/10 - Batch 6920/10125 - Loss: 0.1069 - Acc: 94.21% - LR: 1.04e-05
2025-12-15 21:42:32 - models.bert_model - INFO - Epoch 5/10 - Batch 6960/10125 - Loss: 0.2353 - Acc: 94.19% - LR: 1.04e-05
2025-12-15 21:42:47 - models.bert_model - INFO - Epoch 5/10 - Batch 7000/10125 - Loss: 0.2368 - Acc: 94.20% - LR: 1.04e-05
2025-12-15 21:43:01 - models.bert_model - INFO - Epoch 5/10 - Batch 7040/10125 - Loss: 0.1335 - Acc: 94.20% - LR: 1.04e-05
2025-12-15 21:43:16 - models.bert_model - INFO - Epoch 5/10 - Batch 7080/10125 - Loss: 0.1122 - Acc: 94.21% - LR: 1.03e-05
2025-12-15 21:43:31 - models.bert_model - INFO - Epoch 5/10 - Batch 7120/10125 - Loss: 0.5836 - Acc: 94.20% - LR: 1.03e-05
2025-12-15 21:43:45 - models.bert_model - INFO - Epoch 5/10 - Batch 7160/10125 - Loss: 0.1439 - Acc: 94.20% - LR: 1.03e-05
2025-12-15 21:44:00 - models.bert_model - INFO - Epoch 5/10 - Batch 7200/10125 - Loss: 0.4265 - Acc: 94.21% - LR: 1.03e-05
2025-12-15 21:44:14 - models.bert_model - INFO - Epoch 5/10 - Batch 7240/10125 - Loss: 0.1908 - Acc: 94.20% - LR: 1.03e-05
2025-12-15 21:44:29 - models.bert_model - INFO - Epoch 5/10 - Batch 7280/10125 - Loss: 0.1728 - Acc: 94.20% - LR: 1.03e-05
2025-12-15 21:44:43 - models.bert_model - INFO - Epoch 5/10 - Batch 7320/10125 - Loss: 0.1997 - Acc: 94.20% - LR: 1.03e-05
2025-12-15 21:44:58 - models.bert_model - INFO - Epoch 5/10 - Batch 7360/10125 - Loss: 0.2477 - Acc: 94.20% - LR: 1.03e-05
2025-12-15 21:45:12 - models.bert_model - INFO - Epoch 5/10 - Batch 7400/10125 - Loss: 0.1165 - Acc: 94.21% - LR: 1.03e-05
2025-12-15 21:45:27 - models.bert_model - INFO - Epoch 5/10 - Batch 7440/10125 - Loss: 0.2522 - Acc: 94.22% - LR: 1.02e-05
2025-12-15 21:45:41 - models.bert_model - INFO - Epoch 5/10 - Batch 7480/10125 - Loss: 0.1340 - Acc: 94.21% - LR: 1.02e-05
2025-12-15 21:45:56 - models.bert_model - INFO - Epoch 5/10 - Batch 7520/10125 - Loss: 0.1167 - Acc: 94.21% - LR: 1.02e-05
2025-12-15 21:46:10 - models.bert_model - INFO - Epoch 5/10 - Batch 7560/10125 - Loss: 0.1463 - Acc: 94.22% - LR: 1.02e-05
2025-12-15 21:46:25 - models.bert_model - INFO - Epoch 5/10 - Batch 7600/10125 - Loss: 0.1333 - Acc: 94.22% - LR: 1.02e-05
2025-12-15 21:46:39 - models.bert_model - INFO - Epoch 5/10 - Batch 7640/10125 - Loss: 0.2254 - Acc: 94.21% - LR: 1.02e-05
2025-12-15 21:46:54 - models.bert_model - INFO - Epoch 5/10 - Batch 7680/10125 - Loss: 0.1754 - Acc: 94.21% - LR: 1.02e-05
2025-12-15 21:47:08 - models.bert_model - INFO - Epoch 5/10 - Batch 7720/10125 - Loss: 0.3660 - Acc: 94.21% - LR: 1.02e-05
2025-12-15 21:47:23 - models.bert_model - INFO - Epoch 5/10 - Batch 7760/10125 - Loss: 0.4576 - Acc: 94.21% - LR: 1.02e-05
2025-12-15 21:47:37 - models.bert_model - INFO - Epoch 5/10 - Batch 7800/10125 - Loss: 0.1251 - Acc: 94.20% - LR: 1.02e-05
2025-12-15 21:47:52 - models.bert_model - INFO - Epoch 5/10 - Batch 7840/10125 - Loss: 0.1884 - Acc: 94.21% - LR: 1.01e-05
2025-12-15 21:48:06 - models.bert_model - INFO - Epoch 5/10 - Batch 7880/10125 - Loss: 0.1302 - Acc: 94.20% - LR: 1.01e-05
2025-12-15 21:48:21 - models.bert_model - INFO - Epoch 5/10 - Batch 7920/10125 - Loss: 0.1359 - Acc: 94.21% - LR: 1.01e-05
2025-12-15 21:48:35 - models.bert_model - INFO - Epoch 5/10 - Batch 7960/10125 - Loss: 0.1160 - Acc: 94.21% - LR: 1.01e-05
2025-12-15 21:48:50 - models.bert_model - INFO - Epoch 5/10 - Batch 8000/10125 - Loss: 0.1563 - Acc: 94.22% - LR: 1.01e-05
2025-12-15 21:49:04 - models.bert_model - INFO - Epoch 5/10 - Batch 8040/10125 - Loss: 0.3009 - Acc: 94.22% - LR: 1.01e-05
2025-12-15 21:49:19 - models.bert_model - INFO - Epoch 5/10 - Batch 8080/10125 - Loss: 0.4048 - Acc: 94.22% - LR: 1.01e-05
2025-12-15 21:49:34 - models.bert_model - INFO - Epoch 5/10 - Batch 8120/10125 - Loss: 0.1127 - Acc: 94.21% - LR: 1.01e-05
2025-12-15 21:49:48 - models.bert_model - INFO - Epoch 5/10 - Batch 8160/10125 - Loss: 0.2690 - Acc: 94.21% - LR: 1.01e-05
2025-12-15 21:50:03 - models.bert_model - INFO - Epoch 5/10 - Batch 8200/10125 - Loss: 0.1388 - Acc: 94.21% - LR: 1.01e-05
2025-12-15 21:50:17 - models.bert_model - INFO - Epoch 5/10 - Batch 8240/10125 - Loss: 0.2246 - Acc: 94.21% - LR: 1.00e-05
2025-12-15 21:50:32 - models.bert_model - INFO - Epoch 5/10 - Batch 8280/10125 - Loss: 0.1314 - Acc: 94.21% - LR: 1.00e-05
2025-12-15 21:50:46 - models.bert_model - INFO - Epoch 5/10 - Batch 8320/10125 - Loss: 0.4636 - Acc: 94.21% - LR: 1.00e-05
2025-12-15 21:51:01 - models.bert_model - INFO - Epoch 5/10 - Batch 8360/10125 - Loss: 0.4991 - Acc: 94.21% - LR: 1.00e-05
2025-12-15 21:51:15 - models.bert_model - INFO - Epoch 5/10 - Batch 8400/10125 - Loss: 0.2184 - Acc: 94.21% - LR: 1.00e-05
2025-12-15 21:51:30 - models.bert_model - INFO - Epoch 5/10 - Batch 8440/10125 - Loss: 0.1138 - Acc: 94.20% - LR: 9.99e-06
2025-12-15 21:51:44 - models.bert_model - INFO - Epoch 5/10 - Batch 8480/10125 - Loss: 0.1276 - Acc: 94.20% - LR: 9.98e-06
2025-12-15 21:51:59 - models.bert_model - INFO - Epoch 5/10 - Batch 8520/10125 - Loss: 0.1137 - Acc: 94.20% - LR: 9.97e-06
2025-12-15 21:52:13 - models.bert_model - INFO - Epoch 5/10 - Batch 8560/10125 - Loss: 0.3968 - Acc: 94.20% - LR: 9.96e-06
2025-12-15 21:52:28 - models.bert_model - INFO - Epoch 5/10 - Batch 8600/10125 - Loss: 0.1231 - Acc: 94.20% - LR: 9.95e-06
2025-12-15 21:52:42 - models.bert_model - INFO - Epoch 5/10 - Batch 8640/10125 - Loss: 0.2121 - Acc: 94.20% - LR: 9.94e-06
2025-12-15 21:52:57 - models.bert_model - INFO - Epoch 5/10 - Batch 8680/10125 - Loss: 0.1199 - Acc: 94.20% - LR: 9.93e-06
2025-12-15 21:53:11 - models.bert_model - INFO - Epoch 5/10 - Batch 8720/10125 - Loss: 0.1138 - Acc: 94.20% - LR: 9.92e-06
2025-12-15 21:53:26 - models.bert_model - INFO - Epoch 5/10 - Batch 8760/10125 - Loss: 0.3860 - Acc: 94.20% - LR: 9.91e-06
2025-12-15 21:53:40 - models.bert_model - INFO - Epoch 5/10 - Batch 8800/10125 - Loss: 0.3439 - Acc: 94.21% - LR: 9.90e-06
2025-12-15 21:53:55 - models.bert_model - INFO - Epoch 5/10 - Batch 8840/10125 - Loss: 0.1700 - Acc: 94.21% - LR: 9.89e-06
2025-12-15 21:54:09 - models.bert_model - INFO - Epoch 5/10 - Batch 8880/10125 - Loss: 0.2928 - Acc: 94.21% - LR: 9.88e-06
2025-12-15 21:54:24 - models.bert_model - INFO - Epoch 5/10 - Batch 8920/10125 - Loss: 0.1996 - Acc: 94.21% - LR: 9.87e-06
2025-12-15 21:54:38 - models.bert_model - INFO - Epoch 5/10 - Batch 8960/10125 - Loss: 0.1918 - Acc: 94.21% - LR: 9.86e-06
2025-12-15 21:54:53 - models.bert_model - INFO - Epoch 5/10 - Batch 9000/10125 - Loss: 0.1633 - Acc: 94.21% - LR: 9.85e-06
2025-12-15 21:55:08 - models.bert_model - INFO - Epoch 5/10 - Batch 9040/10125 - Loss: 0.1194 - Acc: 94.21% - LR: 9.84e-06
2025-12-15 21:55:22 - models.bert_model - INFO - Epoch 5/10 - Batch 9080/10125 - Loss: 0.3242 - Acc: 94.21% - LR: 9.83e-06
2025-12-15 21:55:36 - models.bert_model - INFO - Epoch 5/10 - Batch 9120/10125 - Loss: 0.2435 - Acc: 94.21% - LR: 9.82e-06
2025-12-15 21:55:51 - models.bert_model - INFO - Epoch 5/10 - Batch 9160/10125 - Loss: 0.1128 - Acc: 94.21% - LR: 9.81e-06
2025-12-15 21:56:05 - models.bert_model - INFO - Epoch 5/10 - Batch 9200/10125 - Loss: 0.2863 - Acc: 94.21% - LR: 9.80e-06
2025-12-15 21:56:20 - models.bert_model - INFO - Epoch 5/10 - Batch 9240/10125 - Loss: 0.1192 - Acc: 94.20% - LR: 9.78e-06
2025-12-15 21:56:35 - models.bert_model - INFO - Epoch 5/10 - Batch 9280/10125 - Loss: 0.1353 - Acc: 94.20% - LR: 9.77e-06
2025-12-15 21:56:49 - models.bert_model - INFO - Epoch 5/10 - Batch 9320/10125 - Loss: 0.1107 - Acc: 94.19% - LR: 9.76e-06
2025-12-15 21:57:04 - models.bert_model - INFO - Epoch 5/10 - Batch 9360/10125 - Loss: 0.1150 - Acc: 94.19% - LR: 9.75e-06
2025-12-15 21:57:18 - models.bert_model - INFO - Epoch 5/10 - Batch 9400/10125 - Loss: 0.1405 - Acc: 94.19% - LR: 9.74e-06
2025-12-15 21:57:33 - models.bert_model - INFO - Epoch 5/10 - Batch 9440/10125 - Loss: 0.1763 - Acc: 94.19% - LR: 9.73e-06
2025-12-15 21:57:47 - models.bert_model - INFO - Epoch 5/10 - Batch 9480/10125 - Loss: 0.1314 - Acc: 94.19% - LR: 9.72e-06
2025-12-15 21:58:02 - models.bert_model - INFO - Epoch 5/10 - Batch 9520/10125 - Loss: 0.1391 - Acc: 94.20% - LR: 9.71e-06
2025-12-15 21:58:16 - models.bert_model - INFO - Epoch 5/10 - Batch 9560/10125 - Loss: 0.3403 - Acc: 94.19% - LR: 9.70e-06
2025-12-15 21:58:31 - models.bert_model - INFO - Epoch 5/10 - Batch 9600/10125 - Loss: 0.1390 - Acc: 94.19% - LR: 9.69e-06
2025-12-15 21:58:45 - models.bert_model - INFO - Epoch 5/10 - Batch 9640/10125 - Loss: 0.3892 - Acc: 94.19% - LR: 9.68e-06
2025-12-15 21:59:00 - models.bert_model - INFO - Epoch 5/10 - Batch 9680/10125 - Loss: 0.2215 - Acc: 94.19% - LR: 9.67e-06
2025-12-15 21:59:15 - models.bert_model - INFO - Epoch 5/10 - Batch 9720/10125 - Loss: 0.3777 - Acc: 94.19% - LR: 9.66e-06
2025-12-15 21:59:29 - models.bert_model - INFO - Epoch 5/10 - Batch 9760/10125 - Loss: 0.1283 - Acc: 94.20% - LR: 9.65e-06
2025-12-15 21:59:44 - models.bert_model - INFO - Epoch 5/10 - Batch 9800/10125 - Loss: 0.1429 - Acc: 94.20% - LR: 9.64e-06
2025-12-15 21:59:58 - models.bert_model - INFO - Epoch 5/10 - Batch 9840/10125 - Loss: 0.1935 - Acc: 94.20% - LR: 9.63e-06
2025-12-15 22:00:13 - models.bert_model - INFO - Epoch 5/10 - Batch 9880/10125 - Loss: 0.2490 - Acc: 94.21% - LR: 9.62e-06
2025-12-15 22:00:27 - models.bert_model - INFO - Epoch 5/10 - Batch 9920/10125 - Loss: 0.1511 - Acc: 94.21% - LR: 9.61e-06
2025-12-15 22:00:42 - models.bert_model - INFO - Epoch 5/10 - Batch 9960/10125 - Loss: 0.1311 - Acc: 94.21% - LR: 9.60e-06
2025-12-15 22:00:56 - models.bert_model - INFO - Epoch 5/10 - Batch 10000/10125 - Loss: 0.1138 - Acc: 94.21% - LR: 9.59e-06
2025-12-15 22:01:11 - models.bert_model - INFO - Epoch 5/10 - Batch 10040/10125 - Loss: 0.1653 - Acc: 94.22% - LR: 9.58e-06
2025-12-15 22:01:25 - models.bert_model - INFO - Epoch 5/10 - Batch 10080/10125 - Loss: 0.5538 - Acc: 94.21% - LR: 9.56e-06
2025-12-15 22:01:40 - models.bert_model - INFO - Epoch 5/10 - Batch 10120/10125 - Loss: 0.2045 - Acc: 94.21% - LR: 9.55e-06
2025-12-15 22:03:57 - models.bert_model - INFO - Epoch 5/10 - Train Loss: 0.2257, Train Acc: 94.22% - Val Loss: 0.2260, Val Acc: 94.28%
2025-12-15 22:03:57 - models.bert_model - INFO - New best validation accuracy: 94.28%
2025-12-15 22:04:12 - models.bert_model - INFO - Epoch 6/10 - Batch 40/10125 - Loss: 0.3299 - Acc: 94.84% - LR: 9.54e-06
2025-12-15 22:04:26 - models.bert_model - INFO - Epoch 6/10 - Batch 80/10125 - Loss: 0.3391 - Acc: 94.53% - LR: 9.53e-06
2025-12-15 22:04:41 - models.bert_model - INFO - Epoch 6/10 - Batch 120/10125 - Loss: 0.2391 - Acc: 94.79% - LR: 9.52e-06
2025-12-15 22:04:55 - models.bert_model - INFO - Epoch 6/10 - Batch 160/10125 - Loss: 0.2210 - Acc: 94.80% - LR: 9.51e-06
2025-12-15 22:05:10 - models.bert_model - INFO - Epoch 6/10 - Batch 200/10125 - Loss: 0.2272 - Acc: 95.00% - LR: 9.50e-06
2025-12-15 22:05:24 - models.bert_model - INFO - Epoch 6/10 - Batch 240/10125 - Loss: 0.1602 - Acc: 95.03% - LR: 9.49e-06
2025-12-15 22:05:39 - models.bert_model - INFO - Epoch 6/10 - Batch 280/10125 - Loss: 0.2282 - Acc: 94.91% - LR: 9.48e-06
2025-12-15 22:05:53 - models.bert_model - INFO - Epoch 6/10 - Batch 320/10125 - Loss: 0.1773 - Acc: 95.02% - LR: 9.47e-06
2025-12-15 22:06:08 - models.bert_model - INFO - Epoch 6/10 - Batch 360/10125 - Loss: 0.1100 - Acc: 95.03% - LR: 9.46e-06
2025-12-15 22:06:22 - models.bert_model - INFO - Epoch 6/10 - Batch 400/10125 - Loss: 0.3962 - Acc: 94.97% - LR: 9.45e-06
2025-12-15 22:06:37 - models.bert_model - INFO - Epoch 6/10 - Batch 440/10125 - Loss: 0.1704 - Acc: 94.93% - LR: 9.44e-06
2025-12-15 22:06:51 - models.bert_model - INFO - Epoch 6/10 - Batch 480/10125 - Loss: 0.2046 - Acc: 94.82% - LR: 9.43e-06
2025-12-15 22:07:06 - models.bert_model - INFO - Epoch 6/10 - Batch 520/10125 - Loss: 0.1254 - Acc: 94.72% - LR: 9.42e-06
2025-12-15 22:07:21 - models.bert_model - INFO - Epoch 6/10 - Batch 560/10125 - Loss: 0.3706 - Acc: 94.81% - LR: 9.41e-06
2025-12-15 22:07:35 - models.bert_model - INFO - Epoch 6/10 - Batch 600/10125 - Loss: 0.2693 - Acc: 94.92% - LR: 9.39e-06
2025-12-15 22:07:50 - models.bert_model - INFO - Epoch 6/10 - Batch 640/10125 - Loss: 0.1425 - Acc: 94.85% - LR: 9.38e-06
2025-12-15 22:08:04 - models.bert_model - INFO - Epoch 6/10 - Batch 680/10125 - Loss: 0.3194 - Acc: 94.85% - LR: 9.37e-06
2025-12-15 22:08:19 - models.bert_model - INFO - Epoch 6/10 - Batch 720/10125 - Loss: 0.2042 - Acc: 94.83% - LR: 9.36e-06
2025-12-15 22:08:33 - models.bert_model - INFO - Epoch 6/10 - Batch 760/10125 - Loss: 0.2389 - Acc: 94.85% - LR: 9.35e-06
2025-12-15 22:08:48 - models.bert_model - INFO - Epoch 6/10 - Batch 800/10125 - Loss: 0.2292 - Acc: 94.88% - LR: 9.34e-06
2025-12-15 22:09:02 - models.bert_model - INFO - Epoch 6/10 - Batch 840/10125 - Loss: 0.1214 - Acc: 94.87% - LR: 9.33e-06
2025-12-15 22:09:17 - models.bert_model - INFO - Epoch 6/10 - Batch 880/10125 - Loss: 0.1787 - Acc: 95.00% - LR: 9.32e-06
2025-12-15 22:09:31 - models.bert_model - INFO - Epoch 6/10 - Batch 920/10125 - Loss: 0.2032 - Acc: 94.97% - LR: 9.31e-06
2025-12-15 22:09:46 - models.bert_model - INFO - Epoch 6/10 - Batch 960/10125 - Loss: 0.2495 - Acc: 94.98% - LR: 9.30e-06
2025-12-15 22:10:00 - models.bert_model - INFO - Epoch 6/10 - Batch 1000/10125 - Loss: 0.1120 - Acc: 94.92% - LR: 9.29e-06
2025-12-15 22:10:15 - models.bert_model - INFO - Epoch 6/10 - Batch 1040/10125 - Loss: 0.1289 - Acc: 94.84% - LR: 9.28e-06
2025-12-15 22:10:29 - models.bert_model - INFO - Epoch 6/10 - Batch 1080/10125 - Loss: 0.2867 - Acc: 94.82% - LR: 9.27e-06
2025-12-15 22:10:44 - models.bert_model - INFO - Epoch 6/10 - Batch 1120/10125 - Loss: 0.1157 - Acc: 94.83% - LR: 9.26e-06
2025-12-15 22:10:58 - models.bert_model - INFO - Epoch 6/10 - Batch 1160/10125 - Loss: 0.1877 - Acc: 94.81% - LR: 9.25e-06
2025-12-15 22:11:13 - models.bert_model - INFO - Epoch 6/10 - Batch 1200/10125 - Loss: 0.1087 - Acc: 94.80% - LR: 9.24e-06
2025-12-15 22:11:27 - models.bert_model - INFO - Epoch 6/10 - Batch 1240/10125 - Loss: 0.2357 - Acc: 94.82% - LR: 9.22e-06
2025-12-15 22:11:42 - models.bert_model - INFO - Epoch 6/10 - Batch 1280/10125 - Loss: 0.1083 - Acc: 94.82% - LR: 9.21e-06
2025-12-15 22:11:57 - models.bert_model - INFO - Epoch 6/10 - Batch 1320/10125 - Loss: 0.1065 - Acc: 94.79% - LR: 9.20e-06
2025-12-15 22:12:11 - models.bert_model - INFO - Epoch 6/10 - Batch 1360/10125 - Loss: 0.1204 - Acc: 94.78% - LR: 9.19e-06
2025-12-15 22:12:26 - models.bert_model - INFO - Epoch 6/10 - Batch 1400/10125 - Loss: 0.4840 - Acc: 94.76% - LR: 9.18e-06
2025-12-15 22:12:40 - models.bert_model - INFO - Epoch 6/10 - Batch 1440/10125 - Loss: 0.1756 - Acc: 94.77% - LR: 9.17e-06
2025-12-15 22:12:55 - models.bert_model - INFO - Epoch 6/10 - Batch 1480/10125 - Loss: 0.3308 - Acc: 94.75% - LR: 9.16e-06
2025-12-15 22:13:09 - models.bert_model - INFO - Epoch 6/10 - Batch 1520/10125 - Loss: 0.4284 - Acc: 94.72% - LR: 9.15e-06
2025-12-15 22:13:24 - models.bert_model - INFO - Epoch 6/10 - Batch 1560/10125 - Loss: 0.2417 - Acc: 94.74% - LR: 9.14e-06
2025-12-15 22:13:38 - models.bert_model - INFO - Epoch 6/10 - Batch 1600/10125 - Loss: 0.1860 - Acc: 94.74% - LR: 9.13e-06
2025-12-15 22:13:53 - models.bert_model - INFO - Epoch 6/10 - Batch 1640/10125 - Loss: 0.1240 - Acc: 94.75% - LR: 9.12e-06
2025-12-15 22:14:07 - models.bert_model - INFO - Epoch 6/10 - Batch 1680/10125 - Loss: 0.3387 - Acc: 94.75% - LR: 9.11e-06
2025-12-15 22:14:22 - models.bert_model - INFO - Epoch 6/10 - Batch 1720/10125 - Loss: 0.2518 - Acc: 94.71% - LR: 9.10e-06
2025-12-15 22:14:36 - models.bert_model - INFO - Epoch 6/10 - Batch 1760/10125 - Loss: 0.1981 - Acc: 94.69% - LR: 9.09e-06
2025-12-15 22:14:51 - models.bert_model - INFO - Epoch 6/10 - Batch 1800/10125 - Loss: 0.2771 - Acc: 94.73% - LR: 9.07e-06
2025-12-15 22:15:05 - models.bert_model - INFO - Epoch 6/10 - Batch 1840/10125 - Loss: 0.1436 - Acc: 94.71% - LR: 9.06e-06
2025-12-15 22:15:20 - models.bert_model - INFO - Epoch 6/10 - Batch 1880/10125 - Loss: 0.3478 - Acc: 94.72% - LR: 9.05e-06
2025-12-15 22:15:34 - models.bert_model - INFO - Epoch 6/10 - Batch 1920/10125 - Loss: 0.1173 - Acc: 94.73% - LR: 9.04e-06
2025-12-15 22:15:49 - models.bert_model - INFO - Epoch 6/10 - Batch 1960/10125 - Loss: 0.1154 - Acc: 94.75% - LR: 9.03e-06
2025-12-15 22:16:03 - models.bert_model - INFO - Epoch 6/10 - Batch 2000/10125 - Loss: 0.1320 - Acc: 94.77% - LR: 9.02e-06
2025-12-15 22:16:18 - models.bert_model - INFO - Epoch 6/10 - Batch 2040/10125 - Loss: 0.4242 - Acc: 94.76% - LR: 9.01e-06
2025-12-15 22:16:32 - models.bert_model - INFO - Epoch 6/10 - Batch 2080/10125 - Loss: 0.1051 - Acc: 94.74% - LR: 9.00e-06
2025-12-15 22:16:47 - models.bert_model - INFO - Epoch 6/10 - Batch 2120/10125 - Loss: 0.1933 - Acc: 94.74% - LR: 8.99e-06
2025-12-15 22:17:01 - models.bert_model - INFO - Epoch 6/10 - Batch 2160/10125 - Loss: 0.3545 - Acc: 94.73% - LR: 8.98e-06
2025-12-15 22:17:16 - models.bert_model - INFO - Epoch 6/10 - Batch 2200/10125 - Loss: 0.3033 - Acc: 94.71% - LR: 8.97e-06
2025-12-15 22:17:30 - models.bert_model - INFO - Epoch 6/10 - Batch 2240/10125 - Loss: 0.1208 - Acc: 94.73% - LR: 8.96e-06
2025-12-15 22:17:45 - models.bert_model - INFO - Epoch 6/10 - Batch 2280/10125 - Loss: 0.1135 - Acc: 94.74% - LR: 8.95e-06
2025-12-15 22:17:59 - models.bert_model - INFO - Epoch 6/10 - Batch 2320/10125 - Loss: 0.3142 - Acc: 94.74% - LR: 8.94e-06
2025-12-15 22:18:14 - models.bert_model - INFO - Epoch 6/10 - Batch 2360/10125 - Loss: 0.1254 - Acc: 94.74% - LR: 8.92e-06
2025-12-15 22:18:28 - models.bert_model - INFO - Epoch 6/10 - Batch 2400/10125 - Loss: 0.3494 - Acc: 94.73% - LR: 8.91e-06
2025-12-15 22:18:43 - models.bert_model - INFO - Epoch 6/10 - Batch 2440/10125 - Loss: 0.1229 - Acc: 94.72% - LR: 8.90e-06
2025-12-15 22:18:57 - models.bert_model - INFO - Epoch 6/10 - Batch 2480/10125 - Loss: 0.3586 - Acc: 94.73% - LR: 8.89e-06
2025-12-15 22:19:12 - models.bert_model - INFO - Epoch 6/10 - Batch 2520/10125 - Loss: 0.1734 - Acc: 94.74% - LR: 8.88e-06
2025-12-15 22:19:26 - models.bert_model - INFO - Epoch 6/10 - Batch 2560/10125 - Loss: 0.2384 - Acc: 94.74% - LR: 8.87e-06
2025-12-15 22:19:41 - models.bert_model - INFO - Epoch 6/10 - Batch 2600/10125 - Loss: 0.1508 - Acc: 94.74% - LR: 8.86e-06
2025-12-15 22:19:56 - models.bert_model - INFO - Epoch 6/10 - Batch 2640/10125 - Loss: 0.1233 - Acc: 94.76% - LR: 8.85e-06
2025-12-15 22:20:10 - models.bert_model - INFO - Epoch 6/10 - Batch 2680/10125 - Loss: 0.2927 - Acc: 94.76% - LR: 8.84e-06
2025-12-15 22:20:25 - models.bert_model - INFO - Epoch 6/10 - Batch 2720/10125 - Loss: 0.2269 - Acc: 94.77% - LR: 8.83e-06
2025-12-15 22:20:39 - models.bert_model - INFO - Epoch 6/10 - Batch 2760/10125 - Loss: 0.1277 - Acc: 94.78% - LR: 8.82e-06
2025-12-15 22:20:54 - models.bert_model - INFO - Epoch 6/10 - Batch 2800/10125 - Loss: 0.1218 - Acc: 94.77% - LR: 8.81e-06
2025-12-15 22:21:08 - models.bert_model - INFO - Epoch 6/10 - Batch 2840/10125 - Loss: 0.1091 - Acc: 94.78% - LR: 8.80e-06
2025-12-15 22:21:23 - models.bert_model - INFO - Epoch 6/10 - Batch 2880/10125 - Loss: 0.2669 - Acc: 94.79% - LR: 8.78e-06
2025-12-15 22:21:37 - models.bert_model - INFO - Epoch 6/10 - Batch 2920/10125 - Loss: 0.1687 - Acc: 94.79% - LR: 8.77e-06
2025-12-15 22:21:52 - models.bert_model - INFO - Epoch 6/10 - Batch 2960/10125 - Loss: 0.3135 - Acc: 94.78% - LR: 8.76e-06
2025-12-15 22:22:06 - models.bert_model - INFO - Epoch 6/10 - Batch 3000/10125 - Loss: 0.2939 - Acc: 94.78% - LR: 8.75e-06
2025-12-15 22:22:21 - models.bert_model - INFO - Epoch 6/10 - Batch 3040/10125 - Loss: 0.2197 - Acc: 94.78% - LR: 8.74e-06
2025-12-15 22:22:35 - models.bert_model - INFO - Epoch 6/10 - Batch 3080/10125 - Loss: 0.3448 - Acc: 94.75% - LR: 8.73e-06
2025-12-15 22:22:50 - models.bert_model - INFO - Epoch 6/10 - Batch 3120/10125 - Loss: 0.1110 - Acc: 94.73% - LR: 8.72e-06
2025-12-15 22:23:04 - models.bert_model - INFO - Epoch 6/10 - Batch 3160/10125 - Loss: 0.1172 - Acc: 94.73% - LR: 8.71e-06
2025-12-15 22:23:19 - models.bert_model - INFO - Epoch 6/10 - Batch 3200/10125 - Loss: 0.5052 - Acc: 94.73% - LR: 8.70e-06
2025-12-15 22:23:33 - models.bert_model - INFO - Epoch 6/10 - Batch 3240/10125 - Loss: 0.1446 - Acc: 94.72% - LR: 8.69e-06
2025-12-15 22:23:48 - models.bert_model - INFO - Epoch 6/10 - Batch 3280/10125 - Loss: 0.2112 - Acc: 94.71% - LR: 8.68e-06
2025-12-15 22:24:02 - models.bert_model - INFO - Epoch 6/10 - Batch 3320/10125 - Loss: 0.1223 - Acc: 94.70% - LR: 8.67e-06
2025-12-15 22:24:17 - models.bert_model - INFO - Epoch 6/10 - Batch 3360/10125 - Loss: 0.2654 - Acc: 94.70% - LR: 8.66e-06
2025-12-15 22:24:31 - models.bert_model - INFO - Epoch 6/10 - Batch 3400/10125 - Loss: 0.1185 - Acc: 94.70% - LR: 8.64e-06
2025-12-15 22:24:46 - models.bert_model - INFO - Epoch 6/10 - Batch 3440/10125 - Loss: 0.2728 - Acc: 94.69% - LR: 8.63e-06
2025-12-15 22:25:00 - models.bert_model - INFO - Epoch 6/10 - Batch 3480/10125 - Loss: 0.1442 - Acc: 94.70% - LR: 8.62e-06
2025-12-15 22:25:15 - models.bert_model - INFO - Epoch 6/10 - Batch 3520/10125 - Loss: 0.1404 - Acc: 94.71% - LR: 8.61e-06
2025-12-15 22:25:29 - models.bert_model - INFO - Epoch 6/10 - Batch 3560/10125 - Loss: 0.1217 - Acc: 94.73% - LR: 8.60e-06
2025-12-15 22:25:44 - models.bert_model - INFO - Epoch 6/10 - Batch 3600/10125 - Loss: 0.1825 - Acc: 94.72% - LR: 8.59e-06
2025-12-15 22:25:58 - models.bert_model - INFO - Epoch 6/10 - Batch 3640/10125 - Loss: 0.1745 - Acc: 94.72% - LR: 8.58e-06
2025-12-15 22:26:13 - models.bert_model - INFO - Epoch 6/10 - Batch 3680/10125 - Loss: 0.1434 - Acc: 94.72% - LR: 8.57e-06
2025-12-15 22:26:27 - models.bert_model - INFO - Epoch 6/10 - Batch 3720/10125 - Loss: 0.1349 - Acc: 94.72% - LR: 8.56e-06
2025-12-15 22:26:42 - models.bert_model - INFO - Epoch 6/10 - Batch 3760/10125 - Loss: 0.1537 - Acc: 94.72% - LR: 8.55e-06
2025-12-15 22:26:56 - models.bert_model - INFO - Epoch 6/10 - Batch 3800/10125 - Loss: 0.1311 - Acc: 94.73% - LR: 8.54e-06
2025-12-15 22:27:11 - models.bert_model - INFO - Epoch 6/10 - Batch 3840/10125 - Loss: 0.3711 - Acc: 94.74% - LR: 8.53e-06
2025-12-15 22:27:25 - models.bert_model - INFO - Epoch 6/10 - Batch 3880/10125 - Loss: 0.2503 - Acc: 94.75% - LR: 8.51e-06
2025-12-15 22:27:40 - models.bert_model - INFO - Epoch 6/10 - Batch 3920/10125 - Loss: 0.3235 - Acc: 94.75% - LR: 8.50e-06
2025-12-15 22:27:54 - models.bert_model - INFO - Epoch 6/10 - Batch 3960/10125 - Loss: 0.3513 - Acc: 94.75% - LR: 8.49e-06
2025-12-15 22:28:09 - models.bert_model - INFO - Epoch 6/10 - Batch 4000/10125 - Loss: 0.1083 - Acc: 94.72% - LR: 8.48e-06
2025-12-15 22:28:24 - models.bert_model - INFO - Epoch 6/10 - Batch 4040/10125 - Loss: 0.1489 - Acc: 94.73% - LR: 8.47e-06
2025-12-15 22:28:38 - models.bert_model - INFO - Epoch 6/10 - Batch 4080/10125 - Loss: 0.2753 - Acc: 94.72% - LR: 8.46e-06
2025-12-15 22:28:53 - models.bert_model - INFO - Epoch 6/10 - Batch 4120/10125 - Loss: 0.1183 - Acc: 94.72% - LR: 8.45e-06
2025-12-15 22:29:07 - models.bert_model - INFO - Epoch 6/10 - Batch 4160/10125 - Loss: 0.1328 - Acc: 94.73% - LR: 8.44e-06
2025-12-15 22:29:22 - models.bert_model - INFO - Epoch 6/10 - Batch 4200/10125 - Loss: 0.5163 - Acc: 94.73% - LR: 8.43e-06
2025-12-15 22:29:36 - models.bert_model - INFO - Epoch 6/10 - Batch 4240/10125 - Loss: 0.1496 - Acc: 94.73% - LR: 8.42e-06
2025-12-15 22:29:51 - models.bert_model - INFO - Epoch 6/10 - Batch 4280/10125 - Loss: 0.3561 - Acc: 94.73% - LR: 8.41e-06
2025-12-15 22:30:05 - models.bert_model - INFO - Epoch 6/10 - Batch 4320/10125 - Loss: 0.2440 - Acc: 94.73% - LR: 8.39e-06
2025-12-15 22:30:20 - models.bert_model - INFO - Epoch 6/10 - Batch 4360/10125 - Loss: 0.3027 - Acc: 94.73% - LR: 8.38e-06
2025-12-15 22:30:34 - models.bert_model - INFO - Epoch 6/10 - Batch 4400/10125 - Loss: 0.2655 - Acc: 94.73% - LR: 8.37e-06
2025-12-15 22:30:49 - models.bert_model - INFO - Epoch 6/10 - Batch 4440/10125 - Loss: 0.4176 - Acc: 94.73% - LR: 8.36e-06
2025-12-15 22:31:03 - models.bert_model - INFO - Epoch 6/10 - Batch 4480/10125 - Loss: 0.5118 - Acc: 94.72% - LR: 8.35e-06
2025-12-15 22:31:18 - models.bert_model - INFO - Epoch 6/10 - Batch 4520/10125 - Loss: 0.2950 - Acc: 94.72% - LR: 8.34e-06
2025-12-15 22:31:32 - models.bert_model - INFO - Epoch 6/10 - Batch 4560/10125 - Loss: 0.1369 - Acc: 94.73% - LR: 8.33e-06
2025-12-15 22:31:47 - models.bert_model - INFO - Epoch 6/10 - Batch 4600/10125 - Loss: 0.1069 - Acc: 94.75% - LR: 8.32e-06
2025-12-15 22:32:01 - models.bert_model - INFO - Epoch 6/10 - Batch 4640/10125 - Loss: 0.1710 - Acc: 94.74% - LR: 8.31e-06
2025-12-15 22:32:16 - models.bert_model - INFO - Epoch 6/10 - Batch 4680/10125 - Loss: 0.2037 - Acc: 94.73% - LR: 8.30e-06
2025-12-15 22:32:30 - models.bert_model - INFO - Epoch 6/10 - Batch 4720/10125 - Loss: 0.2021 - Acc: 94.72% - LR: 8.29e-06
2025-12-15 22:32:45 - models.bert_model - INFO - Epoch 6/10 - Batch 4760/10125 - Loss: 0.3507 - Acc: 94.71% - LR: 8.28e-06
2025-12-15 22:32:59 - models.bert_model - INFO - Epoch 6/10 - Batch 4800/10125 - Loss: 0.1743 - Acc: 94.71% - LR: 8.26e-06
2025-12-15 22:33:14 - models.bert_model - INFO - Epoch 6/10 - Batch 4840/10125 - Loss: 0.1322 - Acc: 94.72% - LR: 8.25e-06
2025-12-15 22:33:28 - models.bert_model - INFO - Epoch 6/10 - Batch 4880/10125 - Loss: 0.1548 - Acc: 94.71% - LR: 8.24e-06
2025-12-15 22:33:43 - models.bert_model - INFO - Epoch 6/10 - Batch 4920/10125 - Loss: 0.1713 - Acc: 94.72% - LR: 8.23e-06
2025-12-15 22:33:57 - models.bert_model - INFO - Epoch 6/10 - Batch 4960/10125 - Loss: 0.3479 - Acc: 94.72% - LR: 8.22e-06
2025-12-15 22:34:12 - models.bert_model - INFO - Epoch 6/10 - Batch 5000/10125 - Loss: 0.4257 - Acc: 94.74% - LR: 8.21e-06
2025-12-15 22:34:26 - models.bert_model - INFO - Epoch 6/10 - Batch 5040/10125 - Loss: 0.1162 - Acc: 94.74% - LR: 8.20e-06
2025-12-15 22:34:41 - models.bert_model - INFO - Epoch 6/10 - Batch 5080/10125 - Loss: 0.3875 - Acc: 94.75% - LR: 8.19e-06
2025-12-15 22:34:55 - models.bert_model - INFO - Epoch 6/10 - Batch 5120/10125 - Loss: 0.1915 - Acc: 94.75% - LR: 8.18e-06
2025-12-15 22:35:10 - models.bert_model - INFO - Epoch 6/10 - Batch 5160/10125 - Loss: 0.1397 - Acc: 94.75% - LR: 8.17e-06
2025-12-15 22:35:24 - models.bert_model - INFO - Epoch 6/10 - Batch 5200/10125 - Loss: 0.1450 - Acc: 94.76% - LR: 8.16e-06
2025-12-15 22:35:39 - models.bert_model - INFO - Epoch 6/10 - Batch 5240/10125 - Loss: 0.1852 - Acc: 94.77% - LR: 8.14e-06
2025-12-15 22:35:54 - models.bert_model - INFO - Epoch 6/10 - Batch 5280/10125 - Loss: 0.1475 - Acc: 94.77% - LR: 8.13e-06
2025-12-15 22:36:08 - models.bert_model - INFO - Epoch 6/10 - Batch 5320/10125 - Loss: 0.1210 - Acc: 94.77% - LR: 8.12e-06
2025-12-15 22:36:23 - models.bert_model - INFO - Epoch 6/10 - Batch 5360/10125 - Loss: 0.1388 - Acc: 94.78% - LR: 8.11e-06
2025-12-15 22:36:37 - models.bert_model - INFO - Epoch 6/10 - Batch 5400/10125 - Loss: 0.1540 - Acc: 94.79% - LR: 8.10e-06
2025-12-15 22:36:52 - models.bert_model - INFO - Epoch 6/10 - Batch 5440/10125 - Loss: 0.5212 - Acc: 94.78% - LR: 8.09e-06
2025-12-15 22:37:06 - models.bert_model - INFO - Epoch 6/10 - Batch 5480/10125 - Loss: 0.1296 - Acc: 94.79% - LR: 8.08e-06
2025-12-15 22:37:21 - models.bert_model - INFO - Epoch 6/10 - Batch 5520/10125 - Loss: 0.1210 - Acc: 94.79% - LR: 8.07e-06
2025-12-15 22:37:35 - models.bert_model - INFO - Epoch 6/10 - Batch 5560/10125 - Loss: 0.1262 - Acc: 94.80% - LR: 8.06e-06
2025-12-15 22:37:50 - models.bert_model - INFO - Epoch 6/10 - Batch 5600/10125 - Loss: 0.1187 - Acc: 94.80% - LR: 8.05e-06
2025-12-15 22:38:04 - models.bert_model - INFO - Epoch 6/10 - Batch 5640/10125 - Loss: 0.2201 - Acc: 94.79% - LR: 8.04e-06
2025-12-15 22:38:19 - models.bert_model - INFO - Epoch 6/10 - Batch 5680/10125 - Loss: 0.1631 - Acc: 94.79% - LR: 8.02e-06
2025-12-15 22:38:33 - models.bert_model - INFO - Epoch 6/10 - Batch 5720/10125 - Loss: 0.1478 - Acc: 94.79% - LR: 8.01e-06
2025-12-15 22:38:48 - models.bert_model - INFO - Epoch 6/10 - Batch 5760/10125 - Loss: 0.1354 - Acc: 94.79% - LR: 8.00e-06
2025-12-15 22:39:02 - models.bert_model - INFO - Epoch 6/10 - Batch 5800/10125 - Loss: 0.2439 - Acc: 94.79% - LR: 7.99e-06
2025-12-15 22:39:17 - models.bert_model - INFO - Epoch 6/10 - Batch 5840/10125 - Loss: 0.2316 - Acc: 94.77% - LR: 7.98e-06
2025-12-15 22:39:31 - models.bert_model - INFO - Epoch 6/10 - Batch 5880/10125 - Loss: 0.1674 - Acc: 94.77% - LR: 7.97e-06
2025-12-15 22:39:46 - models.bert_model - INFO - Epoch 6/10 - Batch 5920/10125 - Loss: 0.1249 - Acc: 94.77% - LR: 7.96e-06
2025-12-15 22:40:00 - models.bert_model - INFO - Epoch 6/10 - Batch 5960/10125 - Loss: 0.1725 - Acc: 94.76% - LR: 7.95e-06
2025-12-15 22:40:15 - models.bert_model - INFO - Epoch 6/10 - Batch 6000/10125 - Loss: 0.2713 - Acc: 94.76% - LR: 7.94e-06
2025-12-15 22:40:29 - models.bert_model - INFO - Epoch 6/10 - Batch 6040/10125 - Loss: 0.1894 - Acc: 94.76% - LR: 7.93e-06
2025-12-15 22:40:44 - models.bert_model - INFO - Epoch 6/10 - Batch 6080/10125 - Loss: 0.1810 - Acc: 94.76% - LR: 7.91e-06
2025-12-15 22:40:58 - models.bert_model - INFO - Epoch 6/10 - Batch 6120/10125 - Loss: 0.2150 - Acc: 94.76% - LR: 7.90e-06
2025-12-15 22:41:13 - models.bert_model - INFO - Epoch 6/10 - Batch 6160/10125 - Loss: 0.2678 - Acc: 94.76% - LR: 7.89e-06
2025-12-15 22:41:28 - models.bert_model - INFO - Epoch 6/10 - Batch 6200/10125 - Loss: 0.4410 - Acc: 94.76% - LR: 7.88e-06
2025-12-15 22:41:42 - models.bert_model - INFO - Epoch 6/10 - Batch 6240/10125 - Loss: 0.2354 - Acc: 94.75% - LR: 7.87e-06
2025-12-15 22:41:57 - models.bert_model - INFO - Epoch 6/10 - Batch 6280/10125 - Loss: 0.1456 - Acc: 94.75% - LR: 7.86e-06
2025-12-15 22:42:11 - models.bert_model - INFO - Epoch 6/10 - Batch 6320/10125 - Loss: 0.1171 - Acc: 94.75% - LR: 7.85e-06
2025-12-15 22:42:26 - models.bert_model - INFO - Epoch 6/10 - Batch 6360/10125 - Loss: 0.2975 - Acc: 94.75% - LR: 7.84e-06
2025-12-15 22:42:40 - models.bert_model - INFO - Epoch 6/10 - Batch 6400/10125 - Loss: 0.1243 - Acc: 94.74% - LR: 7.83e-06
2025-12-15 22:42:55 - models.bert_model - INFO - Epoch 6/10 - Batch 6440/10125 - Loss: 0.2361 - Acc: 94.73% - LR: 7.82e-06
2025-12-15 22:43:09 - models.bert_model - INFO - Epoch 6/10 - Batch 6480/10125 - Loss: 0.1696 - Acc: 94.74% - LR: 7.81e-06
2025-12-15 22:43:24 - models.bert_model - INFO - Epoch 6/10 - Batch 6520/10125 - Loss: 0.1090 - Acc: 94.74% - LR: 7.79e-06
2025-12-15 22:43:38 - models.bert_model - INFO - Epoch 6/10 - Batch 6560/10125 - Loss: 0.4001 - Acc: 94.74% - LR: 7.78e-06
2025-12-15 22:43:53 - models.bert_model - INFO - Epoch 6/10 - Batch 6600/10125 - Loss: 0.2336 - Acc: 94.74% - LR: 7.77e-06
2025-12-15 22:44:07 - models.bert_model - INFO - Epoch 6/10 - Batch 6640/10125 - Loss: 0.2133 - Acc: 94.75% - LR: 7.76e-06
2025-12-15 22:44:22 - models.bert_model - INFO - Epoch 6/10 - Batch 6680/10125 - Loss: 0.1322 - Acc: 94.76% - LR: 7.75e-06
2025-12-15 22:44:36 - models.bert_model - INFO - Epoch 6/10 - Batch 6720/10125 - Loss: 0.2619 - Acc: 94.76% - LR: 7.74e-06
2025-12-15 22:44:51 - models.bert_model - INFO - Epoch 6/10 - Batch 6760/10125 - Loss: 0.1561 - Acc: 94.76% - LR: 7.73e-06
2025-12-15 22:45:05 - models.bert_model - INFO - Epoch 6/10 - Batch 6800/10125 - Loss: 0.1864 - Acc: 94.77% - LR: 7.72e-06
2025-12-15 22:45:20 - models.bert_model - INFO - Epoch 6/10 - Batch 6840/10125 - Loss: 0.1072 - Acc: 94.77% - LR: 7.71e-06
2025-12-15 22:45:34 - models.bert_model - INFO - Epoch 6/10 - Batch 6880/10125 - Loss: 0.1305 - Acc: 94.77% - LR: 7.70e-06
2025-12-15 22:45:49 - models.bert_model - INFO - Epoch 6/10 - Batch 6920/10125 - Loss: 0.1594 - Acc: 94.78% - LR: 7.69e-06
2025-12-15 22:46:03 - models.bert_model - INFO - Epoch 6/10 - Batch 6960/10125 - Loss: 0.1961 - Acc: 94.78% - LR: 7.67e-06
2025-12-15 22:46:18 - models.bert_model - INFO - Epoch 6/10 - Batch 7000/10125 - Loss: 0.3122 - Acc: 94.79% - LR: 7.66e-06
2025-12-15 22:46:33 - models.bert_model - INFO - Epoch 6/10 - Batch 7040/10125 - Loss: 0.3543 - Acc: 94.78% - LR: 7.65e-06
2025-12-15 22:46:47 - models.bert_model - INFO - Epoch 6/10 - Batch 7080/10125 - Loss: 0.7630 - Acc: 94.80% - LR: 7.64e-06
2025-12-15 22:47:02 - models.bert_model - INFO - Epoch 6/10 - Batch 7120/10125 - Loss: 0.3349 - Acc: 94.80% - LR: 7.63e-06
2025-12-15 22:47:16 - models.bert_model - INFO - Epoch 6/10 - Batch 7160/10125 - Loss: 0.2900 - Acc: 94.80% - LR: 7.62e-06
2025-12-15 22:47:31 - models.bert_model - INFO - Epoch 6/10 - Batch 7200/10125 - Loss: 0.2871 - Acc: 94.80% - LR: 7.61e-06
2025-12-15 22:47:45 - models.bert_model - INFO - Epoch 6/10 - Batch 7240/10125 - Loss: 0.3324 - Acc: 94.80% - LR: 7.60e-06
2025-12-15 22:48:00 - models.bert_model - INFO - Epoch 6/10 - Batch 7280/10125 - Loss: 0.1172 - Acc: 94.79% - LR: 7.59e-06
2025-12-15 22:48:14 - models.bert_model - INFO - Epoch 6/10 - Batch 7320/10125 - Loss: 0.3180 - Acc: 94.79% - LR: 7.58e-06
2025-12-15 22:48:29 - models.bert_model - INFO - Epoch 6/10 - Batch 7360/10125 - Loss: 0.1354 - Acc: 94.80% - LR: 7.56e-06
2025-12-15 22:48:43 - models.bert_model - INFO - Epoch 6/10 - Batch 7400/10125 - Loss: 0.1673 - Acc: 94.79% - LR: 7.55e-06
2025-12-15 22:48:58 - models.bert_model - INFO - Epoch 6/10 - Batch 7440/10125 - Loss: 0.1980 - Acc: 94.79% - LR: 7.54e-06
2025-12-15 22:49:13 - models.bert_model - INFO - Epoch 6/10 - Batch 7480/10125 - Loss: 0.1172 - Acc: 94.78% - LR: 7.53e-06
2025-12-15 22:49:27 - models.bert_model - INFO - Epoch 6/10 - Batch 7520/10125 - Loss: 0.1367 - Acc: 94.79% - LR: 7.52e-06
2025-12-15 22:49:42 - models.bert_model - INFO - Epoch 6/10 - Batch 7560/10125 - Loss: 0.1776 - Acc: 94.80% - LR: 7.51e-06
2025-12-15 22:49:56 - models.bert_model - INFO - Epoch 6/10 - Batch 7600/10125 - Loss: 0.2452 - Acc: 94.79% - LR: 7.50e-06
2025-12-15 22:50:11 - models.bert_model - INFO - Epoch 6/10 - Batch 7640/10125 - Loss: 0.3724 - Acc: 94.79% - LR: 7.49e-06
2025-12-15 22:50:25 - models.bert_model - INFO - Epoch 6/10 - Batch 7680/10125 - Loss: 0.1491 - Acc: 94.80% - LR: 7.48e-06
2025-12-15 22:50:40 - models.bert_model - INFO - Epoch 6/10 - Batch 7720/10125 - Loss: 0.1337 - Acc: 94.80% - LR: 7.47e-06
2025-12-15 22:50:54 - models.bert_model - INFO - Epoch 6/10 - Batch 7760/10125 - Loss: 0.2409 - Acc: 94.79% - LR: 7.46e-06
2025-12-15 22:51:09 - models.bert_model - INFO - Epoch 6/10 - Batch 7800/10125 - Loss: 0.2279 - Acc: 94.80% - LR: 7.44e-06
2025-12-15 22:51:23 - models.bert_model - INFO - Epoch 6/10 - Batch 7840/10125 - Loss: 0.2828 - Acc: 94.80% - LR: 7.43e-06
2025-12-15 22:51:38 - models.bert_model - INFO - Epoch 6/10 - Batch 7880/10125 - Loss: 0.2033 - Acc: 94.81% - LR: 7.42e-06
2025-12-15 22:51:52 - models.bert_model - INFO - Epoch 6/10 - Batch 7920/10125 - Loss: 0.3310 - Acc: 94.81% - LR: 7.41e-06
2025-12-15 22:52:07 - models.bert_model - INFO - Epoch 6/10 - Batch 7960/10125 - Loss: 0.1356 - Acc: 94.81% - LR: 7.40e-06
2025-12-15 22:52:21 - models.bert_model - INFO - Epoch 6/10 - Batch 8000/10125 - Loss: 0.1630 - Acc: 94.80% - LR: 7.39e-06
2025-12-15 22:52:36 - models.bert_model - INFO - Epoch 6/10 - Batch 8040/10125 - Loss: 0.1985 - Acc: 94.80% - LR: 7.38e-06
2025-12-15 22:52:51 - models.bert_model - INFO - Epoch 6/10 - Batch 8080/10125 - Loss: 0.1693 - Acc: 94.81% - LR: 7.37e-06
2025-12-15 22:53:05 - models.bert_model - INFO - Epoch 6/10 - Batch 8120/10125 - Loss: 0.2478 - Acc: 94.81% - LR: 7.36e-06
2025-12-15 22:53:20 - models.bert_model - INFO - Epoch 6/10 - Batch 8160/10125 - Loss: 0.3435 - Acc: 94.81% - LR: 7.35e-06
2025-12-15 22:53:34 - models.bert_model - INFO - Epoch 6/10 - Batch 8200/10125 - Loss: 0.1166 - Acc: 94.81% - LR: 7.33e-06
2025-12-15 22:53:49 - models.bert_model - INFO - Epoch 6/10 - Batch 8240/10125 - Loss: 0.1403 - Acc: 94.81% - LR: 7.32e-06
2025-12-15 22:54:03 - models.bert_model - INFO - Epoch 6/10 - Batch 8280/10125 - Loss: 0.1644 - Acc: 94.81% - LR: 7.31e-06
2025-12-15 22:54:18 - models.bert_model - INFO - Epoch 6/10 - Batch 8320/10125 - Loss: 0.1799 - Acc: 94.81% - LR: 7.30e-06
2025-12-15 22:54:32 - models.bert_model - INFO - Epoch 6/10 - Batch 8360/10125 - Loss: 0.1328 - Acc: 94.81% - LR: 7.29e-06
2025-12-15 22:54:47 - models.bert_model - INFO - Epoch 6/10 - Batch 8400/10125 - Loss: 0.1434 - Acc: 94.81% - LR: 7.28e-06
2025-12-15 22:55:01 - models.bert_model - INFO - Epoch 6/10 - Batch 8440/10125 - Loss: 0.3002 - Acc: 94.82% - LR: 7.27e-06
2025-12-15 22:55:16 - models.bert_model - INFO - Epoch 6/10 - Batch 8480/10125 - Loss: 0.1270 - Acc: 94.82% - LR: 7.26e-06
2025-12-15 22:55:30 - models.bert_model - INFO - Epoch 6/10 - Batch 8520/10125 - Loss: 0.1620 - Acc: 94.82% - LR: 7.25e-06
2025-12-15 22:55:45 - models.bert_model - INFO - Epoch 6/10 - Batch 8560/10125 - Loss: 0.1482 - Acc: 94.82% - LR: 7.24e-06
2025-12-15 22:55:59 - models.bert_model - INFO - Epoch 6/10 - Batch 8600/10125 - Loss: 0.1155 - Acc: 94.82% - LR: 7.23e-06
2025-12-15 22:56:14 - models.bert_model - INFO - Epoch 6/10 - Batch 8640/10125 - Loss: 0.4577 - Acc: 94.81% - LR: 7.21e-06
2025-12-15 22:56:28 - models.bert_model - INFO - Epoch 6/10 - Batch 8680/10125 - Loss: 0.2274 - Acc: 94.81% - LR: 7.20e-06
2025-12-15 22:56:43 - models.bert_model - INFO - Epoch 6/10 - Batch 8720/10125 - Loss: 0.1396 - Acc: 94.81% - LR: 7.19e-06
2025-12-15 22:56:58 - models.bert_model - INFO - Epoch 6/10 - Batch 8760/10125 - Loss: 0.1462 - Acc: 94.81% - LR: 7.18e-06
2025-12-15 22:57:12 - models.bert_model - INFO - Epoch 6/10 - Batch 8800/10125 - Loss: 0.5152 - Acc: 94.81% - LR: 7.17e-06
2025-12-15 22:57:26 - models.bert_model - INFO - Epoch 6/10 - Batch 8840/10125 - Loss: 0.1184 - Acc: 94.81% - LR: 7.16e-06
2025-12-15 22:57:41 - models.bert_model - INFO - Epoch 6/10 - Batch 8880/10125 - Loss: 0.2603 - Acc: 94.81% - LR: 7.15e-06
2025-12-15 22:57:55 - models.bert_model - INFO - Epoch 6/10 - Batch 8920/10125 - Loss: 0.1525 - Acc: 94.81% - LR: 7.14e-06
2025-12-15 22:58:10 - models.bert_model - INFO - Epoch 6/10 - Batch 8960/10125 - Loss: 0.2524 - Acc: 94.82% - LR: 7.13e-06
2025-12-15 22:58:24 - models.bert_model - INFO - Epoch 6/10 - Batch 9000/10125 - Loss: 0.1562 - Acc: 94.82% - LR: 7.12e-06
2025-12-15 22:58:39 - models.bert_model - INFO - Epoch 6/10 - Batch 9040/10125 - Loss: 0.1797 - Acc: 94.82% - LR: 7.10e-06
2025-12-15 22:58:53 - models.bert_model - INFO - Epoch 6/10 - Batch 9080/10125 - Loss: 0.1210 - Acc: 94.82% - LR: 7.09e-06
2025-12-15 22:59:08 - models.bert_model - INFO - Epoch 6/10 - Batch 9120/10125 - Loss: 0.1825 - Acc: 94.83% - LR: 7.08e-06
2025-12-15 22:59:22 - models.bert_model - INFO - Epoch 6/10 - Batch 9160/10125 - Loss: 0.1141 - Acc: 94.83% - LR: 7.07e-06
2025-12-15 22:59:37 - models.bert_model - INFO - Epoch 6/10 - Batch 9200/10125 - Loss: 0.4355 - Acc: 94.83% - LR: 7.06e-06
2025-12-15 22:59:51 - models.bert_model - INFO - Epoch 6/10 - Batch 9240/10125 - Loss: 0.1853 - Acc: 94.83% - LR: 7.05e-06
2025-12-15 23:00:06 - models.bert_model - INFO - Epoch 6/10 - Batch 9280/10125 - Loss: 0.3846 - Acc: 94.83% - LR: 7.04e-06
2025-12-15 23:00:21 - models.bert_model - INFO - Epoch 6/10 - Batch 9320/10125 - Loss: 0.1691 - Acc: 94.82% - LR: 7.03e-06
2025-12-15 23:00:35 - models.bert_model - INFO - Epoch 6/10 - Batch 9360/10125 - Loss: 0.2336 - Acc: 94.83% - LR: 7.02e-06
2025-12-15 23:00:50 - models.bert_model - INFO - Epoch 6/10 - Batch 9400/10125 - Loss: 0.2275 - Acc: 94.83% - LR: 7.01e-06
2025-12-15 23:01:04 - models.bert_model - INFO - Epoch 6/10 - Batch 9440/10125 - Loss: 0.1129 - Acc: 94.83% - LR: 7.00e-06
2025-12-15 23:01:19 - models.bert_model - INFO - Epoch 6/10 - Batch 9480/10125 - Loss: 0.1257 - Acc: 94.84% - LR: 6.98e-06
2025-12-15 23:01:33 - models.bert_model - INFO - Epoch 6/10 - Batch 9520/10125 - Loss: 0.1285 - Acc: 94.83% - LR: 6.97e-06
2025-12-15 23:01:48 - models.bert_model - INFO - Epoch 6/10 - Batch 9560/10125 - Loss: 0.1135 - Acc: 94.84% - LR: 6.96e-06
2025-12-15 23:02:02 - models.bert_model - INFO - Epoch 6/10 - Batch 9600/10125 - Loss: 0.1072 - Acc: 94.83% - LR: 6.95e-06
2025-12-15 23:02:17 - models.bert_model - INFO - Epoch 6/10 - Batch 9640/10125 - Loss: 0.2125 - Acc: 94.83% - LR: 6.94e-06
2025-12-15 23:02:31 - models.bert_model - INFO - Epoch 6/10 - Batch 9680/10125 - Loss: 0.3496 - Acc: 94.83% - LR: 6.93e-06
2025-12-15 23:02:46 - models.bert_model - INFO - Epoch 6/10 - Batch 9720/10125 - Loss: 0.1252 - Acc: 94.82% - LR: 6.92e-06
2025-12-15 23:03:00 - models.bert_model - INFO - Epoch 6/10 - Batch 9760/10125 - Loss: 0.1206 - Acc: 94.82% - LR: 6.91e-06
2025-12-15 23:03:15 - models.bert_model - INFO - Epoch 6/10 - Batch 9800/10125 - Loss: 0.1803 - Acc: 94.83% - LR: 6.90e-06
2025-12-15 23:03:29 - models.bert_model - INFO - Epoch 6/10 - Batch 9840/10125 - Loss: 0.1846 - Acc: 94.82% - LR: 6.89e-06
2025-12-15 23:03:44 - models.bert_model - INFO - Epoch 6/10 - Batch 9880/10125 - Loss: 0.3508 - Acc: 94.83% - LR: 6.88e-06
2025-12-15 23:03:58 - models.bert_model - INFO - Epoch 6/10 - Batch 9920/10125 - Loss: 0.2421 - Acc: 94.83% - LR: 6.86e-06
2025-12-15 23:04:13 - models.bert_model - INFO - Epoch 6/10 - Batch 9960/10125 - Loss: 0.1289 - Acc: 94.83% - LR: 6.85e-06
2025-12-15 23:04:27 - models.bert_model - INFO - Epoch 6/10 - Batch 10000/10125 - Loss: 0.2067 - Acc: 94.83% - LR: 6.84e-06
2025-12-15 23:04:42 - models.bert_model - INFO - Epoch 6/10 - Batch 10040/10125 - Loss: 0.2168 - Acc: 94.83% - LR: 6.83e-06
2025-12-15 23:04:56 - models.bert_model - INFO - Epoch 6/10 - Batch 10080/10125 - Loss: 0.1111 - Acc: 94.84% - LR: 6.82e-06
2025-12-15 23:05:11 - models.bert_model - INFO - Epoch 6/10 - Batch 10120/10125 - Loss: 0.3100 - Acc: 94.84% - LR: 6.81e-06
2025-12-15 23:07:29 - models.bert_model - INFO - Epoch 6/10 - Train Loss: 0.2119, Train Acc: 94.84% - Val Loss: 0.2144, Val Acc: 94.88%
2025-12-15 23:07:29 - models.bert_model - INFO - New best validation accuracy: 94.88%
2025-12-15 23:07:43 - models.bert_model - INFO - Epoch 7/10 - Batch 40/10125 - Loss: 0.3529 - Acc: 94.53% - LR: 6.80e-06
2025-12-15 23:07:58 - models.bert_model - INFO - Epoch 7/10 - Batch 80/10125 - Loss: 0.1139 - Acc: 95.08% - LR: 6.79e-06
2025-12-15 23:08:12 - models.bert_model - INFO - Epoch 7/10 - Batch 120/10125 - Loss: 0.1739 - Acc: 95.10% - LR: 6.78e-06
2025-12-15 23:08:27 - models.bert_model - INFO - Epoch 7/10 - Batch 160/10125 - Loss: 0.4100 - Acc: 95.39% - LR: 6.77e-06
2025-12-15 23:08:41 - models.bert_model - INFO - Epoch 7/10 - Batch 200/10125 - Loss: 0.1101 - Acc: 95.22% - LR: 6.75e-06
2025-12-15 23:08:56 - models.bert_model - INFO - Epoch 7/10 - Batch 240/10125 - Loss: 0.1059 - Acc: 95.23% - LR: 6.74e-06
2025-12-15 23:09:10 - models.bert_model - INFO - Epoch 7/10 - Batch 280/10125 - Loss: 0.1547 - Acc: 95.18% - LR: 6.73e-06
2025-12-15 23:09:25 - models.bert_model - INFO - Epoch 7/10 - Batch 320/10125 - Loss: 0.3134 - Acc: 95.23% - LR: 6.72e-06
2025-12-15 23:09:40 - models.bert_model - INFO - Epoch 7/10 - Batch 360/10125 - Loss: 0.3427 - Acc: 95.17% - LR: 6.71e-06
2025-12-15 23:09:54 - models.bert_model - INFO - Epoch 7/10 - Batch 400/10125 - Loss: 0.2077 - Acc: 95.20% - LR: 6.70e-06
2025-12-15 23:10:09 - models.bert_model - INFO - Epoch 7/10 - Batch 440/10125 - Loss: 0.1648 - Acc: 95.14% - LR: 6.69e-06
2025-12-15 23:10:23 - models.bert_model - INFO - Epoch 7/10 - Batch 480/10125 - Loss: 0.1707 - Acc: 95.07% - LR: 6.68e-06
2025-12-15 23:10:38 - models.bert_model - INFO - Epoch 7/10 - Batch 520/10125 - Loss: 0.1208 - Acc: 94.98% - LR: 6.67e-06
2025-12-15 23:10:52 - models.bert_model - INFO - Epoch 7/10 - Batch 560/10125 - Loss: 0.2461 - Acc: 94.97% - LR: 6.66e-06
2025-12-15 23:11:07 - models.bert_model - INFO - Epoch 7/10 - Batch 600/10125 - Loss: 0.1241 - Acc: 95.05% - LR: 6.65e-06
2025-12-15 23:11:21 - models.bert_model - INFO - Epoch 7/10 - Batch 640/10125 - Loss: 0.1125 - Acc: 95.08% - LR: 6.63e-06
2025-12-15 23:11:36 - models.bert_model - INFO - Epoch 7/10 - Batch 680/10125 - Loss: 0.1713 - Acc: 95.06% - LR: 6.62e-06
2025-12-15 23:11:50 - models.bert_model - INFO - Epoch 7/10 - Batch 720/10125 - Loss: 0.2345 - Acc: 95.04% - LR: 6.61e-06
2025-12-15 23:12:05 - models.bert_model - INFO - Epoch 7/10 - Batch 760/10125 - Loss: 0.1216 - Acc: 95.12% - LR: 6.60e-06
2025-12-15 23:12:19 - models.bert_model - INFO - Epoch 7/10 - Batch 800/10125 - Loss: 0.1915 - Acc: 95.13% - LR: 6.59e-06
2025-12-15 23:12:34 - models.bert_model - INFO - Epoch 7/10 - Batch 840/10125 - Loss: 0.2075 - Acc: 95.16% - LR: 6.58e-06
2025-12-15 23:12:48 - models.bert_model - INFO - Epoch 7/10 - Batch 880/10125 - Loss: 0.1814 - Acc: 95.17% - LR: 6.57e-06
2025-12-15 23:13:03 - models.bert_model - INFO - Epoch 7/10 - Batch 920/10125 - Loss: 0.2350 - Acc: 95.15% - LR: 6.56e-06
2025-12-15 23:13:17 - models.bert_model - INFO - Epoch 7/10 - Batch 960/10125 - Loss: 0.1272 - Acc: 95.14% - LR: 6.55e-06
2025-12-15 23:13:32 - models.bert_model - INFO - Epoch 7/10 - Batch 1000/10125 - Loss: 0.1785 - Acc: 95.12% - LR: 6.54e-06
2025-12-15 23:13:46 - models.bert_model - INFO - Epoch 7/10 - Batch 1040/10125 - Loss: 0.3820 - Acc: 95.11% - LR: 6.53e-06
2025-12-15 23:14:01 - models.bert_model - INFO - Epoch 7/10 - Batch 1080/10125 - Loss: 0.2848 - Acc: 95.09% - LR: 6.52e-06
2025-12-15 23:14:15 - models.bert_model - INFO - Epoch 7/10 - Batch 1120/10125 - Loss: 0.1105 - Acc: 95.07% - LR: 6.50e-06
2025-12-15 23:14:30 - models.bert_model - INFO - Epoch 7/10 - Batch 1160/10125 - Loss: 0.1272 - Acc: 95.06% - LR: 6.49e-06
2025-12-15 23:14:44 - models.bert_model - INFO - Epoch 7/10 - Batch 1200/10125 - Loss: 0.2282 - Acc: 95.07% - LR: 6.48e-06
2025-12-15 23:14:59 - models.bert_model - INFO - Epoch 7/10 - Batch 1240/10125 - Loss: 0.2617 - Acc: 95.09% - LR: 6.47e-06
2025-12-15 23:15:14 - models.bert_model - INFO - Epoch 7/10 - Batch 1280/10125 - Loss: 0.2167 - Acc: 95.05% - LR: 6.46e-06
2025-12-15 23:15:28 - models.bert_model - INFO - Epoch 7/10 - Batch 1320/10125 - Loss: 0.1040 - Acc: 95.07% - LR: 6.45e-06
2025-12-15 23:15:43 - models.bert_model - INFO - Epoch 7/10 - Batch 1360/10125 - Loss: 0.2474 - Acc: 95.05% - LR: 6.44e-06
2025-12-15 23:15:57 - models.bert_model - INFO - Epoch 7/10 - Batch 1400/10125 - Loss: 0.5711 - Acc: 95.05% - LR: 6.43e-06
2025-12-15 23:16:12 - models.bert_model - INFO - Epoch 7/10 - Batch 1440/10125 - Loss: 0.3322 - Acc: 95.05% - LR: 6.42e-06
2025-12-15 23:16:26 - models.bert_model - INFO - Epoch 7/10 - Batch 1480/10125 - Loss: 0.2738 - Acc: 95.05% - LR: 6.41e-06
2025-12-15 23:16:41 - models.bert_model - INFO - Epoch 7/10 - Batch 1520/10125 - Loss: 0.1441 - Acc: 95.04% - LR: 6.40e-06
2025-12-15 23:16:55 - models.bert_model - INFO - Epoch 7/10 - Batch 1560/10125 - Loss: 0.1219 - Acc: 95.06% - LR: 6.38e-06
2025-12-15 23:17:10 - models.bert_model - INFO - Epoch 7/10 - Batch 1600/10125 - Loss: 0.1104 - Acc: 95.10% - LR: 6.37e-06
2025-12-15 23:17:24 - models.bert_model - INFO - Epoch 7/10 - Batch 1640/10125 - Loss: 0.2411 - Acc: 95.10% - LR: 6.36e-06
2025-12-15 23:17:39 - models.bert_model - INFO - Epoch 7/10 - Batch 1680/10125 - Loss: 0.2032 - Acc: 95.09% - LR: 6.35e-06
2025-12-15 23:17:53 - models.bert_model - INFO - Epoch 7/10 - Batch 1720/10125 - Loss: 0.3181 - Acc: 95.06% - LR: 6.34e-06
2025-12-15 23:18:08 - models.bert_model - INFO - Epoch 7/10 - Batch 1760/10125 - Loss: 0.1452 - Acc: 95.07% - LR: 6.33e-06
2025-12-15 23:18:22 - models.bert_model - INFO - Epoch 7/10 - Batch 1800/10125 - Loss: 0.1914 - Acc: 95.06% - LR: 6.32e-06
2025-12-15 23:18:37 - models.bert_model - INFO - Epoch 7/10 - Batch 1840/10125 - Loss: 0.1116 - Acc: 95.05% - LR: 6.31e-06
2025-12-15 23:18:51 - models.bert_model - INFO - Epoch 7/10 - Batch 1880/10125 - Loss: 0.1762 - Acc: 95.05% - LR: 6.30e-06
2025-12-15 23:19:06 - models.bert_model - INFO - Epoch 7/10 - Batch 1920/10125 - Loss: 0.1550 - Acc: 95.04% - LR: 6.29e-06
2025-12-15 23:19:20 - models.bert_model - INFO - Epoch 7/10 - Batch 1960/10125 - Loss: 0.1805 - Acc: 95.03% - LR: 6.28e-06
2025-12-15 23:19:35 - models.bert_model - INFO - Epoch 7/10 - Batch 2000/10125 - Loss: 0.2024 - Acc: 95.04% - LR: 6.27e-06
2025-12-15 23:19:49 - models.bert_model - INFO - Epoch 7/10 - Batch 2040/10125 - Loss: 0.2220 - Acc: 95.05% - LR: 6.26e-06
2025-12-15 23:20:04 - models.bert_model - INFO - Epoch 7/10 - Batch 2080/10125 - Loss: 0.3690 - Acc: 95.07% - LR: 6.24e-06
2025-12-15 23:20:19 - models.bert_model - INFO - Epoch 7/10 - Batch 2120/10125 - Loss: 0.1137 - Acc: 95.06% - LR: 6.23e-06
2025-12-15 23:20:33 - models.bert_model - INFO - Epoch 7/10 - Batch 2160/10125 - Loss: 0.1907 - Acc: 95.05% - LR: 6.22e-06
2025-12-15 23:20:48 - models.bert_model - INFO - Epoch 7/10 - Batch 2200/10125 - Loss: 0.1162 - Acc: 95.05% - LR: 6.21e-06
2025-12-15 23:21:02 - models.bert_model - INFO - Epoch 7/10 - Batch 2240/10125 - Loss: 0.1063 - Acc: 95.07% - LR: 6.20e-06
2025-12-15 23:21:17 - models.bert_model - INFO - Epoch 7/10 - Batch 2280/10125 - Loss: 0.1832 - Acc: 95.08% - LR: 6.19e-06
2025-12-15 23:21:31 - models.bert_model - INFO - Epoch 7/10 - Batch 2320/10125 - Loss: 0.2574 - Acc: 95.08% - LR: 6.18e-06
2025-12-15 23:21:46 - models.bert_model - INFO - Epoch 7/10 - Batch 2360/10125 - Loss: 0.1275 - Acc: 95.09% - LR: 6.17e-06
2025-12-15 23:22:00 - models.bert_model - INFO - Epoch 7/10 - Batch 2400/10125 - Loss: 0.2197 - Acc: 95.09% - LR: 6.16e-06
2025-12-15 23:22:15 - models.bert_model - INFO - Epoch 7/10 - Batch 2440/10125 - Loss: 0.2436 - Acc: 95.10% - LR: 6.15e-06
2025-12-15 23:22:29 - models.bert_model - INFO - Epoch 7/10 - Batch 2480/10125 - Loss: 0.1131 - Acc: 95.11% - LR: 6.14e-06
2025-12-15 23:22:44 - models.bert_model - INFO - Epoch 7/10 - Batch 2520/10125 - Loss: 0.2021 - Acc: 95.11% - LR: 6.13e-06
2025-12-15 23:22:58 - models.bert_model - INFO - Epoch 7/10 - Batch 2560/10125 - Loss: 0.1112 - Acc: 95.12% - LR: 6.12e-06
2025-12-15 23:23:13 - models.bert_model - INFO - Epoch 7/10 - Batch 2600/10125 - Loss: 0.1586 - Acc: 95.12% - LR: 6.10e-06
2025-12-15 23:23:27 - models.bert_model - INFO - Epoch 7/10 - Batch 2640/10125 - Loss: 0.1685 - Acc: 95.13% - LR: 6.09e-06
2025-12-15 23:23:42 - models.bert_model - INFO - Epoch 7/10 - Batch 2680/10125 - Loss: 0.2579 - Acc: 95.12% - LR: 6.08e-06
2025-12-15 23:23:57 - models.bert_model - INFO - Epoch 7/10 - Batch 2720/10125 - Loss: 0.1795 - Acc: 95.13% - LR: 6.07e-06
2025-12-15 23:24:11 - models.bert_model - INFO - Epoch 7/10 - Batch 2760/10125 - Loss: 0.1312 - Acc: 95.11% - LR: 6.06e-06
2025-12-15 23:24:26 - models.bert_model - INFO - Epoch 7/10 - Batch 2800/10125 - Loss: 0.1073 - Acc: 95.14% - LR: 6.05e-06
2025-12-15 23:24:40 - models.bert_model - INFO - Epoch 7/10 - Batch 2840/10125 - Loss: 0.2565 - Acc: 95.14% - LR: 6.04e-06
2025-12-15 23:24:55 - models.bert_model - INFO - Epoch 7/10 - Batch 2880/10125 - Loss: 0.1083 - Acc: 95.16% - LR: 6.03e-06
2025-12-15 23:25:09 - models.bert_model - INFO - Epoch 7/10 - Batch 2920/10125 - Loss: 0.1329 - Acc: 95.16% - LR: 6.02e-06
2025-12-15 23:25:24 - models.bert_model - INFO - Epoch 7/10 - Batch 2960/10125 - Loss: 0.1268 - Acc: 95.17% - LR: 6.01e-06
2025-12-15 23:25:38 - models.bert_model - INFO - Epoch 7/10 - Batch 3000/10125 - Loss: 0.1093 - Acc: 95.17% - LR: 6.00e-06
2025-12-15 23:25:53 - models.bert_model - INFO - Epoch 7/10 - Batch 3040/10125 - Loss: 0.1222 - Acc: 95.17% - LR: 5.99e-06
2025-12-15 23:26:07 - models.bert_model - INFO - Epoch 7/10 - Batch 3080/10125 - Loss: 0.1682 - Acc: 95.14% - LR: 5.98e-06
2025-12-15 23:26:22 - models.bert_model - INFO - Epoch 7/10 - Batch 3120/10125 - Loss: 0.1491 - Acc: 95.14% - LR: 5.96e-06
2025-12-15 23:26:36 - models.bert_model - INFO - Epoch 7/10 - Batch 3160/10125 - Loss: 0.2120 - Acc: 95.12% - LR: 5.95e-06
2025-12-15 23:26:51 - models.bert_model - INFO - Epoch 7/10 - Batch 3200/10125 - Loss: 0.1280 - Acc: 95.12% - LR: 5.94e-06
2025-12-15 23:27:05 - models.bert_model - INFO - Epoch 7/10 - Batch 3240/10125 - Loss: 0.1343 - Acc: 95.12% - LR: 5.93e-06
2025-12-15 23:27:20 - models.bert_model - INFO - Epoch 7/10 - Batch 3280/10125 - Loss: 0.3580 - Acc: 95.13% - LR: 5.92e-06
2025-12-15 23:27:34 - models.bert_model - INFO - Epoch 7/10 - Batch 3320/10125 - Loss: 0.3206 - Acc: 95.12% - LR: 5.91e-06
2025-12-15 23:27:49 - models.bert_model - INFO - Epoch 7/10 - Batch 3360/10125 - Loss: 0.1608 - Acc: 95.14% - LR: 5.90e-06
2025-12-15 23:28:03 - models.bert_model - INFO - Epoch 7/10 - Batch 3400/10125 - Loss: 0.1245 - Acc: 95.15% - LR: 5.89e-06
2025-12-15 23:28:18 - models.bert_model - INFO - Epoch 7/10 - Batch 3440/10125 - Loss: 0.1333 - Acc: 95.17% - LR: 5.88e-06
2025-12-15 23:28:32 - models.bert_model - INFO - Epoch 7/10 - Batch 3480/10125 - Loss: 0.3002 - Acc: 95.17% - LR: 5.87e-06
2025-12-15 23:28:47 - models.bert_model - INFO - Epoch 7/10 - Batch 3520/10125 - Loss: 0.1379 - Acc: 95.16% - LR: 5.86e-06
2025-12-15 23:29:01 - models.bert_model - INFO - Epoch 7/10 - Batch 3560/10125 - Loss: 0.1044 - Acc: 95.16% - LR: 5.85e-06
2025-12-15 23:29:16 - models.bert_model - INFO - Epoch 7/10 - Batch 3600/10125 - Loss: 0.1119 - Acc: 95.15% - LR: 5.84e-06
2025-12-15 23:29:30 - models.bert_model - INFO - Epoch 7/10 - Batch 3640/10125 - Loss: 0.1255 - Acc: 95.14% - LR: 5.83e-06
2025-12-15 23:29:45 - models.bert_model - INFO - Epoch 7/10 - Batch 3680/10125 - Loss: 0.2723 - Acc: 95.14% - LR: 5.81e-06
2025-12-15 23:29:59 - models.bert_model - INFO - Epoch 7/10 - Batch 3720/10125 - Loss: 0.1152 - Acc: 95.14% - LR: 5.80e-06
2025-12-15 23:30:14 - models.bert_model - INFO - Epoch 7/10 - Batch 3760/10125 - Loss: 0.3362 - Acc: 95.15% - LR: 5.79e-06
2025-12-15 23:30:29 - models.bert_model - INFO - Epoch 7/10 - Batch 3800/10125 - Loss: 0.1168 - Acc: 95.15% - LR: 5.78e-06
2025-12-15 23:30:43 - models.bert_model - INFO - Epoch 7/10 - Batch 3840/10125 - Loss: 0.2487 - Acc: 95.15% - LR: 5.77e-06
2025-12-15 23:30:58 - models.bert_model - INFO - Epoch 7/10 - Batch 3880/10125 - Loss: 0.1499 - Acc: 95.13% - LR: 5.76e-06
2025-12-15 23:31:12 - models.bert_model - INFO - Epoch 7/10 - Batch 3920/10125 - Loss: 0.1573 - Acc: 95.13% - LR: 5.75e-06
2025-12-15 23:31:27 - models.bert_model - INFO - Epoch 7/10 - Batch 3960/10125 - Loss: 0.2775 - Acc: 95.13% - LR: 5.74e-06
2025-12-15 23:31:41 - models.bert_model - INFO - Epoch 7/10 - Batch 4000/10125 - Loss: 0.1233 - Acc: 95.14% - LR: 5.73e-06
2025-12-15 23:31:56 - models.bert_model - INFO - Epoch 7/10 - Batch 4040/10125 - Loss: 0.1716 - Acc: 95.14% - LR: 5.72e-06
2025-12-15 23:32:10 - models.bert_model - INFO - Epoch 7/10 - Batch 4080/10125 - Loss: 0.1300 - Acc: 95.14% - LR: 5.71e-06
2025-12-15 23:32:25 - models.bert_model - INFO - Epoch 7/10 - Batch 4120/10125 - Loss: 0.1354 - Acc: 95.15% - LR: 5.70e-06
2025-12-15 23:32:39 - models.bert_model - INFO - Epoch 7/10 - Batch 4160/10125 - Loss: 0.2278 - Acc: 95.16% - LR: 5.69e-06
2025-12-15 23:32:54 - models.bert_model - INFO - Epoch 7/10 - Batch 4200/10125 - Loss: 0.2332 - Acc: 95.16% - LR: 5.68e-06
2025-12-15 23:33:08 - models.bert_model - INFO - Epoch 7/10 - Batch 4240/10125 - Loss: 0.4398 - Acc: 95.18% - LR: 5.67e-06
2025-12-15 23:33:23 - models.bert_model - INFO - Epoch 7/10 - Batch 4280/10125 - Loss: 0.1179 - Acc: 95.18% - LR: 5.66e-06
2025-12-15 23:33:37 - models.bert_model - INFO - Epoch 7/10 - Batch 4320/10125 - Loss: 0.1138 - Acc: 95.18% - LR: 5.64e-06
2025-12-15 23:33:52 - models.bert_model - INFO - Epoch 7/10 - Batch 4360/10125 - Loss: 0.5320 - Acc: 95.18% - LR: 5.63e-06
2025-12-15 23:34:06 - models.bert_model - INFO - Epoch 7/10 - Batch 4400/10125 - Loss: 0.4658 - Acc: 95.18% - LR: 5.62e-06
2025-12-15 23:34:21 - models.bert_model - INFO - Epoch 7/10 - Batch 4440/10125 - Loss: 0.2452 - Acc: 95.17% - LR: 5.61e-06
2025-12-15 23:34:35 - models.bert_model - INFO - Epoch 7/10 - Batch 4480/10125 - Loss: 0.3464 - Acc: 95.17% - LR: 5.60e-06
2025-12-15 23:34:50 - models.bert_model - INFO - Epoch 7/10 - Batch 4520/10125 - Loss: 0.1077 - Acc: 95.18% - LR: 5.59e-06
2025-12-15 23:35:04 - models.bert_model - INFO - Epoch 7/10 - Batch 4560/10125 - Loss: 0.1101 - Acc: 95.19% - LR: 5.58e-06
2025-12-15 23:35:19 - models.bert_model - INFO - Epoch 7/10 - Batch 4600/10125 - Loss: 0.1568 - Acc: 95.19% - LR: 5.57e-06
2025-12-15 23:35:33 - models.bert_model - INFO - Epoch 7/10 - Batch 4640/10125 - Loss: 0.1814 - Acc: 95.18% - LR: 5.56e-06
2025-12-15 23:35:48 - models.bert_model - INFO - Epoch 7/10 - Batch 4680/10125 - Loss: 0.1106 - Acc: 95.19% - LR: 5.55e-06
2025-12-15 23:36:02 - models.bert_model - INFO - Epoch 7/10 - Batch 4720/10125 - Loss: 0.2576 - Acc: 95.20% - LR: 5.54e-06
2025-12-15 23:36:17 - models.bert_model - INFO - Epoch 7/10 - Batch 4760/10125 - Loss: 0.2726 - Acc: 95.20% - LR: 5.53e-06
2025-12-15 23:36:31 - models.bert_model - INFO - Epoch 7/10 - Batch 4800/10125 - Loss: 0.1627 - Acc: 95.20% - LR: 5.52e-06
2025-12-15 23:36:46 - models.bert_model - INFO - Epoch 7/10 - Batch 4840/10125 - Loss: 0.1088 - Acc: 95.20% - LR: 5.51e-06
2025-12-15 23:37:01 - models.bert_model - INFO - Epoch 7/10 - Batch 4880/10125 - Loss: 0.1531 - Acc: 95.20% - LR: 5.50e-06
2025-12-15 23:37:15 - models.bert_model - INFO - Epoch 7/10 - Batch 4920/10125 - Loss: 0.3043 - Acc: 95.20% - LR: 5.49e-06
2025-12-15 23:37:29 - models.bert_model - INFO - Epoch 7/10 - Batch 4960/10125 - Loss: 0.1112 - Acc: 95.20% - LR: 5.48e-06
2025-12-15 23:37:44 - models.bert_model - INFO - Epoch 7/10 - Batch 5000/10125 - Loss: 0.1973 - Acc: 95.19% - LR: 5.46e-06
2025-12-15 23:37:58 - models.bert_model - INFO - Epoch 7/10 - Batch 5040/10125 - Loss: 0.1132 - Acc: 95.19% - LR: 5.45e-06
2025-12-15 23:38:13 - models.bert_model - INFO - Epoch 7/10 - Batch 5080/10125 - Loss: 0.2974 - Acc: 95.19% - LR: 5.44e-06
2025-12-15 23:38:27 - models.bert_model - INFO - Epoch 7/10 - Batch 5120/10125 - Loss: 0.1050 - Acc: 95.20% - LR: 5.43e-06
2025-12-15 23:38:42 - models.bert_model - INFO - Epoch 7/10 - Batch 5160/10125 - Loss: 0.1447 - Acc: 95.19% - LR: 5.42e-06
2025-12-15 23:38:56 - models.bert_model - INFO - Epoch 7/10 - Batch 5200/10125 - Loss: 0.1727 - Acc: 95.19% - LR: 5.41e-06
2025-12-15 23:39:11 - models.bert_model - INFO - Epoch 7/10 - Batch 5240/10125 - Loss: 0.1260 - Acc: 95.21% - LR: 5.40e-06
2025-12-15 23:39:25 - models.bert_model - INFO - Epoch 7/10 - Batch 5280/10125 - Loss: 0.2183 - Acc: 95.21% - LR: 5.39e-06
2025-12-15 23:39:40 - models.bert_model - INFO - Epoch 7/10 - Batch 5320/10125 - Loss: 0.2814 - Acc: 95.22% - LR: 5.38e-06
2025-12-15 23:39:55 - models.bert_model - INFO - Epoch 7/10 - Batch 5360/10125 - Loss: 0.1127 - Acc: 95.21% - LR: 5.37e-06
2025-12-15 23:40:09 - models.bert_model - INFO - Epoch 7/10 - Batch 5400/10125 - Loss: 0.1833 - Acc: 95.21% - LR: 5.36e-06
2025-12-15 23:40:24 - models.bert_model - INFO - Epoch 7/10 - Batch 5440/10125 - Loss: 0.3787 - Acc: 95.20% - LR: 5.35e-06
2025-12-15 23:40:38 - models.bert_model - INFO - Epoch 7/10 - Batch 5480/10125 - Loss: 0.1114 - Acc: 95.21% - LR: 5.34e-06
2025-12-15 23:40:53 - models.bert_model - INFO - Epoch 7/10 - Batch 5520/10125 - Loss: 0.3327 - Acc: 95.21% - LR: 5.33e-06
2025-12-15 23:41:07 - models.bert_model - INFO - Epoch 7/10 - Batch 5560/10125 - Loss: 0.1266 - Acc: 95.21% - LR: 5.32e-06
2025-12-15 23:41:22 - models.bert_model - INFO - Epoch 7/10 - Batch 5600/10125 - Loss: 0.1209 - Acc: 95.21% - LR: 5.31e-06
2025-12-15 23:41:36 - models.bert_model - INFO - Epoch 7/10 - Batch 5640/10125 - Loss: 0.1589 - Acc: 95.21% - LR: 5.30e-06
2025-12-15 23:41:51 - models.bert_model - INFO - Epoch 7/10 - Batch 5680/10125 - Loss: 0.2526 - Acc: 95.22% - LR: 5.29e-06
2025-12-15 23:42:05 - models.bert_model - INFO - Epoch 7/10 - Batch 5720/10125 - Loss: 0.1235 - Acc: 95.22% - LR: 5.28e-06
2025-12-15 23:42:20 - models.bert_model - INFO - Epoch 7/10 - Batch 5760/10125 - Loss: 0.1418 - Acc: 95.22% - LR: 5.27e-06
2025-12-15 23:42:34 - models.bert_model - INFO - Epoch 7/10 - Batch 5800/10125 - Loss: 0.3538 - Acc: 95.22% - LR: 5.25e-06
2025-12-15 23:42:49 - models.bert_model - INFO - Epoch 7/10 - Batch 5840/10125 - Loss: 0.1492 - Acc: 95.22% - LR: 5.24e-06
2025-12-15 23:43:03 - models.bert_model - INFO - Epoch 7/10 - Batch 5880/10125 - Loss: 0.1612 - Acc: 95.22% - LR: 5.23e-06
2025-12-15 23:43:18 - models.bert_model - INFO - Epoch 7/10 - Batch 5920/10125 - Loss: 0.1029 - Acc: 95.22% - LR: 5.22e-06
2025-12-15 23:43:33 - models.bert_model - INFO - Epoch 7/10 - Batch 5960/10125 - Loss: 0.1190 - Acc: 95.22% - LR: 5.21e-06
2025-12-15 23:43:47 - models.bert_model - INFO - Epoch 7/10 - Batch 6000/10125 - Loss: 0.1272 - Acc: 95.21% - LR: 5.20e-06
2025-12-15 23:44:02 - models.bert_model - INFO - Epoch 7/10 - Batch 6040/10125 - Loss: 0.2579 - Acc: 95.22% - LR: 5.19e-06
2025-12-15 23:44:16 - models.bert_model - INFO - Epoch 7/10 - Batch 6080/10125 - Loss: 0.1937 - Acc: 95.20% - LR: 5.18e-06
2025-12-15 23:44:31 - models.bert_model - INFO - Epoch 7/10 - Batch 6120/10125 - Loss: 0.1113 - Acc: 95.21% - LR: 5.17e-06
2025-12-15 23:44:45 - models.bert_model - INFO - Epoch 7/10 - Batch 6160/10125 - Loss: 0.1317 - Acc: 95.21% - LR: 5.16e-06
2025-12-15 23:45:00 - models.bert_model - INFO - Epoch 7/10 - Batch 6200/10125 - Loss: 0.1118 - Acc: 95.21% - LR: 5.15e-06
2025-12-15 23:45:14 - models.bert_model - INFO - Epoch 7/10 - Batch 6240/10125 - Loss: 0.1810 - Acc: 95.21% - LR: 5.14e-06
2025-12-15 23:45:29 - models.bert_model - INFO - Epoch 7/10 - Batch 6280/10125 - Loss: 0.1059 - Acc: 95.21% - LR: 5.13e-06
2025-12-15 23:45:43 - models.bert_model - INFO - Epoch 7/10 - Batch 6320/10125 - Loss: 0.1719 - Acc: 95.20% - LR: 5.12e-06
2025-12-15 23:45:58 - models.bert_model - INFO - Epoch 7/10 - Batch 6360/10125 - Loss: 0.1678 - Acc: 95.20% - LR: 5.11e-06
2025-12-15 23:46:13 - models.bert_model - INFO - Epoch 7/10 - Batch 6400/10125 - Loss: 0.2762 - Acc: 95.20% - LR: 5.10e-06
2025-12-15 23:46:27 - models.bert_model - INFO - Epoch 7/10 - Batch 6440/10125 - Loss: 0.1534 - Acc: 95.19% - LR: 5.09e-06
2025-12-15 23:46:42 - models.bert_model - INFO - Epoch 7/10 - Batch 6480/10125 - Loss: 0.1521 - Acc: 95.20% - LR: 5.08e-06
2025-12-15 23:46:56 - models.bert_model - INFO - Epoch 7/10 - Batch 6520/10125 - Loss: 0.1091 - Acc: 95.21% - LR: 5.07e-06
2025-12-15 23:47:11 - models.bert_model - INFO - Epoch 7/10 - Batch 6560/10125 - Loss: 0.2526 - Acc: 95.22% - LR: 5.06e-06
2025-12-15 23:47:25 - models.bert_model - INFO - Epoch 7/10 - Batch 6600/10125 - Loss: 0.2644 - Acc: 95.22% - LR: 5.05e-06
2025-12-15 23:47:40 - models.bert_model - INFO - Epoch 7/10 - Batch 6640/10125 - Loss: 0.1483 - Acc: 95.22% - LR: 5.04e-06
2025-12-15 23:47:54 - models.bert_model - INFO - Epoch 7/10 - Batch 6680/10125 - Loss: 0.1427 - Acc: 95.23% - LR: 5.03e-06
2025-12-15 23:48:09 - models.bert_model - INFO - Epoch 7/10 - Batch 6720/10125 - Loss: 0.1757 - Acc: 95.23% - LR: 5.02e-06
2025-12-15 23:48:23 - models.bert_model - INFO - Epoch 7/10 - Batch 6760/10125 - Loss: 0.1335 - Acc: 95.23% - LR: 5.01e-06
2025-12-15 23:48:38 - models.bert_model - INFO - Epoch 7/10 - Batch 6800/10125 - Loss: 0.1321 - Acc: 95.24% - LR: 5.00e-06
2025-12-15 23:48:52 - models.bert_model - INFO - Epoch 7/10 - Batch 6840/10125 - Loss: 0.2549 - Acc: 95.24% - LR: 4.98e-06
2025-12-15 23:49:07 - models.bert_model - INFO - Epoch 7/10 - Batch 6880/10125 - Loss: 0.1171 - Acc: 95.24% - LR: 4.97e-06
2025-12-15 23:49:21 - models.bert_model - INFO - Epoch 7/10 - Batch 6920/10125 - Loss: 0.1106 - Acc: 95.25% - LR: 4.96e-06
2025-12-15 23:49:36 - models.bert_model - INFO - Epoch 7/10 - Batch 6960/10125 - Loss: 0.1193 - Acc: 95.25% - LR: 4.95e-06
2025-12-15 23:49:50 - models.bert_model - INFO - Epoch 7/10 - Batch 7000/10125 - Loss: 0.3154 - Acc: 95.25% - LR: 4.94e-06
2025-12-15 23:50:05 - models.bert_model - INFO - Epoch 7/10 - Batch 7040/10125 - Loss: 0.2054 - Acc: 95.24% - LR: 4.93e-06
2025-12-15 23:50:19 - models.bert_model - INFO - Epoch 7/10 - Batch 7080/10125 - Loss: 0.1171 - Acc: 95.25% - LR: 4.92e-06
2025-12-15 23:50:34 - models.bert_model - INFO - Epoch 7/10 - Batch 7120/10125 - Loss: 0.1195 - Acc: 95.24% - LR: 4.91e-06
2025-12-15 23:50:48 - models.bert_model - INFO - Epoch 7/10 - Batch 7160/10125 - Loss: 0.1243 - Acc: 95.24% - LR: 4.90e-06
2025-12-15 23:51:03 - models.bert_model - INFO - Epoch 7/10 - Batch 7200/10125 - Loss: 0.1096 - Acc: 95.24% - LR: 4.89e-06
2025-12-15 23:51:17 - models.bert_model - INFO - Epoch 7/10 - Batch 7240/10125 - Loss: 0.1501 - Acc: 95.25% - LR: 4.88e-06
2025-12-15 23:51:32 - models.bert_model - INFO - Epoch 7/10 - Batch 7280/10125 - Loss: 0.1310 - Acc: 95.25% - LR: 4.87e-06
2025-12-15 23:51:46 - models.bert_model - INFO - Epoch 7/10 - Batch 7320/10125 - Loss: 0.1985 - Acc: 95.24% - LR: 4.86e-06
2025-12-15 23:52:01 - models.bert_model - INFO - Epoch 7/10 - Batch 7360/10125 - Loss: 0.1599 - Acc: 95.23% - LR: 4.85e-06
2025-12-15 23:52:15 - models.bert_model - INFO - Epoch 7/10 - Batch 7400/10125 - Loss: 0.1136 - Acc: 95.23% - LR: 4.84e-06
2025-12-15 23:52:30 - models.bert_model - INFO - Epoch 7/10 - Batch 7440/10125 - Loss: 0.3889 - Acc: 95.24% - LR: 4.83e-06
2025-12-15 23:52:44 - models.bert_model - INFO - Epoch 7/10 - Batch 7480/10125 - Loss: 0.2687 - Acc: 95.24% - LR: 4.82e-06
2025-12-15 23:52:59 - models.bert_model - INFO - Epoch 7/10 - Batch 7520/10125 - Loss: 0.1120 - Acc: 95.25% - LR: 4.81e-06
2025-12-15 23:53:14 - models.bert_model - INFO - Epoch 7/10 - Batch 7560/10125 - Loss: 0.1982 - Acc: 95.25% - LR: 4.80e-06
2025-12-15 23:53:28 - models.bert_model - INFO - Epoch 7/10 - Batch 7600/10125 - Loss: 0.1383 - Acc: 95.24% - LR: 4.79e-06
2025-12-15 23:53:43 - models.bert_model - INFO - Epoch 7/10 - Batch 7640/10125 - Loss: 0.1188 - Acc: 95.25% - LR: 4.78e-06
2025-12-15 23:53:57 - models.bert_model - INFO - Epoch 7/10 - Batch 7680/10125 - Loss: 0.1437 - Acc: 95.25% - LR: 4.77e-06
2025-12-15 23:54:12 - models.bert_model - INFO - Epoch 7/10 - Batch 7720/10125 - Loss: 0.3327 - Acc: 95.24% - LR: 4.76e-06
2025-12-15 23:54:26 - models.bert_model - INFO - Epoch 7/10 - Batch 7760/10125 - Loss: 0.1260 - Acc: 95.25% - LR: 4.75e-06
2025-12-15 23:54:41 - models.bert_model - INFO - Epoch 7/10 - Batch 7800/10125 - Loss: 0.1431 - Acc: 95.25% - LR: 4.74e-06
2025-12-15 23:54:55 - models.bert_model - INFO - Epoch 7/10 - Batch 7840/10125 - Loss: 0.2464 - Acc: 95.25% - LR: 4.73e-06
2025-12-15 23:55:10 - models.bert_model - INFO - Epoch 7/10 - Batch 7880/10125 - Loss: 0.2066 - Acc: 95.26% - LR: 4.72e-06
2025-12-15 23:55:24 - models.bert_model - INFO - Epoch 7/10 - Batch 7920/10125 - Loss: 0.3390 - Acc: 95.25% - LR: 4.71e-06
2025-12-15 23:55:39 - models.bert_model - INFO - Epoch 7/10 - Batch 7960/10125 - Loss: 0.1344 - Acc: 95.25% - LR: 4.70e-06
2025-12-15 23:55:53 - models.bert_model - INFO - Epoch 7/10 - Batch 8000/10125 - Loss: 0.1150 - Acc: 95.26% - LR: 4.69e-06
2025-12-15 23:56:08 - models.bert_model - INFO - Epoch 7/10 - Batch 8040/10125 - Loss: 0.1539 - Acc: 95.26% - LR: 4.68e-06
2025-12-15 23:56:22 - models.bert_model - INFO - Epoch 7/10 - Batch 8080/10125 - Loss: 0.2282 - Acc: 95.26% - LR: 4.67e-06
2025-12-15 23:56:37 - models.bert_model - INFO - Epoch 7/10 - Batch 8120/10125 - Loss: 0.1147 - Acc: 95.26% - LR: 4.66e-06
2025-12-15 23:56:51 - models.bert_model - INFO - Epoch 7/10 - Batch 8160/10125 - Loss: 0.1522 - Acc: 95.26% - LR: 4.65e-06
2025-12-15 23:57:06 - models.bert_model - INFO - Epoch 7/10 - Batch 8200/10125 - Loss: 0.1331 - Acc: 95.26% - LR: 4.64e-06
2025-12-15 23:57:20 - models.bert_model - INFO - Epoch 7/10 - Batch 8240/10125 - Loss: 0.1053 - Acc: 95.26% - LR: 4.63e-06
2025-12-15 23:57:35 - models.bert_model - INFO - Epoch 7/10 - Batch 8280/10125 - Loss: 0.1870 - Acc: 95.26% - LR: 4.62e-06
2025-12-15 23:57:49 - models.bert_model - INFO - Epoch 7/10 - Batch 8320/10125 - Loss: 0.3148 - Acc: 95.26% - LR: 4.61e-06
2025-12-15 23:58:04 - models.bert_model - INFO - Epoch 7/10 - Batch 8360/10125 - Loss: 0.1329 - Acc: 95.26% - LR: 4.60e-06
2025-12-15 23:58:18 - models.bert_model - INFO - Epoch 7/10 - Batch 8400/10125 - Loss: 0.1245 - Acc: 95.26% - LR: 4.59e-06
2025-12-15 23:58:33 - models.bert_model - INFO - Epoch 7/10 - Batch 8440/10125 - Loss: 0.1338 - Acc: 95.26% - LR: 4.58e-06
2025-12-15 23:58:48 - models.bert_model - INFO - Epoch 7/10 - Batch 8480/10125 - Loss: 0.2355 - Acc: 95.26% - LR: 4.57e-06
2025-12-15 23:59:02 - models.bert_model - INFO - Epoch 7/10 - Batch 8520/10125 - Loss: 0.1182 - Acc: 95.26% - LR: 4.56e-06
2025-12-15 23:59:17 - models.bert_model - INFO - Epoch 7/10 - Batch 8560/10125 - Loss: 0.1668 - Acc: 95.26% - LR: 4.55e-06
2025-12-15 23:59:31 - models.bert_model - INFO - Epoch 7/10 - Batch 8600/10125 - Loss: 0.1382 - Acc: 95.26% - LR: 4.54e-06
2025-12-15 23:59:46 - models.bert_model - INFO - Epoch 7/10 - Batch 8640/10125 - Loss: 0.1320 - Acc: 95.26% - LR: 4.53e-06
2025-12-16 00:00:00 - models.bert_model - INFO - Epoch 7/10 - Batch 8680/10125 - Loss: 0.1110 - Acc: 95.26% - LR: 4.52e-06
2025-12-16 00:00:15 - models.bert_model - INFO - Epoch 7/10 - Batch 8720/10125 - Loss: 0.1314 - Acc: 95.26% - LR: 4.51e-06
2025-12-16 00:00:29 - models.bert_model - INFO - Epoch 7/10 - Batch 8760/10125 - Loss: 0.1244 - Acc: 95.26% - LR: 4.50e-06
2025-12-16 00:00:44 - models.bert_model - INFO - Epoch 7/10 - Batch 8800/10125 - Loss: 0.2435 - Acc: 95.26% - LR: 4.49e-06
2025-12-16 00:00:58 - models.bert_model - INFO - Epoch 7/10 - Batch 8840/10125 - Loss: 0.1435 - Acc: 95.26% - LR: 4.48e-06
2025-12-16 00:01:13 - models.bert_model - INFO - Epoch 7/10 - Batch 8880/10125 - Loss: 0.1998 - Acc: 95.26% - LR: 4.47e-06
2025-12-16 00:01:27 - models.bert_model - INFO - Epoch 7/10 - Batch 8920/10125 - Loss: 0.1471 - Acc: 95.25% - LR: 4.46e-06
2025-12-16 00:01:42 - models.bert_model - INFO - Epoch 7/10 - Batch 8960/10125 - Loss: 0.1218 - Acc: 95.26% - LR: 4.45e-06
2025-12-16 00:01:56 - models.bert_model - INFO - Epoch 7/10 - Batch 9000/10125 - Loss: 0.1271 - Acc: 95.26% - LR: 4.44e-06
2025-12-16 00:02:11 - models.bert_model - INFO - Epoch 7/10 - Batch 9040/10125 - Loss: 0.1142 - Acc: 95.25% - LR: 4.43e-06
2025-12-16 00:02:25 - models.bert_model - INFO - Epoch 7/10 - Batch 9080/10125 - Loss: 0.1094 - Acc: 95.25% - LR: 4.42e-06
2025-12-16 00:02:40 - models.bert_model - INFO - Epoch 7/10 - Batch 9120/10125 - Loss: 0.1264 - Acc: 95.26% - LR: 4.41e-06
2025-12-16 00:02:54 - models.bert_model - INFO - Epoch 7/10 - Batch 9160/10125 - Loss: 0.1257 - Acc: 95.26% - LR: 4.40e-06
2025-12-16 00:03:09 - models.bert_model - INFO - Epoch 7/10 - Batch 9200/10125 - Loss: 0.1074 - Acc: 95.25% - LR: 4.39e-06
2025-12-16 00:03:23 - models.bert_model - INFO - Epoch 7/10 - Batch 9240/10125 - Loss: 0.1134 - Acc: 95.25% - LR: 4.38e-06
2025-12-16 00:03:38 - models.bert_model - INFO - Epoch 7/10 - Batch 9280/10125 - Loss: 0.2120 - Acc: 95.26% - LR: 4.37e-06
2025-12-16 00:03:52 - models.bert_model - INFO - Epoch 7/10 - Batch 9320/10125 - Loss: 0.1127 - Acc: 95.26% - LR: 4.36e-06
2025-12-16 00:04:07 - models.bert_model - INFO - Epoch 7/10 - Batch 9360/10125 - Loss: 0.1092 - Acc: 95.27% - LR: 4.35e-06
2025-12-16 00:04:21 - models.bert_model - INFO - Epoch 7/10 - Batch 9400/10125 - Loss: 0.1071 - Acc: 95.26% - LR: 4.34e-06
2025-12-16 00:04:36 - models.bert_model - INFO - Epoch 7/10 - Batch 9440/10125 - Loss: 0.1864 - Acc: 95.26% - LR: 4.33e-06
2025-12-16 00:04:50 - models.bert_model - INFO - Epoch 7/10 - Batch 9480/10125 - Loss: 0.2428 - Acc: 95.26% - LR: 4.32e-06
2025-12-16 00:05:05 - models.bert_model - INFO - Epoch 7/10 - Batch 9520/10125 - Loss: 0.3208 - Acc: 95.26% - LR: 4.31e-06
2025-12-16 00:05:19 - models.bert_model - INFO - Epoch 7/10 - Batch 9560/10125 - Loss: 0.1277 - Acc: 95.26% - LR: 4.30e-06
2025-12-16 00:05:34 - models.bert_model - INFO - Epoch 7/10 - Batch 9600/10125 - Loss: 0.2788 - Acc: 95.25% - LR: 4.29e-06
2025-12-16 00:05:48 - models.bert_model - INFO - Epoch 7/10 - Batch 9640/10125 - Loss: 0.1727 - Acc: 95.25% - LR: 4.28e-06
2025-12-16 00:06:03 - models.bert_model - INFO - Epoch 7/10 - Batch 9680/10125 - Loss: 0.3419 - Acc: 95.26% - LR: 4.27e-06
2025-12-16 00:06:18 - models.bert_model - INFO - Epoch 7/10 - Batch 9720/10125 - Loss: 0.1034 - Acc: 95.26% - LR: 4.26e-06
2025-12-16 00:06:32 - models.bert_model - INFO - Epoch 7/10 - Batch 9760/10125 - Loss: 0.2270 - Acc: 95.26% - LR: 4.25e-06
2025-12-16 00:06:47 - models.bert_model - INFO - Epoch 7/10 - Batch 9800/10125 - Loss: 0.4070 - Acc: 95.27% - LR: 4.24e-06
2025-12-16 00:07:01 - models.bert_model - INFO - Epoch 7/10 - Batch 9840/10125 - Loss: 0.1581 - Acc: 95.27% - LR: 4.23e-06
2025-12-16 00:07:16 - models.bert_model - INFO - Epoch 7/10 - Batch 9880/10125 - Loss: 0.1217 - Acc: 95.27% - LR: 4.22e-06
2025-12-16 00:07:30 - models.bert_model - INFO - Epoch 7/10 - Batch 9920/10125 - Loss: 0.2435 - Acc: 95.27% - LR: 4.21e-06
2025-12-16 00:07:45 - models.bert_model - INFO - Epoch 7/10 - Batch 9960/10125 - Loss: 0.1969 - Acc: 95.27% - LR: 4.20e-06
2025-12-16 00:07:59 - models.bert_model - INFO - Epoch 7/10 - Batch 10000/10125 - Loss: 0.1607 - Acc: 95.27% - LR: 4.19e-06
2025-12-16 00:08:14 - models.bert_model - INFO - Epoch 7/10 - Batch 10040/10125 - Loss: 0.1133 - Acc: 95.27% - LR: 4.18e-06
2025-12-16 00:08:28 - models.bert_model - INFO - Epoch 7/10 - Batch 10080/10125 - Loss: 0.1639 - Acc: 95.27% - LR: 4.17e-06
2025-12-16 00:08:43 - models.bert_model - INFO - Epoch 7/10 - Batch 10120/10125 - Loss: 0.2364 - Acc: 95.27% - LR: 4.16e-06
2025-12-16 00:11:00 - models.bert_model - INFO - Epoch 7/10 - Train Loss: 0.2020, Train Acc: 95.27% - Val Loss: 0.2122, Val Acc: 94.73%
2025-12-16 00:11:15 - models.bert_model - INFO - Epoch 8/10 - Batch 40/10125 - Loss: 0.1293 - Acc: 95.62% - LR: 4.15e-06
2025-12-16 00:11:30 - models.bert_model - INFO - Epoch 8/10 - Batch 80/10125 - Loss: 0.3463 - Acc: 96.17% - LR: 4.14e-06
2025-12-16 00:11:44 - models.bert_model - INFO - Epoch 8/10 - Batch 120/10125 - Loss: 0.1072 - Acc: 95.94% - LR: 4.13e-06
2025-12-16 00:11:59 - models.bert_model - INFO - Epoch 8/10 - Batch 160/10125 - Loss: 0.1048 - Acc: 95.98% - LR: 4.12e-06
2025-12-16 00:12:13 - models.bert_model - INFO - Epoch 8/10 - Batch 200/10125 - Loss: 0.2781 - Acc: 95.94% - LR: 4.11e-06
2025-12-16 00:12:28 - models.bert_model - INFO - Epoch 8/10 - Batch 240/10125 - Loss: 0.1790 - Acc: 95.94% - LR: 4.10e-06
2025-12-16 00:12:42 - models.bert_model - INFO - Epoch 8/10 - Batch 280/10125 - Loss: 0.2713 - Acc: 95.80% - LR: 4.09e-06
2025-12-16 00:12:57 - models.bert_model - INFO - Epoch 8/10 - Batch 320/10125 - Loss: 0.2832 - Acc: 95.82% - LR: 4.08e-06
2025-12-16 00:13:11 - models.bert_model - INFO - Epoch 8/10 - Batch 360/10125 - Loss: 0.1159 - Acc: 95.78% - LR: 4.07e-06
2025-12-16 00:13:26 - models.bert_model - INFO - Epoch 8/10 - Batch 400/10125 - Loss: 0.1029 - Acc: 95.70% - LR: 4.06e-06
2025-12-16 00:13:40 - models.bert_model - INFO - Epoch 8/10 - Batch 440/10125 - Loss: 0.2108 - Acc: 95.80% - LR: 4.05e-06
2025-12-16 00:13:55 - models.bert_model - INFO - Epoch 8/10 - Batch 480/10125 - Loss: 0.1476 - Acc: 95.81% - LR: 4.04e-06
2025-12-16 00:14:09 - models.bert_model - INFO - Epoch 8/10 - Batch 520/10125 - Loss: 0.2878 - Acc: 95.81% - LR: 4.03e-06
2025-12-16 00:14:24 - models.bert_model - INFO - Epoch 8/10 - Batch 560/10125 - Loss: 0.1375 - Acc: 95.93% - LR: 4.02e-06
2025-12-16 00:14:38 - models.bert_model - INFO - Epoch 8/10 - Batch 600/10125 - Loss: 0.1054 - Acc: 95.86% - LR: 4.01e-06
2025-12-16 00:14:53 - models.bert_model - INFO - Epoch 8/10 - Batch 640/10125 - Loss: 0.3425 - Acc: 95.79% - LR: 4.00e-06
2025-12-16 00:15:07 - models.bert_model - INFO - Epoch 8/10 - Batch 680/10125 - Loss: 0.2522 - Acc: 95.73% - LR: 3.99e-06
2025-12-16 00:15:22 - models.bert_model - INFO - Epoch 8/10 - Batch 720/10125 - Loss: 0.3904 - Acc: 95.66% - LR: 3.98e-06
2025-12-16 00:15:36 - models.bert_model - INFO - Epoch 8/10 - Batch 760/10125 - Loss: 0.1318 - Acc: 95.65% - LR: 3.97e-06
2025-12-16 00:15:51 - models.bert_model - INFO - Epoch 8/10 - Batch 800/10125 - Loss: 0.1094 - Acc: 95.71% - LR: 3.96e-06
2025-12-16 00:16:05 - models.bert_model - INFO - Epoch 8/10 - Batch 840/10125 - Loss: 0.1657 - Acc: 95.71% - LR: 3.95e-06
2025-12-16 00:16:20 - models.bert_model - INFO - Epoch 8/10 - Batch 880/10125 - Loss: 0.1382 - Acc: 95.67% - LR: 3.94e-06
2025-12-16 00:16:35 - models.bert_model - INFO - Epoch 8/10 - Batch 920/10125 - Loss: 0.2393 - Acc: 95.68% - LR: 3.93e-06
2025-12-16 00:16:49 - models.bert_model - INFO - Epoch 8/10 - Batch 960/10125 - Loss: 0.1047 - Acc: 95.65% - LR: 3.92e-06
2025-12-16 00:17:04 - models.bert_model - INFO - Epoch 8/10 - Batch 1000/10125 - Loss: 0.5230 - Acc: 95.61% - LR: 3.92e-06
2025-12-16 00:17:18 - models.bert_model - INFO - Epoch 8/10 - Batch 1040/10125 - Loss: 0.1049 - Acc: 95.61% - LR: 3.91e-06
2025-12-16 00:17:33 - models.bert_model - INFO - Epoch 8/10 - Batch 1080/10125 - Loss: 0.1800 - Acc: 95.61% - LR: 3.90e-06
2025-12-16 00:17:47 - models.bert_model - INFO - Epoch 8/10 - Batch 1120/10125 - Loss: 0.1818 - Acc: 95.60% - LR: 3.89e-06
2025-12-16 00:18:02 - models.bert_model - INFO - Epoch 8/10 - Batch 1160/10125 - Loss: 0.1449 - Acc: 95.57% - LR: 3.88e-06
2025-12-16 00:18:16 - models.bert_model - INFO - Epoch 8/10 - Batch 1200/10125 - Loss: 0.1237 - Acc: 95.58% - LR: 3.87e-06
2025-12-16 00:18:31 - models.bert_model - INFO - Epoch 8/10 - Batch 1240/10125 - Loss: 0.1414 - Acc: 95.61% - LR: 3.86e-06
2025-12-16 00:18:45 - models.bert_model - INFO - Epoch 8/10 - Batch 1280/10125 - Loss: 0.1209 - Acc: 95.64% - LR: 3.85e-06
2025-12-16 00:19:00 - models.bert_model - INFO - Epoch 8/10 - Batch 1320/10125 - Loss: 0.2308 - Acc: 95.61% - LR: 3.84e-06
2025-12-16 00:19:14 - models.bert_model - INFO - Epoch 8/10 - Batch 1360/10125 - Loss: 0.1083 - Acc: 95.58% - LR: 3.83e-06
2025-12-16 00:19:29 - models.bert_model - INFO - Epoch 8/10 - Batch 1400/10125 - Loss: 0.1474 - Acc: 95.58% - LR: 3.82e-06
2025-12-16 00:19:43 - models.bert_model - INFO - Epoch 8/10 - Batch 1440/10125 - Loss: 0.1667 - Acc: 95.59% - LR: 3.81e-06
2025-12-16 00:19:58 - models.bert_model - INFO - Epoch 8/10 - Batch 1480/10125 - Loss: 0.1478 - Acc: 95.57% - LR: 3.80e-06
2025-12-16 00:20:12 - models.bert_model - INFO - Epoch 8/10 - Batch 1520/10125 - Loss: 0.1171 - Acc: 95.58% - LR: 3.79e-06
2025-12-16 00:20:27 - models.bert_model - INFO - Epoch 8/10 - Batch 1560/10125 - Loss: 0.3785 - Acc: 95.58% - LR: 3.78e-06
2025-12-16 00:20:41 - models.bert_model - INFO - Epoch 8/10 - Batch 1600/10125 - Loss: 0.1070 - Acc: 95.59% - LR: 3.77e-06
2025-12-16 00:20:56 - models.bert_model - INFO - Epoch 8/10 - Batch 1640/10125 - Loss: 0.1113 - Acc: 95.61% - LR: 3.76e-06
2025-12-16 00:21:10 - models.bert_model - INFO - Epoch 8/10 - Batch 1680/10125 - Loss: 0.1583 - Acc: 95.62% - LR: 3.75e-06
2025-12-16 00:21:25 - models.bert_model - INFO - Epoch 8/10 - Batch 1720/10125 - Loss: 0.2692 - Acc: 95.62% - LR: 3.74e-06
2025-12-16 00:21:40 - models.bert_model - INFO - Epoch 8/10 - Batch 1760/10125 - Loss: 0.3212 - Acc: 95.63% - LR: 3.73e-06
2025-12-16 00:21:54 - models.bert_model - INFO - Epoch 8/10 - Batch 1800/10125 - Loss: 0.4269 - Acc: 95.61% - LR: 3.72e-06
2025-12-16 00:22:09 - models.bert_model - INFO - Epoch 8/10 - Batch 1840/10125 - Loss: 0.1399 - Acc: 95.58% - LR: 3.71e-06
2025-12-16 00:22:23 - models.bert_model - INFO - Epoch 8/10 - Batch 1880/10125 - Loss: 0.3869 - Acc: 95.55% - LR: 3.71e-06
2025-12-16 00:22:38 - models.bert_model - INFO - Epoch 8/10 - Batch 1920/10125 - Loss: 0.3057 - Acc: 95.56% - LR: 3.70e-06
2025-12-16 00:22:52 - models.bert_model - INFO - Epoch 8/10 - Batch 1960/10125 - Loss: 0.1218 - Acc: 95.57% - LR: 3.69e-06
2025-12-16 00:23:07 - models.bert_model - INFO - Epoch 8/10 - Batch 2000/10125 - Loss: 0.1583 - Acc: 95.57% - LR: 3.68e-06
2025-12-16 00:23:21 - models.bert_model - INFO - Epoch 8/10 - Batch 2040/10125 - Loss: 0.1168 - Acc: 95.59% - LR: 3.67e-06
2025-12-16 00:23:36 - models.bert_model - INFO - Epoch 8/10 - Batch 2080/10125 - Loss: 0.2936 - Acc: 95.59% - LR: 3.66e-06
2025-12-16 00:23:50 - models.bert_model - INFO - Epoch 8/10 - Batch 2120/10125 - Loss: 0.1204 - Acc: 95.61% - LR: 3.65e-06
2025-12-16 00:24:05 - models.bert_model - INFO - Epoch 8/10 - Batch 2160/10125 - Loss: 0.1414 - Acc: 95.63% - LR: 3.64e-06
2025-12-16 00:24:19 - models.bert_model - INFO - Epoch 8/10 - Batch 2200/10125 - Loss: 0.1480 - Acc: 95.64% - LR: 3.63e-06
2025-12-16 00:24:34 - models.bert_model - INFO - Epoch 8/10 - Batch 2240/10125 - Loss: 0.1928 - Acc: 95.65% - LR: 3.62e-06
2025-12-16 00:24:48 - models.bert_model - INFO - Epoch 8/10 - Batch 2280/10125 - Loss: 0.2231 - Acc: 95.64% - LR: 3.61e-06
2025-12-16 00:25:03 - models.bert_model - INFO - Epoch 8/10 - Batch 2320/10125 - Loss: 0.1149 - Acc: 95.65% - LR: 3.60e-06
2025-12-16 00:25:17 - models.bert_model - INFO - Epoch 8/10 - Batch 2360/10125 - Loss: 0.4179 - Acc: 95.65% - LR: 3.59e-06
2025-12-16 00:25:32 - models.bert_model - INFO - Epoch 8/10 - Batch 2400/10125 - Loss: 0.1087 - Acc: 95.66% - LR: 3.58e-06
2025-12-16 00:25:46 - models.bert_model - INFO - Epoch 8/10 - Batch 2440/10125 - Loss: 0.1554 - Acc: 95.68% - LR: 3.57e-06
2025-12-16 00:26:01 - models.bert_model - INFO - Epoch 8/10 - Batch 2480/10125 - Loss: 0.1589 - Acc: 95.66% - LR: 3.56e-06
2025-12-16 00:26:15 - models.bert_model - INFO - Epoch 8/10 - Batch 2520/10125 - Loss: 0.1238 - Acc: 95.66% - LR: 3.56e-06
2025-12-16 00:26:30 - models.bert_model - INFO - Epoch 8/10 - Batch 2560/10125 - Loss: 0.1437 - Acc: 95.67% - LR: 3.55e-06
2025-12-16 00:26:44 - models.bert_model - INFO - Epoch 8/10 - Batch 2600/10125 - Loss: 0.1185 - Acc: 95.68% - LR: 3.54e-06
2025-12-16 00:26:59 - models.bert_model - INFO - Epoch 8/10 - Batch 2640/10125 - Loss: 0.1223 - Acc: 95.68% - LR: 3.53e-06
2025-12-16 00:27:14 - models.bert_model - INFO - Epoch 8/10 - Batch 2680/10125 - Loss: 0.1123 - Acc: 95.68% - LR: 3.52e-06
2025-12-16 00:27:28 - models.bert_model - INFO - Epoch 8/10 - Batch 2720/10125 - Loss: 0.1994 - Acc: 95.69% - LR: 3.51e-06
2025-12-16 00:27:43 - models.bert_model - INFO - Epoch 8/10 - Batch 2760/10125 - Loss: 0.2905 - Acc: 95.69% - LR: 3.50e-06
2025-12-16 00:27:57 - models.bert_model - INFO - Epoch 8/10 - Batch 2800/10125 - Loss: 0.1083 - Acc: 95.69% - LR: 3.49e-06
2025-12-16 00:28:12 - models.bert_model - INFO - Epoch 8/10 - Batch 2840/10125 - Loss: 0.1640 - Acc: 95.70% - LR: 3.48e-06
2025-12-16 00:28:26 - models.bert_model - INFO - Epoch 8/10 - Batch 2880/10125 - Loss: 0.1114 - Acc: 95.70% - LR: 3.47e-06
2025-12-16 00:28:41 - models.bert_model - INFO - Epoch 8/10 - Batch 2920/10125 - Loss: 0.6134 - Acc: 95.69% - LR: 3.46e-06
2025-12-16 00:28:55 - models.bert_model - INFO - Epoch 8/10 - Batch 2960/10125 - Loss: 0.1116 - Acc: 95.68% - LR: 3.45e-06
2025-12-16 00:29:10 - models.bert_model - INFO - Epoch 8/10 - Batch 3000/10125 - Loss: 0.3009 - Acc: 95.69% - LR: 3.44e-06
2025-12-16 00:29:24 - models.bert_model - INFO - Epoch 8/10 - Batch 3040/10125 - Loss: 0.1412 - Acc: 95.71% - LR: 3.44e-06
2025-12-16 00:29:39 - models.bert_model - INFO - Epoch 8/10 - Batch 3080/10125 - Loss: 0.2093 - Acc: 95.71% - LR: 3.43e-06
2025-12-16 00:29:53 - models.bert_model - INFO - Epoch 8/10 - Batch 3120/10125 - Loss: 0.1970 - Acc: 95.72% - LR: 3.42e-06
2025-12-16 00:30:08 - models.bert_model - INFO - Epoch 8/10 - Batch 3160/10125 - Loss: 0.1980 - Acc: 95.70% - LR: 3.41e-06
2025-12-16 00:30:22 - models.bert_model - INFO - Epoch 8/10 - Batch 3200/10125 - Loss: 0.4698 - Acc: 95.70% - LR: 3.40e-06
2025-12-16 00:30:37 - models.bert_model - INFO - Epoch 8/10 - Batch 3240/10125 - Loss: 0.1190 - Acc: 95.70% - LR: 3.39e-06
2025-12-16 00:30:51 - models.bert_model - INFO - Epoch 8/10 - Batch 3280/10125 - Loss: 0.1296 - Acc: 95.69% - LR: 3.38e-06
2025-12-16 00:31:06 - models.bert_model - INFO - Epoch 8/10 - Batch 3320/10125 - Loss: 0.4347 - Acc: 95.68% - LR: 3.37e-06
2025-12-16 00:31:20 - models.bert_model - INFO - Epoch 8/10 - Batch 3360/10125 - Loss: 0.3830 - Acc: 95.67% - LR: 3.36e-06
2025-12-16 00:31:35 - models.bert_model - INFO - Epoch 8/10 - Batch 3400/10125 - Loss: 0.3406 - Acc: 95.68% - LR: 3.35e-06
2025-12-16 00:31:49 - models.bert_model - INFO - Epoch 8/10 - Batch 3440/10125 - Loss: 0.1621 - Acc: 95.67% - LR: 3.34e-06
2025-12-16 00:32:04 - models.bert_model - INFO - Epoch 8/10 - Batch 3480/10125 - Loss: 0.1448 - Acc: 95.68% - LR: 3.33e-06
2025-12-16 00:32:18 - models.bert_model - INFO - Epoch 8/10 - Batch 3520/10125 - Loss: 0.1552 - Acc: 95.69% - LR: 3.33e-06
2025-12-16 00:32:33 - models.bert_model - INFO - Epoch 8/10 - Batch 3560/10125 - Loss: 0.1576 - Acc: 95.67% - LR: 3.32e-06
2025-12-16 00:32:47 - models.bert_model - INFO - Epoch 8/10 - Batch 3600/10125 - Loss: 0.2103 - Acc: 95.67% - LR: 3.31e-06
2025-12-16 00:33:02 - models.bert_model - INFO - Epoch 8/10 - Batch 3640/10125 - Loss: 0.1110 - Acc: 95.68% - LR: 3.30e-06
2025-12-16 00:33:16 - models.bert_model - INFO - Epoch 8/10 - Batch 3680/10125 - Loss: 0.2495 - Acc: 95.67% - LR: 3.29e-06
2025-12-16 00:33:31 - models.bert_model - INFO - Epoch 8/10 - Batch 3720/10125 - Loss: 0.1060 - Acc: 95.68% - LR: 3.28e-06
2025-12-16 00:33:45 - models.bert_model - INFO - Epoch 8/10 - Batch 3760/10125 - Loss: 0.1576 - Acc: 95.69% - LR: 3.27e-06
2025-12-16 00:34:00 - models.bert_model - INFO - Epoch 8/10 - Batch 3800/10125 - Loss: 0.1955 - Acc: 95.68% - LR: 3.26e-06
2025-12-16 00:34:14 - models.bert_model - INFO - Epoch 8/10 - Batch 3840/10125 - Loss: 0.1237 - Acc: 95.68% - LR: 3.25e-06
2025-12-16 00:34:29 - models.bert_model - INFO - Epoch 8/10 - Batch 3880/10125 - Loss: 0.2339 - Acc: 95.69% - LR: 3.24e-06
2025-12-16 00:34:43 - models.bert_model - INFO - Epoch 8/10 - Batch 3920/10125 - Loss: 0.1133 - Acc: 95.69% - LR: 3.23e-06
2025-12-16 00:34:58 - models.bert_model - INFO - Epoch 8/10 - Batch 3960/10125 - Loss: 0.1140 - Acc: 95.68% - LR: 3.23e-06
2025-12-16 00:35:13 - models.bert_model - INFO - Epoch 8/10 - Batch 4000/10125 - Loss: 0.1403 - Acc: 95.67% - LR: 3.22e-06
2025-12-16 00:35:27 - models.bert_model - INFO - Epoch 8/10 - Batch 4040/10125 - Loss: 0.1067 - Acc: 95.67% - LR: 3.21e-06
2025-12-16 00:35:42 - models.bert_model - INFO - Epoch 8/10 - Batch 4080/10125 - Loss: 0.2702 - Acc: 95.67% - LR: 3.20e-06
2025-12-16 00:35:56 - models.bert_model - INFO - Epoch 8/10 - Batch 4120/10125 - Loss: 0.2129 - Acc: 95.67% - LR: 3.19e-06
2025-12-16 00:36:11 - models.bert_model - INFO - Epoch 8/10 - Batch 4160/10125 - Loss: 0.2624 - Acc: 95.66% - LR: 3.18e-06
2025-12-16 00:36:25 - models.bert_model - INFO - Epoch 8/10 - Batch 4200/10125 - Loss: 0.1045 - Acc: 95.65% - LR: 3.17e-06
2025-12-16 00:36:40 - models.bert_model - INFO - Epoch 8/10 - Batch 4240/10125 - Loss: 0.1913 - Acc: 95.64% - LR: 3.16e-06
2025-12-16 00:36:54 - models.bert_model - INFO - Epoch 8/10 - Batch 4280/10125 - Loss: 0.1308 - Acc: 95.65% - LR: 3.15e-06
2025-12-16 00:37:09 - models.bert_model - INFO - Epoch 8/10 - Batch 4320/10125 - Loss: 0.1524 - Acc: 95.66% - LR: 3.15e-06
2025-12-16 00:37:23 - models.bert_model - INFO - Epoch 8/10 - Batch 4360/10125 - Loss: 0.2584 - Acc: 95.66% - LR: 3.14e-06
2025-12-16 00:37:38 - models.bert_model - INFO - Epoch 8/10 - Batch 4400/10125 - Loss: 0.2251 - Acc: 95.65% - LR: 3.13e-06
2025-12-16 00:37:52 - models.bert_model - INFO - Epoch 8/10 - Batch 4440/10125 - Loss: 0.3668 - Acc: 95.65% - LR: 3.12e-06
2025-12-16 00:38:07 - models.bert_model - INFO - Epoch 8/10 - Batch 4480/10125 - Loss: 0.2112 - Acc: 95.64% - LR: 3.11e-06
2025-12-16 00:38:21 - models.bert_model - INFO - Epoch 8/10 - Batch 4520/10125 - Loss: 0.1047 - Acc: 95.63% - LR: 3.10e-06
2025-12-16 00:38:36 - models.bert_model - INFO - Epoch 8/10 - Batch 4560/10125 - Loss: 0.2582 - Acc: 95.63% - LR: 3.09e-06
2025-12-16 00:38:50 - models.bert_model - INFO - Epoch 8/10 - Batch 4600/10125 - Loss: 0.2827 - Acc: 95.64% - LR: 3.08e-06
2025-12-16 00:39:05 - models.bert_model - INFO - Epoch 8/10 - Batch 4640/10125 - Loss: 0.1159 - Acc: 95.64% - LR: 3.07e-06
2025-12-16 00:39:19 - models.bert_model - INFO - Epoch 8/10 - Batch 4680/10125 - Loss: 0.1415 - Acc: 95.64% - LR: 3.07e-06
2025-12-16 00:39:34 - models.bert_model - INFO - Epoch 8/10 - Batch 4720/10125 - Loss: 0.1940 - Acc: 95.64% - LR: 3.06e-06
2025-12-16 00:39:48 - models.bert_model - INFO - Epoch 8/10 - Batch 4760/10125 - Loss: 0.1472 - Acc: 95.64% - LR: 3.05e-06
2025-12-16 00:40:03 - models.bert_model - INFO - Epoch 8/10 - Batch 4800/10125 - Loss: 0.2997 - Acc: 95.64% - LR: 3.04e-06
2025-12-16 00:40:18 - models.bert_model - INFO - Epoch 8/10 - Batch 4840/10125 - Loss: 0.1162 - Acc: 95.63% - LR: 3.03e-06
2025-12-16 00:40:32 - models.bert_model - INFO - Epoch 8/10 - Batch 4880/10125 - Loss: 0.1584 - Acc: 95.62% - LR: 3.02e-06
2025-12-16 00:40:47 - models.bert_model - INFO - Epoch 8/10 - Batch 4920/10125 - Loss: 0.1445 - Acc: 95.62% - LR: 3.01e-06
2025-12-16 00:41:01 - models.bert_model - INFO - Epoch 8/10 - Batch 4960/10125 - Loss: 0.1438 - Acc: 95.62% - LR: 3.00e-06
2025-12-16 00:41:16 - models.bert_model - INFO - Epoch 8/10 - Batch 5000/10125 - Loss: 0.1459 - Acc: 95.62% - LR: 2.99e-06
2025-12-16 00:41:30 - models.bert_model - INFO - Epoch 8/10 - Batch 5040/10125 - Loss: 0.1556 - Acc: 95.62% - LR: 2.99e-06
2025-12-16 00:41:45 - models.bert_model - INFO - Epoch 8/10 - Batch 5080/10125 - Loss: 0.2923 - Acc: 95.63% - LR: 2.98e-06
2025-12-16 00:41:59 - models.bert_model - INFO - Epoch 8/10 - Batch 5120/10125 - Loss: 0.1156 - Acc: 95.62% - LR: 2.97e-06
2025-12-16 00:42:14 - models.bert_model - INFO - Epoch 8/10 - Batch 5160/10125 - Loss: 0.1147 - Acc: 95.62% - LR: 2.96e-06
2025-12-16 00:42:28 - models.bert_model - INFO - Epoch 8/10 - Batch 5200/10125 - Loss: 0.1868 - Acc: 95.63% - LR: 2.95e-06
2025-12-16 00:42:43 - models.bert_model - INFO - Epoch 8/10 - Batch 5240/10125 - Loss: 0.1122 - Acc: 95.63% - LR: 2.94e-06
2025-12-16 00:42:57 - models.bert_model - INFO - Epoch 8/10 - Batch 5280/10125 - Loss: 0.1509 - Acc: 95.63% - LR: 2.93e-06
2025-12-16 00:43:12 - models.bert_model - INFO - Epoch 8/10 - Batch 5320/10125 - Loss: 0.3591 - Acc: 95.63% - LR: 2.93e-06
2025-12-16 00:43:26 - models.bert_model - INFO - Epoch 8/10 - Batch 5360/10125 - Loss: 0.2693 - Acc: 95.63% - LR: 2.92e-06
2025-12-16 00:43:41 - models.bert_model - INFO - Epoch 8/10 - Batch 5400/10125 - Loss: 0.1119 - Acc: 95.62% - LR: 2.91e-06
2025-12-16 00:43:55 - models.bert_model - INFO - Epoch 8/10 - Batch 5440/10125 - Loss: 0.1175 - Acc: 95.62% - LR: 2.90e-06
2025-12-16 00:44:10 - models.bert_model - INFO - Epoch 8/10 - Batch 5480/10125 - Loss: 0.1778 - Acc: 95.62% - LR: 2.89e-06
2025-12-16 00:44:24 - models.bert_model - INFO - Epoch 8/10 - Batch 5520/10125 - Loss: 0.1072 - Acc: 95.63% - LR: 2.88e-06
2025-12-16 00:44:39 - models.bert_model - INFO - Epoch 8/10 - Batch 5560/10125 - Loss: 0.1168 - Acc: 95.64% - LR: 2.87e-06
2025-12-16 00:44:53 - models.bert_model - INFO - Epoch 8/10 - Batch 5600/10125 - Loss: 0.1120 - Acc: 95.65% - LR: 2.86e-06
2025-12-16 00:45:08 - models.bert_model - INFO - Epoch 8/10 - Batch 5640/10125 - Loss: 0.1603 - Acc: 95.64% - LR: 2.86e-06
2025-12-16 00:45:23 - models.bert_model - INFO - Epoch 8/10 - Batch 5680/10125 - Loss: 0.1556 - Acc: 95.65% - LR: 2.85e-06
2025-12-16 00:45:37 - models.bert_model - INFO - Epoch 8/10 - Batch 5720/10125 - Loss: 0.2532 - Acc: 95.64% - LR: 2.84e-06
2025-12-16 00:45:52 - models.bert_model - INFO - Epoch 8/10 - Batch 5760/10125 - Loss: 0.1166 - Acc: 95.64% - LR: 2.83e-06
2025-12-16 00:46:06 - models.bert_model - INFO - Epoch 8/10 - Batch 5800/10125 - Loss: 0.1506 - Acc: 95.64% - LR: 2.82e-06
2025-12-16 00:46:21 - models.bert_model - INFO - Epoch 8/10 - Batch 5840/10125 - Loss: 0.2512 - Acc: 95.64% - LR: 2.81e-06
2025-12-16 00:46:35 - models.bert_model - INFO - Epoch 8/10 - Batch 5880/10125 - Loss: 0.1093 - Acc: 95.63% - LR: 2.80e-06
2025-12-16 00:46:50 - models.bert_model - INFO - Epoch 8/10 - Batch 5920/10125 - Loss: 0.2046 - Acc: 95.63% - LR: 2.80e-06
2025-12-16 00:47:04 - models.bert_model - INFO - Epoch 8/10 - Batch 5960/10125 - Loss: 0.1734 - Acc: 95.62% - LR: 2.79e-06
2025-12-16 00:47:19 - models.bert_model - INFO - Epoch 8/10 - Batch 6000/10125 - Loss: 0.1074 - Acc: 95.62% - LR: 2.78e-06
2025-12-16 00:47:33 - models.bert_model - INFO - Epoch 8/10 - Batch 6040/10125 - Loss: 0.1124 - Acc: 95.61% - LR: 2.77e-06
2025-12-16 00:47:48 - models.bert_model - INFO - Epoch 8/10 - Batch 6080/10125 - Loss: 0.1240 - Acc: 95.62% - LR: 2.76e-06
2025-12-16 00:48:02 - models.bert_model - INFO - Epoch 8/10 - Batch 6120/10125 - Loss: 0.5787 - Acc: 95.61% - LR: 2.75e-06
2025-12-16 00:48:17 - models.bert_model - INFO - Epoch 8/10 - Batch 6160/10125 - Loss: 0.1127 - Acc: 95.61% - LR: 2.75e-06
2025-12-16 00:48:31 - models.bert_model - INFO - Epoch 8/10 - Batch 6200/10125 - Loss: 0.1686 - Acc: 95.60% - LR: 2.74e-06
2025-12-16 00:48:46 - models.bert_model - INFO - Epoch 8/10 - Batch 6240/10125 - Loss: 0.1222 - Acc: 95.60% - LR: 2.73e-06
2025-12-16 00:49:00 - models.bert_model - INFO - Epoch 8/10 - Batch 6280/10125 - Loss: 0.3304 - Acc: 95.60% - LR: 2.72e-06
2025-12-16 00:49:15 - models.bert_model - INFO - Epoch 8/10 - Batch 6320/10125 - Loss: 0.1099 - Acc: 95.60% - LR: 2.71e-06
2025-12-16 00:49:29 - models.bert_model - INFO - Epoch 8/10 - Batch 6360/10125 - Loss: 0.2095 - Acc: 95.59% - LR: 2.70e-06
2025-12-16 00:49:44 - models.bert_model - INFO - Epoch 8/10 - Batch 6400/10125 - Loss: 0.2471 - Acc: 95.60% - LR: 2.69e-06
2025-12-16 00:49:59 - models.bert_model - INFO - Epoch 8/10 - Batch 6440/10125 - Loss: 0.1102 - Acc: 95.60% - LR: 2.69e-06
2025-12-16 00:50:13 - models.bert_model - INFO - Epoch 8/10 - Batch 6480/10125 - Loss: 0.2701 - Acc: 95.59% - LR: 2.68e-06
2025-12-16 00:50:28 - models.bert_model - INFO - Epoch 8/10 - Batch 6520/10125 - Loss: 0.2414 - Acc: 95.59% - LR: 2.67e-06
2025-12-16 00:50:42 - models.bert_model - INFO - Epoch 8/10 - Batch 6560/10125 - Loss: 0.1325 - Acc: 95.60% - LR: 2.66e-06
2025-12-16 00:50:57 - models.bert_model - INFO - Epoch 8/10 - Batch 6600/10125 - Loss: 0.1370 - Acc: 95.60% - LR: 2.65e-06
2025-12-16 00:51:11 - models.bert_model - INFO - Epoch 8/10 - Batch 6640/10125 - Loss: 0.4015 - Acc: 95.60% - LR: 2.64e-06
2025-12-16 00:51:26 - models.bert_model - INFO - Epoch 8/10 - Batch 6680/10125 - Loss: 0.1535 - Acc: 95.60% - LR: 2.64e-06
2025-12-16 00:51:40 - models.bert_model - INFO - Epoch 8/10 - Batch 6720/10125 - Loss: 0.1452 - Acc: 95.60% - LR: 2.63e-06
2025-12-16 00:51:55 - models.bert_model - INFO - Epoch 8/10 - Batch 6760/10125 - Loss: 0.1070 - Acc: 95.60% - LR: 2.62e-06
2025-12-16 00:52:09 - models.bert_model - INFO - Epoch 8/10 - Batch 6800/10125 - Loss: 0.1544 - Acc: 95.60% - LR: 2.61e-06
2025-12-16 00:52:24 - models.bert_model - INFO - Epoch 8/10 - Batch 6840/10125 - Loss: 0.1155 - Acc: 95.60% - LR: 2.60e-06
2025-12-16 00:52:38 - models.bert_model - INFO - Epoch 8/10 - Batch 6880/10125 - Loss: 0.2014 - Acc: 95.61% - LR: 2.59e-06
2025-12-16 00:52:53 - models.bert_model - INFO - Epoch 8/10 - Batch 6920/10125 - Loss: 0.1295 - Acc: 95.62% - LR: 2.59e-06
2025-12-16 00:53:07 - models.bert_model - INFO - Epoch 8/10 - Batch 6960/10125 - Loss: 0.3473 - Acc: 95.62% - LR: 2.58e-06
2025-12-16 00:53:22 - models.bert_model - INFO - Epoch 8/10 - Batch 7000/10125 - Loss: 0.1632 - Acc: 95.62% - LR: 2.57e-06
2025-12-16 00:53:36 - models.bert_model - INFO - Epoch 8/10 - Batch 7040/10125 - Loss: 0.2280 - Acc: 95.62% - LR: 2.56e-06
2025-12-16 00:53:51 - models.bert_model - INFO - Epoch 8/10 - Batch 7080/10125 - Loss: 0.1221 - Acc: 95.62% - LR: 2.55e-06
2025-12-16 00:54:05 - models.bert_model - INFO - Epoch 8/10 - Batch 7120/10125 - Loss: 0.1471 - Acc: 95.61% - LR: 2.54e-06
2025-12-16 00:54:20 - models.bert_model - INFO - Epoch 8/10 - Batch 7160/10125 - Loss: 0.2061 - Acc: 95.62% - LR: 2.54e-06
2025-12-16 00:54:35 - models.bert_model - INFO - Epoch 8/10 - Batch 7200/10125 - Loss: 0.1377 - Acc: 95.61% - LR: 2.53e-06
2025-12-16 00:54:49 - models.bert_model - INFO - Epoch 8/10 - Batch 7240/10125 - Loss: 0.3183 - Acc: 95.61% - LR: 2.52e-06
2025-12-16 00:55:04 - models.bert_model - INFO - Epoch 8/10 - Batch 7280/10125 - Loss: 0.1502 - Acc: 95.61% - LR: 2.51e-06
2025-12-16 00:55:18 - models.bert_model - INFO - Epoch 8/10 - Batch 7320/10125 - Loss: 0.1388 - Acc: 95.61% - LR: 2.50e-06
2025-12-16 00:55:33 - models.bert_model - INFO - Epoch 8/10 - Batch 7360/10125 - Loss: 0.1587 - Acc: 95.61% - LR: 2.50e-06
2025-12-16 00:55:47 - models.bert_model - INFO - Epoch 8/10 - Batch 7400/10125 - Loss: 0.1632 - Acc: 95.61% - LR: 2.49e-06
2025-12-16 00:56:02 - models.bert_model - INFO - Epoch 8/10 - Batch 7440/10125 - Loss: 0.2583 - Acc: 95.61% - LR: 2.48e-06
2025-12-16 00:56:16 - models.bert_model - INFO - Epoch 8/10 - Batch 7480/10125 - Loss: 0.6477 - Acc: 95.61% - LR: 2.47e-06
2025-12-16 00:56:31 - models.bert_model - INFO - Epoch 8/10 - Batch 7520/10125 - Loss: 0.1232 - Acc: 95.61% - LR: 2.46e-06
2025-12-16 00:56:45 - models.bert_model - INFO - Epoch 8/10 - Batch 7560/10125 - Loss: 0.1061 - Acc: 95.61% - LR: 2.46e-06
2025-12-16 00:57:00 - models.bert_model - INFO - Epoch 8/10 - Batch 7600/10125 - Loss: 0.2792 - Acc: 95.61% - LR: 2.45e-06
2025-12-16 00:57:14 - models.bert_model - INFO - Epoch 8/10 - Batch 7640/10125 - Loss: 0.1370 - Acc: 95.61% - LR: 2.44e-06
2025-12-16 00:57:29 - models.bert_model - INFO - Epoch 8/10 - Batch 7680/10125 - Loss: 0.1471 - Acc: 95.60% - LR: 2.43e-06
2025-12-16 00:57:43 - models.bert_model - INFO - Epoch 8/10 - Batch 7720/10125 - Loss: 0.2121 - Acc: 95.60% - LR: 2.42e-06
2025-12-16 00:57:58 - models.bert_model - INFO - Epoch 8/10 - Batch 7760/10125 - Loss: 0.1202 - Acc: 95.60% - LR: 2.41e-06
2025-12-16 00:58:12 - models.bert_model - INFO - Epoch 8/10 - Batch 7800/10125 - Loss: 0.1129 - Acc: 95.60% - LR: 2.41e-06
2025-12-16 00:58:27 - models.bert_model - INFO - Epoch 8/10 - Batch 7840/10125 - Loss: 0.1536 - Acc: 95.59% - LR: 2.40e-06
2025-12-16 00:58:41 - models.bert_model - INFO - Epoch 8/10 - Batch 7880/10125 - Loss: 0.1458 - Acc: 95.59% - LR: 2.39e-06
2025-12-16 00:58:56 - models.bert_model - INFO - Epoch 8/10 - Batch 7920/10125 - Loss: 0.1112 - Acc: 95.59% - LR: 2.38e-06
2025-12-16 00:59:10 - models.bert_model - INFO - Epoch 8/10 - Batch 7960/10125 - Loss: 0.1450 - Acc: 95.59% - LR: 2.37e-06
2025-12-16 00:59:25 - models.bert_model - INFO - Epoch 8/10 - Batch 8000/10125 - Loss: 0.2248 - Acc: 95.59% - LR: 2.37e-06
2025-12-16 00:59:40 - models.bert_model - INFO - Epoch 8/10 - Batch 8040/10125 - Loss: 0.1954 - Acc: 95.58% - LR: 2.36e-06
2025-12-16 00:59:54 - models.bert_model - INFO - Epoch 8/10 - Batch 8080/10125 - Loss: 0.2119 - Acc: 95.58% - LR: 2.35e-06
2025-12-16 01:00:09 - models.bert_model - INFO - Epoch 8/10 - Batch 8120/10125 - Loss: 0.1241 - Acc: 95.58% - LR: 2.34e-06
2025-12-16 01:00:23 - models.bert_model - INFO - Epoch 8/10 - Batch 8160/10125 - Loss: 0.3868 - Acc: 95.58% - LR: 2.33e-06
2025-12-16 01:00:38 - models.bert_model - INFO - Epoch 8/10 - Batch 8200/10125 - Loss: 0.2216 - Acc: 95.57% - LR: 2.33e-06
2025-12-16 01:00:52 - models.bert_model - INFO - Epoch 8/10 - Batch 8240/10125 - Loss: 0.1536 - Acc: 95.57% - LR: 2.32e-06
2025-12-16 01:01:07 - models.bert_model - INFO - Epoch 8/10 - Batch 8280/10125 - Loss: 0.1240 - Acc: 95.57% - LR: 2.31e-06
2025-12-16 01:01:21 - models.bert_model - INFO - Epoch 8/10 - Batch 8320/10125 - Loss: 0.1049 - Acc: 95.57% - LR: 2.30e-06
2025-12-16 01:01:36 - models.bert_model - INFO - Epoch 8/10 - Batch 8360/10125 - Loss: 0.2519 - Acc: 95.57% - LR: 2.30e-06
2025-12-16 01:01:50 - models.bert_model - INFO - Epoch 8/10 - Batch 8400/10125 - Loss: 0.4912 - Acc: 95.58% - LR: 2.29e-06
2025-12-16 01:02:05 - models.bert_model - INFO - Epoch 8/10 - Batch 8440/10125 - Loss: 0.1335 - Acc: 95.58% - LR: 2.28e-06
2025-12-16 01:02:19 - models.bert_model - INFO - Epoch 8/10 - Batch 8480/10125 - Loss: 0.1395 - Acc: 95.58% - LR: 2.27e-06
2025-12-16 01:02:34 - models.bert_model - INFO - Epoch 8/10 - Batch 8520/10125 - Loss: 0.3233 - Acc: 95.58% - LR: 2.26e-06
2025-12-16 01:02:48 - models.bert_model - INFO - Epoch 8/10 - Batch 8560/10125 - Loss: 0.2589 - Acc: 95.58% - LR: 2.26e-06
2025-12-16 01:03:03 - models.bert_model - INFO - Epoch 8/10 - Batch 8600/10125 - Loss: 0.1600 - Acc: 95.59% - LR: 2.25e-06
2025-12-16 01:03:17 - models.bert_model - INFO - Epoch 8/10 - Batch 8640/10125 - Loss: 0.2548 - Acc: 95.58% - LR: 2.24e-06
2025-12-16 01:03:32 - models.bert_model - INFO - Epoch 8/10 - Batch 8680/10125 - Loss: 0.1350 - Acc: 95.58% - LR: 2.23e-06
2025-12-16 01:03:46 - models.bert_model - INFO - Epoch 8/10 - Batch 8720/10125 - Loss: 0.2298 - Acc: 95.58% - LR: 2.22e-06
2025-12-16 01:04:01 - models.bert_model - INFO - Epoch 8/10 - Batch 8760/10125 - Loss: 0.1206 - Acc: 95.58% - LR: 2.22e-06
2025-12-16 01:04:15 - models.bert_model - INFO - Epoch 8/10 - Batch 8800/10125 - Loss: 0.2556 - Acc: 95.58% - LR: 2.21e-06
2025-12-16 01:04:30 - models.bert_model - INFO - Epoch 8/10 - Batch 8840/10125 - Loss: 0.6672 - Acc: 95.58% - LR: 2.20e-06
2025-12-16 01:04:44 - models.bert_model - INFO - Epoch 8/10 - Batch 8880/10125 - Loss: 0.3801 - Acc: 95.58% - LR: 2.19e-06
2025-12-16 01:04:59 - models.bert_model - INFO - Epoch 8/10 - Batch 8920/10125 - Loss: 0.1676 - Acc: 95.58% - LR: 2.19e-06
2025-12-16 01:05:13 - models.bert_model - INFO - Epoch 8/10 - Batch 8960/10125 - Loss: 0.1026 - Acc: 95.57% - LR: 2.18e-06
2025-12-16 01:05:28 - models.bert_model - INFO - Epoch 8/10 - Batch 9000/10125 - Loss: 0.3226 - Acc: 95.57% - LR: 2.17e-06
2025-12-16 01:05:42 - models.bert_model - INFO - Epoch 8/10 - Batch 9040/10125 - Loss: 0.1242 - Acc: 95.57% - LR: 2.16e-06
2025-12-16 01:05:57 - models.bert_model - INFO - Epoch 8/10 - Batch 9080/10125 - Loss: 0.1948 - Acc: 95.58% - LR: 2.16e-06
2025-12-16 01:06:12 - models.bert_model - INFO - Epoch 8/10 - Batch 9120/10125 - Loss: 0.1982 - Acc: 95.58% - LR: 2.15e-06
2025-12-16 01:06:26 - models.bert_model - INFO - Epoch 8/10 - Batch 9160/10125 - Loss: 0.1139 - Acc: 95.58% - LR: 2.14e-06
2025-12-16 01:06:41 - models.bert_model - INFO - Epoch 8/10 - Batch 9200/10125 - Loss: 0.1097 - Acc: 95.58% - LR: 2.13e-06
2025-12-16 01:06:55 - models.bert_model - INFO - Epoch 8/10 - Batch 9240/10125 - Loss: 0.1032 - Acc: 95.59% - LR: 2.12e-06
2025-12-16 01:07:10 - models.bert_model - INFO - Epoch 8/10 - Batch 9280/10125 - Loss: 0.1066 - Acc: 95.59% - LR: 2.12e-06
2025-12-16 01:07:24 - models.bert_model - INFO - Epoch 8/10 - Batch 9320/10125 - Loss: 0.5072 - Acc: 95.59% - LR: 2.11e-06
2025-12-16 01:07:39 - models.bert_model - INFO - Epoch 8/10 - Batch 9360/10125 - Loss: 0.1099 - Acc: 95.59% - LR: 2.10e-06
2025-12-16 01:07:53 - models.bert_model - INFO - Epoch 8/10 - Batch 9400/10125 - Loss: 0.2849 - Acc: 95.60% - LR: 2.09e-06
2025-12-16 01:08:08 - models.bert_model - INFO - Epoch 8/10 - Batch 9440/10125 - Loss: 0.1900 - Acc: 95.60% - LR: 2.09e-06
2025-12-16 01:08:22 - models.bert_model - INFO - Epoch 8/10 - Batch 9480/10125 - Loss: 0.1459 - Acc: 95.60% - LR: 2.08e-06
2025-12-16 01:08:37 - models.bert_model - INFO - Epoch 8/10 - Batch 9520/10125 - Loss: 0.1735 - Acc: 95.60% - LR: 2.07e-06
2025-12-16 01:08:51 - models.bert_model - INFO - Epoch 8/10 - Batch 9560/10125 - Loss: 0.3661 - Acc: 95.60% - LR: 2.06e-06
2025-12-16 01:09:06 - models.bert_model - INFO - Epoch 8/10 - Batch 9600/10125 - Loss: 0.3403 - Acc: 95.60% - LR: 2.06e-06
2025-12-16 01:09:20 - models.bert_model - INFO - Epoch 8/10 - Batch 9640/10125 - Loss: 0.1564 - Acc: 95.60% - LR: 2.05e-06
2025-12-16 01:09:35 - models.bert_model - INFO - Epoch 8/10 - Batch 9680/10125 - Loss: 0.1175 - Acc: 95.60% - LR: 2.04e-06
2025-12-16 01:09:49 - models.bert_model - INFO - Epoch 8/10 - Batch 9720/10125 - Loss: 0.1100 - Acc: 95.60% - LR: 2.03e-06
2025-12-16 01:10:04 - models.bert_model - INFO - Epoch 8/10 - Batch 9760/10125 - Loss: 0.3229 - Acc: 95.60% - LR: 2.03e-06
2025-12-16 01:10:18 - models.bert_model - INFO - Epoch 8/10 - Batch 9800/10125 - Loss: 0.1065 - Acc: 95.61% - LR: 2.02e-06
2025-12-16 01:10:33 - models.bert_model - INFO - Epoch 8/10 - Batch 9840/10125 - Loss: 0.1561 - Acc: 95.61% - LR: 2.01e-06
2025-12-16 01:10:47 - models.bert_model - INFO - Epoch 8/10 - Batch 9880/10125 - Loss: 0.1089 - Acc: 95.61% - LR: 2.00e-06
2025-12-16 01:11:02 - models.bert_model - INFO - Epoch 8/10 - Batch 9920/10125 - Loss: 0.1647 - Acc: 95.61% - LR: 2.00e-06
2025-12-16 01:11:16 - models.bert_model - INFO - Epoch 8/10 - Batch 9960/10125 - Loss: 0.1112 - Acc: 95.62% - LR: 1.99e-06
2025-12-16 01:11:31 - models.bert_model - INFO - Epoch 8/10 - Batch 10000/10125 - Loss: 0.1831 - Acc: 95.62% - LR: 1.98e-06
2025-12-16 01:11:45 - models.bert_model - INFO - Epoch 8/10 - Batch 10040/10125 - Loss: 0.2631 - Acc: 95.62% - LR: 1.97e-06
2025-12-16 01:12:00 - models.bert_model - INFO - Epoch 8/10 - Batch 10080/10125 - Loss: 0.1796 - Acc: 95.62% - LR: 1.97e-06
2025-12-16 01:12:14 - models.bert_model - INFO - Epoch 8/10 - Batch 10120/10125 - Loss: 0.1417 - Acc: 95.62% - LR: 1.96e-06
2025-12-16 01:14:32 - models.bert_model - INFO - Epoch 8/10 - Train Loss: 0.1935, Train Acc: 95.62% - Val Loss: 0.2103, Val Acc: 94.92%
2025-12-16 01:14:32 - models.bert_model - INFO - New best validation accuracy: 94.92%
2025-12-16 01:14:47 - models.bert_model - INFO - Epoch 9/10 - Batch 40/10125 - Loss: 0.1276 - Acc: 96.25% - LR: 1.95e-06
2025-12-16 01:15:01 - models.bert_model - INFO - Epoch 9/10 - Batch 80/10125 - Loss: 0.1851 - Acc: 96.25% - LR: 1.94e-06
2025-12-16 01:15:16 - models.bert_model - INFO - Epoch 9/10 - Batch 120/10125 - Loss: 0.1612 - Acc: 96.41% - LR: 1.94e-06
2025-12-16 01:15:30 - models.bert_model - INFO - Epoch 9/10 - Batch 160/10125 - Loss: 0.1686 - Acc: 96.13% - LR: 1.93e-06
2025-12-16 01:15:45 - models.bert_model - INFO - Epoch 9/10 - Batch 200/10125 - Loss: 0.1138 - Acc: 95.91% - LR: 1.92e-06
2025-12-16 01:15:59 - models.bert_model - INFO - Epoch 9/10 - Batch 240/10125 - Loss: 0.1093 - Acc: 95.99% - LR: 1.91e-06
2025-12-16 01:16:14 - models.bert_model - INFO - Epoch 9/10 - Batch 280/10125 - Loss: 0.1500 - Acc: 95.78% - LR: 1.91e-06
2025-12-16 01:16:28 - models.bert_model - INFO - Epoch 9/10 - Batch 320/10125 - Loss: 0.3007 - Acc: 95.64% - LR: 1.90e-06
2025-12-16 01:16:43 - models.bert_model - INFO - Epoch 9/10 - Batch 360/10125 - Loss: 0.2849 - Acc: 95.66% - LR: 1.89e-06
2025-12-16 01:16:57 - models.bert_model - INFO - Epoch 9/10 - Batch 400/10125 - Loss: 0.1117 - Acc: 95.58% - LR: 1.89e-06
2025-12-16 01:17:12 - models.bert_model - INFO - Epoch 9/10 - Batch 440/10125 - Loss: 0.1075 - Acc: 95.64% - LR: 1.88e-06
2025-12-16 01:17:26 - models.bert_model - INFO - Epoch 9/10 - Batch 480/10125 - Loss: 0.2548 - Acc: 95.69% - LR: 1.87e-06
2025-12-16 01:17:41 - models.bert_model - INFO - Epoch 9/10 - Batch 520/10125 - Loss: 0.1351 - Acc: 95.71% - LR: 1.86e-06
2025-12-16 01:17:55 - models.bert_model - INFO - Epoch 9/10 - Batch 560/10125 - Loss: 0.2625 - Acc: 95.78% - LR: 1.86e-06
2025-12-16 01:18:10 - models.bert_model - INFO - Epoch 9/10 - Batch 600/10125 - Loss: 0.1783 - Acc: 95.75% - LR: 1.85e-06
2025-12-16 01:18:24 - models.bert_model - INFO - Epoch 9/10 - Batch 640/10125 - Loss: 0.1236 - Acc: 95.73% - LR: 1.84e-06
2025-12-16 01:18:39 - models.bert_model - INFO - Epoch 9/10 - Batch 680/10125 - Loss: 0.2831 - Acc: 95.78% - LR: 1.83e-06
2025-12-16 01:18:54 - models.bert_model - INFO - Epoch 9/10 - Batch 720/10125 - Loss: 0.1229 - Acc: 95.90% - LR: 1.83e-06
2025-12-16 01:19:08 - models.bert_model - INFO - Epoch 9/10 - Batch 760/10125 - Loss: 0.1021 - Acc: 95.93% - LR: 1.82e-06
2025-12-16 01:19:23 - models.bert_model - INFO - Epoch 9/10 - Batch 800/10125 - Loss: 0.2686 - Acc: 95.96% - LR: 1.81e-06
2025-12-16 01:19:37 - models.bert_model - INFO - Epoch 9/10 - Batch 840/10125 - Loss: 0.2067 - Acc: 96.03% - LR: 1.81e-06
2025-12-16 01:19:52 - models.bert_model - INFO - Epoch 9/10 - Batch 880/10125 - Loss: 0.1230 - Acc: 96.03% - LR: 1.80e-06
2025-12-16 01:20:06 - models.bert_model - INFO - Epoch 9/10 - Batch 920/10125 - Loss: 0.1219 - Acc: 96.04% - LR: 1.79e-06
2025-12-16 01:20:21 - models.bert_model - INFO - Epoch 9/10 - Batch 960/10125 - Loss: 0.3031 - Acc: 96.02% - LR: 1.78e-06
2025-12-16 01:20:35 - models.bert_model - INFO - Epoch 9/10 - Batch 1000/10125 - Loss: 0.3855 - Acc: 96.01% - LR: 1.78e-06
2025-12-16 01:20:50 - models.bert_model - INFO - Epoch 9/10 - Batch 1040/10125 - Loss: 0.2293 - Acc: 95.98% - LR: 1.77e-06
2025-12-16 01:21:04 - models.bert_model - INFO - Epoch 9/10 - Batch 1080/10125 - Loss: 0.3040 - Acc: 95.94% - LR: 1.76e-06
2025-12-16 01:21:19 - models.bert_model - INFO - Epoch 9/10 - Batch 1120/10125 - Loss: 0.1320 - Acc: 95.93% - LR: 1.76e-06
2025-12-16 01:21:33 - models.bert_model - INFO - Epoch 9/10 - Batch 1160/10125 - Loss: 0.4042 - Acc: 95.96% - LR: 1.75e-06
2025-12-16 01:21:48 - models.bert_model - INFO - Epoch 9/10 - Batch 1200/10125 - Loss: 0.1064 - Acc: 95.91% - LR: 1.74e-06
2025-12-16 01:22:02 - models.bert_model - INFO - Epoch 9/10 - Batch 1240/10125 - Loss: 0.1139 - Acc: 95.86% - LR: 1.74e-06
2025-12-16 01:22:17 - models.bert_model - INFO - Epoch 9/10 - Batch 1280/10125 - Loss: 0.1218 - Acc: 95.87% - LR: 1.73e-06
2025-12-16 01:22:31 - models.bert_model - INFO - Epoch 9/10 - Batch 1320/10125 - Loss: 0.1130 - Acc: 95.90% - LR: 1.72e-06
2025-12-16 01:22:46 - models.bert_model - INFO - Epoch 9/10 - Batch 1360/10125 - Loss: 0.1530 - Acc: 95.89% - LR: 1.71e-06
2025-12-16 01:23:00 - models.bert_model - INFO - Epoch 9/10 - Batch 1400/10125 - Loss: 0.1777 - Acc: 95.91% - LR: 1.71e-06
2025-12-16 01:23:15 - models.bert_model - INFO - Epoch 9/10 - Batch 1440/10125 - Loss: 0.1238 - Acc: 95.89% - LR: 1.70e-06
2025-12-16 01:23:30 - models.bert_model - INFO - Epoch 9/10 - Batch 1480/10125 - Loss: 0.1869 - Acc: 95.87% - LR: 1.69e-06
2025-12-16 01:23:44 - models.bert_model - INFO - Epoch 9/10 - Batch 1520/10125 - Loss: 0.2106 - Acc: 95.81% - LR: 1.69e-06
2025-12-16 01:23:59 - models.bert_model - INFO - Epoch 9/10 - Batch 1560/10125 - Loss: 0.1288 - Acc: 95.81% - LR: 1.68e-06
2025-12-16 01:24:13 - models.bert_model - INFO - Epoch 9/10 - Batch 1600/10125 - Loss: 0.1219 - Acc: 95.82% - LR: 1.67e-06
2025-12-16 01:24:28 - models.bert_model - INFO - Epoch 9/10 - Batch 1640/10125 - Loss: 0.1899 - Acc: 95.82% - LR: 1.67e-06
2025-12-16 01:24:42 - models.bert_model - INFO - Epoch 9/10 - Batch 1680/10125 - Loss: 0.2844 - Acc: 95.80% - LR: 1.66e-06
2025-12-16 01:24:57 - models.bert_model - INFO - Epoch 9/10 - Batch 1720/10125 - Loss: 0.1326 - Acc: 95.80% - LR: 1.65e-06
2025-12-16 01:25:11 - models.bert_model - INFO - Epoch 9/10 - Batch 1760/10125 - Loss: 0.1585 - Acc: 95.83% - LR: 1.65e-06
2025-12-16 01:25:26 - models.bert_model - INFO - Epoch 9/10 - Batch 1800/10125 - Loss: 0.1687 - Acc: 95.82% - LR: 1.64e-06
2025-12-16 01:25:40 - models.bert_model - INFO - Epoch 9/10 - Batch 1840/10125 - Loss: 0.3099 - Acc: 95.83% - LR: 1.63e-06
2025-12-16 01:25:55 - models.bert_model - INFO - Epoch 9/10 - Batch 1880/10125 - Loss: 0.1071 - Acc: 95.85% - LR: 1.62e-06
2025-12-16 01:26:09 - models.bert_model - INFO - Epoch 9/10 - Batch 1920/10125 - Loss: 0.2228 - Acc: 95.84% - LR: 1.62e-06
2025-12-16 01:26:24 - models.bert_model - INFO - Epoch 9/10 - Batch 1960/10125 - Loss: 0.1400 - Acc: 95.85% - LR: 1.61e-06
2025-12-16 01:26:38 - models.bert_model - INFO - Epoch 9/10 - Batch 2000/10125 - Loss: 0.1204 - Acc: 95.86% - LR: 1.60e-06
2025-12-16 01:26:53 - models.bert_model - INFO - Epoch 9/10 - Batch 2040/10125 - Loss: 0.1658 - Acc: 95.86% - LR: 1.60e-06
2025-12-16 01:27:07 - models.bert_model - INFO - Epoch 9/10 - Batch 2080/10125 - Loss: 0.1740 - Acc: 95.88% - LR: 1.59e-06
2025-12-16 01:27:22 - models.bert_model - INFO - Epoch 9/10 - Batch 2120/10125 - Loss: 0.1577 - Acc: 95.88% - LR: 1.58e-06
2025-12-16 01:27:36 - models.bert_model - INFO - Epoch 9/10 - Batch 2160/10125 - Loss: 0.3787 - Acc: 95.85% - LR: 1.58e-06
2025-12-16 01:27:51 - models.bert_model - INFO - Epoch 9/10 - Batch 2200/10125 - Loss: 0.1132 - Acc: 95.85% - LR: 1.57e-06
2025-12-16 01:28:05 - models.bert_model - INFO - Epoch 9/10 - Batch 2240/10125 - Loss: 0.1196 - Acc: 95.83% - LR: 1.56e-06
2025-12-16 01:28:20 - models.bert_model - INFO - Epoch 9/10 - Batch 2280/10125 - Loss: 0.3913 - Acc: 95.80% - LR: 1.56e-06
2025-12-16 01:28:35 - models.bert_model - INFO - Epoch 9/10 - Batch 2320/10125 - Loss: 0.2040 - Acc: 95.81% - LR: 1.55e-06
2025-12-16 01:28:49 - models.bert_model - INFO - Epoch 9/10 - Batch 2360/10125 - Loss: 0.1119 - Acc: 95.80% - LR: 1.54e-06
2025-12-16 01:29:03 - models.bert_model - INFO - Epoch 9/10 - Batch 2400/10125 - Loss: 0.1607 - Acc: 95.82% - LR: 1.54e-06
2025-12-16 01:29:18 - models.bert_model - INFO - Epoch 9/10 - Batch 2440/10125 - Loss: 0.1476 - Acc: 95.83% - LR: 1.53e-06
2025-12-16 01:29:32 - models.bert_model - INFO - Epoch 9/10 - Batch 2480/10125 - Loss: 0.1503 - Acc: 95.81% - LR: 1.52e-06
2025-12-16 01:29:47 - models.bert_model - INFO - Epoch 9/10 - Batch 2520/10125 - Loss: 0.3602 - Acc: 95.83% - LR: 1.52e-06
2025-12-16 01:30:01 - models.bert_model - INFO - Epoch 9/10 - Batch 2560/10125 - Loss: 0.3679 - Acc: 95.83% - LR: 1.51e-06
2025-12-16 01:30:16 - models.bert_model - INFO - Epoch 9/10 - Batch 2600/10125 - Loss: 0.1115 - Acc: 95.83% - LR: 1.50e-06
2025-12-16 01:30:30 - models.bert_model - INFO - Epoch 9/10 - Batch 2640/10125 - Loss: 0.1231 - Acc: 95.83% - LR: 1.50e-06
2025-12-16 01:30:45 - models.bert_model - INFO - Epoch 9/10 - Batch 2680/10125 - Loss: 0.1827 - Acc: 95.84% - LR: 1.49e-06
2025-12-16 01:30:59 - models.bert_model - INFO - Epoch 9/10 - Batch 2720/10125 - Loss: 0.1595 - Acc: 95.83% - LR: 1.48e-06
2025-12-16 01:31:14 - models.bert_model - INFO - Epoch 9/10 - Batch 2760/10125 - Loss: 0.2564 - Acc: 95.83% - LR: 1.48e-06
2025-12-16 01:31:28 - models.bert_model - INFO - Epoch 9/10 - Batch 2800/10125 - Loss: 0.3767 - Acc: 95.83% - LR: 1.47e-06
2025-12-16 01:31:43 - models.bert_model - INFO - Epoch 9/10 - Batch 2840/10125 - Loss: 0.2175 - Acc: 95.82% - LR: 1.47e-06
2025-12-16 01:31:57 - models.bert_model - INFO - Epoch 9/10 - Batch 2880/10125 - Loss: 0.3016 - Acc: 95.82% - LR: 1.46e-06
2025-12-16 01:32:12 - models.bert_model - INFO - Epoch 9/10 - Batch 2920/10125 - Loss: 0.3352 - Acc: 95.81% - LR: 1.45e-06
2025-12-16 01:32:27 - models.bert_model - INFO - Epoch 9/10 - Batch 2960/10125 - Loss: 0.3586 - Acc: 95.81% - LR: 1.45e-06
2025-12-16 01:32:41 - models.bert_model - INFO - Epoch 9/10 - Batch 3000/10125 - Loss: 0.1089 - Acc: 95.81% - LR: 1.44e-06
2025-12-16 01:32:56 - models.bert_model - INFO - Epoch 9/10 - Batch 3040/10125 - Loss: 0.1198 - Acc: 95.82% - LR: 1.43e-06
2025-12-16 01:33:10 - models.bert_model - INFO - Epoch 9/10 - Batch 3080/10125 - Loss: 0.3008 - Acc: 95.82% - LR: 1.43e-06
2025-12-16 01:33:25 - models.bert_model - INFO - Epoch 9/10 - Batch 3120/10125 - Loss: 0.1503 - Acc: 95.83% - LR: 1.42e-06
2025-12-16 01:33:39 - models.bert_model - INFO - Epoch 9/10 - Batch 3160/10125 - Loss: 0.1319 - Acc: 95.82% - LR: 1.41e-06
2025-12-16 01:33:54 - models.bert_model - INFO - Epoch 9/10 - Batch 3200/10125 - Loss: 0.1115 - Acc: 95.84% - LR: 1.41e-06
2025-12-16 01:34:09 - models.bert_model - INFO - Epoch 9/10 - Batch 3240/10125 - Loss: 0.1148 - Acc: 95.84% - LR: 1.40e-06
2025-12-16 01:34:23 - models.bert_model - INFO - Epoch 9/10 - Batch 3280/10125 - Loss: 0.3653 - Acc: 95.84% - LR: 1.39e-06
2025-12-16 01:34:37 - models.bert_model - INFO - Epoch 9/10 - Batch 3320/10125 - Loss: 0.1660 - Acc: 95.84% - LR: 1.39e-06
2025-12-16 01:34:52 - models.bert_model - INFO - Epoch 9/10 - Batch 3360/10125 - Loss: 0.1625 - Acc: 95.84% - LR: 1.38e-06
2025-12-16 01:35:06 - models.bert_model - INFO - Epoch 9/10 - Batch 3400/10125 - Loss: 0.2756 - Acc: 95.85% - LR: 1.38e-06
2025-12-16 01:35:21 - models.bert_model - INFO - Epoch 9/10 - Batch 3440/10125 - Loss: 0.1565 - Acc: 95.84% - LR: 1.37e-06
2025-12-16 01:35:36 - models.bert_model - INFO - Epoch 9/10 - Batch 3480/10125 - Loss: 0.2492 - Acc: 95.85% - LR: 1.36e-06
2025-12-16 01:35:50 - models.bert_model - INFO - Epoch 9/10 - Batch 3520/10125 - Loss: 0.1215 - Acc: 95.86% - LR: 1.36e-06
2025-12-16 01:36:05 - models.bert_model - INFO - Epoch 9/10 - Batch 3560/10125 - Loss: 0.2994 - Acc: 95.87% - LR: 1.35e-06
2025-12-16 01:36:19 - models.bert_model - INFO - Epoch 9/10 - Batch 3600/10125 - Loss: 0.1257 - Acc: 95.88% - LR: 1.34e-06
2025-12-16 01:36:34 - models.bert_model - INFO - Epoch 9/10 - Batch 3640/10125 - Loss: 0.3151 - Acc: 95.87% - LR: 1.34e-06
2025-12-16 01:36:48 - models.bert_model - INFO - Epoch 9/10 - Batch 3680/10125 - Loss: 0.1048 - Acc: 95.88% - LR: 1.33e-06
2025-12-16 01:37:03 - models.bert_model - INFO - Epoch 9/10 - Batch 3720/10125 - Loss: 0.3574 - Acc: 95.88% - LR: 1.33e-06
2025-12-16 01:37:17 - models.bert_model - INFO - Epoch 9/10 - Batch 3760/10125 - Loss: 0.1567 - Acc: 95.87% - LR: 1.32e-06
2025-12-16 01:37:32 - models.bert_model - INFO - Epoch 9/10 - Batch 3800/10125 - Loss: 0.1384 - Acc: 95.86% - LR: 1.31e-06
2025-12-16 01:37:46 - models.bert_model - INFO - Epoch 9/10 - Batch 3840/10125 - Loss: 0.2583 - Acc: 95.87% - LR: 1.31e-06
2025-12-16 01:38:01 - models.bert_model - INFO - Epoch 9/10 - Batch 3880/10125 - Loss: 0.3013 - Acc: 95.85% - LR: 1.30e-06
2025-12-16 01:38:15 - models.bert_model - INFO - Epoch 9/10 - Batch 3920/10125 - Loss: 0.2228 - Acc: 95.85% - LR: 1.29e-06
2025-12-16 01:38:30 - models.bert_model - INFO - Epoch 9/10 - Batch 3960/10125 - Loss: 0.1606 - Acc: 95.85% - LR: 1.29e-06
2025-12-16 01:38:44 - models.bert_model - INFO - Epoch 9/10 - Batch 4000/10125 - Loss: 0.1246 - Acc: 95.84% - LR: 1.28e-06
2025-12-16 01:38:59 - models.bert_model - INFO - Epoch 9/10 - Batch 4040/10125 - Loss: 0.1071 - Acc: 95.83% - LR: 1.28e-06
2025-12-16 01:39:13 - models.bert_model - INFO - Epoch 9/10 - Batch 4080/10125 - Loss: 0.1244 - Acc: 95.83% - LR: 1.27e-06
2025-12-16 01:39:28 - models.bert_model - INFO - Epoch 9/10 - Batch 4120/10125 - Loss: 0.1192 - Acc: 95.82% - LR: 1.26e-06
2025-12-16 01:39:42 - models.bert_model - INFO - Epoch 9/10 - Batch 4160/10125 - Loss: 0.2361 - Acc: 95.82% - LR: 1.26e-06
2025-12-16 01:39:57 - models.bert_model - INFO - Epoch 9/10 - Batch 4200/10125 - Loss: 0.1073 - Acc: 95.83% - LR: 1.25e-06
2025-12-16 01:40:11 - models.bert_model - INFO - Epoch 9/10 - Batch 4240/10125 - Loss: 0.1388 - Acc: 95.84% - LR: 1.25e-06
2025-12-16 01:40:26 - models.bert_model - INFO - Epoch 9/10 - Batch 4280/10125 - Loss: 0.1086 - Acc: 95.84% - LR: 1.24e-06
2025-12-16 01:40:40 - models.bert_model - INFO - Epoch 9/10 - Batch 4320/10125 - Loss: 0.1198 - Acc: 95.84% - LR: 1.23e-06
2025-12-16 01:40:55 - models.bert_model - INFO - Epoch 9/10 - Batch 4360/10125 - Loss: 0.1857 - Acc: 95.84% - LR: 1.23e-06
2025-12-16 01:41:09 - models.bert_model - INFO - Epoch 9/10 - Batch 4400/10125 - Loss: 0.1759 - Acc: 95.84% - LR: 1.22e-06
2025-12-16 01:41:24 - models.bert_model - INFO - Epoch 9/10 - Batch 4440/10125 - Loss: 0.1081 - Acc: 95.85% - LR: 1.22e-06
2025-12-16 01:41:38 - models.bert_model - INFO - Epoch 9/10 - Batch 4480/10125 - Loss: 0.1477 - Acc: 95.86% - LR: 1.21e-06
2025-12-16 01:41:53 - models.bert_model - INFO - Epoch 9/10 - Batch 4520/10125 - Loss: 0.3373 - Acc: 95.87% - LR: 1.20e-06
2025-12-16 01:42:07 - models.bert_model - INFO - Epoch 9/10 - Batch 4560/10125 - Loss: 0.1337 - Acc: 95.86% - LR: 1.20e-06
2025-12-16 01:42:22 - models.bert_model - INFO - Epoch 9/10 - Batch 4600/10125 - Loss: 0.1373 - Acc: 95.87% - LR: 1.19e-06
2025-12-16 01:42:37 - models.bert_model - INFO - Epoch 9/10 - Batch 4640/10125 - Loss: 0.3143 - Acc: 95.88% - LR: 1.19e-06
2025-12-16 01:42:51 - models.bert_model - INFO - Epoch 9/10 - Batch 4680/10125 - Loss: 0.2531 - Acc: 95.87% - LR: 1.18e-06
2025-12-16 01:43:06 - models.bert_model - INFO - Epoch 9/10 - Batch 4720/10125 - Loss: 0.1191 - Acc: 95.89% - LR: 1.17e-06
2025-12-16 01:43:20 - models.bert_model - INFO - Epoch 9/10 - Batch 4760/10125 - Loss: 0.2707 - Acc: 95.89% - LR: 1.17e-06
2025-12-16 01:43:35 - models.bert_model - INFO - Epoch 9/10 - Batch 4800/10125 - Loss: 0.1338 - Acc: 95.89% - LR: 1.16e-06
2025-12-16 01:43:49 - models.bert_model - INFO - Epoch 9/10 - Batch 4840/10125 - Loss: 0.1265 - Acc: 95.89% - LR: 1.16e-06
2025-12-16 01:44:04 - models.bert_model - INFO - Epoch 9/10 - Batch 4880/10125 - Loss: 0.1865 - Acc: 95.89% - LR: 1.15e-06
2025-12-16 01:44:18 - models.bert_model - INFO - Epoch 9/10 - Batch 4920/10125 - Loss: 0.2119 - Acc: 95.89% - LR: 1.14e-06
2025-12-16 01:44:33 - models.bert_model - INFO - Epoch 9/10 - Batch 4960/10125 - Loss: 0.1088 - Acc: 95.89% - LR: 1.14e-06
2025-12-16 01:44:47 - models.bert_model - INFO - Epoch 9/10 - Batch 5000/10125 - Loss: 0.2457 - Acc: 95.89% - LR: 1.13e-06
2025-12-16 01:45:02 - models.bert_model - INFO - Epoch 9/10 - Batch 5040/10125 - Loss: 0.1207 - Acc: 95.88% - LR: 1.13e-06
2025-12-16 01:45:16 - models.bert_model - INFO - Epoch 9/10 - Batch 5080/10125 - Loss: 0.1112 - Acc: 95.88% - LR: 1.12e-06
2025-12-16 01:45:31 - models.bert_model - INFO - Epoch 9/10 - Batch 5120/10125 - Loss: 0.2082 - Acc: 95.89% - LR: 1.12e-06
2025-12-16 01:45:45 - models.bert_model - INFO - Epoch 9/10 - Batch 5160/10125 - Loss: 0.1083 - Acc: 95.89% - LR: 1.11e-06
2025-12-16 01:46:00 - models.bert_model - INFO - Epoch 9/10 - Batch 5200/10125 - Loss: 0.1119 - Acc: 95.89% - LR: 1.10e-06
2025-12-16 01:46:14 - models.bert_model - INFO - Epoch 9/10 - Batch 5240/10125 - Loss: 0.1035 - Acc: 95.88% - LR: 1.10e-06
2025-12-16 01:46:29 - models.bert_model - INFO - Epoch 9/10 - Batch 5280/10125 - Loss: 0.1742 - Acc: 95.88% - LR: 1.09e-06
2025-12-16 01:46:43 - models.bert_model - INFO - Epoch 9/10 - Batch 5320/10125 - Loss: 0.1184 - Acc: 95.89% - LR: 1.09e-06
2025-12-16 01:46:58 - models.bert_model - INFO - Epoch 9/10 - Batch 5360/10125 - Loss: 0.1234 - Acc: 95.90% - LR: 1.08e-06
2025-12-16 01:47:12 - models.bert_model - INFO - Epoch 9/10 - Batch 5400/10125 - Loss: 0.3607 - Acc: 95.90% - LR: 1.08e-06
2025-12-16 01:47:27 - models.bert_model - INFO - Epoch 9/10 - Batch 5440/10125 - Loss: 0.1378 - Acc: 95.89% - LR: 1.07e-06
2025-12-16 01:47:41 - models.bert_model - INFO - Epoch 9/10 - Batch 5480/10125 - Loss: 0.1031 - Acc: 95.90% - LR: 1.06e-06
2025-12-16 01:47:56 - models.bert_model - INFO - Epoch 9/10 - Batch 5520/10125 - Loss: 0.1181 - Acc: 95.91% - LR: 1.06e-06
2025-12-16 01:48:10 - models.bert_model - INFO - Epoch 9/10 - Batch 5560/10125 - Loss: 0.3152 - Acc: 95.90% - LR: 1.05e-06
2025-12-16 01:48:25 - models.bert_model - INFO - Epoch 9/10 - Batch 5600/10125 - Loss: 0.1261 - Acc: 95.91% - LR: 1.05e-06
2025-12-16 01:48:39 - models.bert_model - INFO - Epoch 9/10 - Batch 5640/10125 - Loss: 0.1165 - Acc: 95.91% - LR: 1.04e-06
2025-12-16 01:48:54 - models.bert_model - INFO - Epoch 9/10 - Batch 5680/10125 - Loss: 0.1340 - Acc: 95.91% - LR: 1.04e-06
2025-12-16 01:49:09 - models.bert_model - INFO - Epoch 9/10 - Batch 5720/10125 - Loss: 0.2831 - Acc: 95.90% - LR: 1.03e-06
2025-12-16 01:49:23 - models.bert_model - INFO - Epoch 9/10 - Batch 5760/10125 - Loss: 0.1341 - Acc: 95.90% - LR: 1.03e-06
2025-12-16 01:49:38 - models.bert_model - INFO - Epoch 9/10 - Batch 5800/10125 - Loss: 0.3926 - Acc: 95.90% - LR: 1.02e-06
2025-12-16 01:49:52 - models.bert_model - INFO - Epoch 9/10 - Batch 5840/10125 - Loss: 0.1153 - Acc: 95.90% - LR: 1.01e-06
2025-12-16 01:50:07 - models.bert_model - INFO - Epoch 9/10 - Batch 5880/10125 - Loss: 0.2258 - Acc: 95.90% - LR: 1.01e-06
2025-12-16 01:50:21 - models.bert_model - INFO - Epoch 9/10 - Batch 5920/10125 - Loss: 0.1180 - Acc: 95.90% - LR: 1.00e-06
2025-12-16 01:50:36 - models.bert_model - INFO - Epoch 9/10 - Batch 5960/10125 - Loss: 0.1071 - Acc: 95.91% - LR: 9.98e-07
2025-12-16 01:50:50 - models.bert_model - INFO - Epoch 9/10 - Batch 6000/10125 - Loss: 0.1130 - Acc: 95.91% - LR: 9.93e-07
2025-12-16 01:51:05 - models.bert_model - INFO - Epoch 9/10 - Batch 6040/10125 - Loss: 0.1149 - Acc: 95.91% - LR: 9.87e-07
2025-12-16 01:51:19 - models.bert_model - INFO - Epoch 9/10 - Batch 6080/10125 - Loss: 0.1202 - Acc: 95.91% - LR: 9.82e-07
2025-12-16 01:51:34 - models.bert_model - INFO - Epoch 9/10 - Batch 6120/10125 - Loss: 0.1099 - Acc: 95.90% - LR: 9.77e-07
2025-12-16 01:51:48 - models.bert_model - INFO - Epoch 9/10 - Batch 6160/10125 - Loss: 0.2318 - Acc: 95.90% - LR: 9.71e-07
2025-12-16 01:52:03 - models.bert_model - INFO - Epoch 9/10 - Batch 6200/10125 - Loss: 0.1356 - Acc: 95.90% - LR: 9.66e-07
2025-12-16 01:52:17 - models.bert_model - INFO - Epoch 9/10 - Batch 6240/10125 - Loss: 0.2061 - Acc: 95.90% - LR: 9.60e-07
2025-12-16 01:52:32 - models.bert_model - INFO - Epoch 9/10 - Batch 6280/10125 - Loss: 0.1437 - Acc: 95.91% - LR: 9.55e-07
2025-12-16 01:52:46 - models.bert_model - INFO - Epoch 9/10 - Batch 6320/10125 - Loss: 0.2906 - Acc: 95.91% - LR: 9.50e-07
2025-12-16 01:53:01 - models.bert_model - INFO - Epoch 9/10 - Batch 6360/10125 - Loss: 0.2062 - Acc: 95.91% - LR: 9.44e-07
2025-12-16 01:53:16 - models.bert_model - INFO - Epoch 9/10 - Batch 6400/10125 - Loss: 0.1151 - Acc: 95.90% - LR: 9.39e-07
2025-12-16 01:53:30 - models.bert_model - INFO - Epoch 9/10 - Batch 6440/10125 - Loss: 0.1032 - Acc: 95.89% - LR: 9.34e-07
2025-12-16 01:53:45 - models.bert_model - INFO - Epoch 9/10 - Batch 6480/10125 - Loss: 0.1909 - Acc: 95.89% - LR: 9.28e-07
2025-12-16 01:53:59 - models.bert_model - INFO - Epoch 9/10 - Batch 6520/10125 - Loss: 0.1372 - Acc: 95.88% - LR: 9.23e-07
2025-12-16 01:54:14 - models.bert_model - INFO - Epoch 9/10 - Batch 6560/10125 - Loss: 0.1595 - Acc: 95.89% - LR: 9.18e-07
2025-12-16 01:54:28 - models.bert_model - INFO - Epoch 9/10 - Batch 6600/10125 - Loss: 0.3763 - Acc: 95.87% - LR: 9.13e-07
2025-12-16 01:54:43 - models.bert_model - INFO - Epoch 9/10 - Batch 6640/10125 - Loss: 0.2968 - Acc: 95.88% - LR: 9.07e-07
2025-12-16 01:54:57 - models.bert_model - INFO - Epoch 9/10 - Batch 6680/10125 - Loss: 0.1163 - Acc: 95.87% - LR: 9.02e-07
2025-12-16 01:55:12 - models.bert_model - INFO - Epoch 9/10 - Batch 6720/10125 - Loss: 0.1184 - Acc: 95.87% - LR: 8.97e-07
2025-12-16 01:55:26 - models.bert_model - INFO - Epoch 9/10 - Batch 6760/10125 - Loss: 0.2827 - Acc: 95.86% - LR: 8.92e-07
2025-12-16 01:55:41 - models.bert_model - INFO - Epoch 9/10 - Batch 6800/10125 - Loss: 0.1889 - Acc: 95.86% - LR: 8.87e-07
2025-12-16 01:55:55 - models.bert_model - INFO - Epoch 9/10 - Batch 6840/10125 - Loss: 0.2293 - Acc: 95.86% - LR: 8.82e-07
2025-12-16 01:56:10 - models.bert_model - INFO - Epoch 9/10 - Batch 6880/10125 - Loss: 0.1391 - Acc: 95.86% - LR: 8.76e-07
2025-12-16 01:56:24 - models.bert_model - INFO - Epoch 9/10 - Batch 6920/10125 - Loss: 0.4139 - Acc: 95.87% - LR: 8.71e-07
2025-12-16 01:56:39 - models.bert_model - INFO - Epoch 9/10 - Batch 6960/10125 - Loss: 0.1379 - Acc: 95.86% - LR: 8.66e-07
2025-12-16 01:56:53 - models.bert_model - INFO - Epoch 9/10 - Batch 7000/10125 - Loss: 0.1387 - Acc: 95.86% - LR: 8.61e-07
2025-12-16 01:57:08 - models.bert_model - INFO - Epoch 9/10 - Batch 7040/10125 - Loss: 0.1363 - Acc: 95.86% - LR: 8.56e-07
2025-12-16 01:57:22 - models.bert_model - INFO - Epoch 9/10 - Batch 7080/10125 - Loss: 0.1424 - Acc: 95.86% - LR: 8.51e-07
2025-12-16 01:57:37 - models.bert_model - INFO - Epoch 9/10 - Batch 7120/10125 - Loss: 0.3003 - Acc: 95.86% - LR: 8.46e-07
2025-12-16 01:57:51 - models.bert_model - INFO - Epoch 9/10 - Batch 7160/10125 - Loss: 0.2876 - Acc: 95.86% - LR: 8.41e-07
2025-12-16 01:58:06 - models.bert_model - INFO - Epoch 9/10 - Batch 7200/10125 - Loss: 0.1231 - Acc: 95.86% - LR: 8.36e-07
2025-12-16 01:58:20 - models.bert_model - INFO - Epoch 9/10 - Batch 7240/10125 - Loss: 0.2165 - Acc: 95.86% - LR: 8.31e-07
2025-12-16 01:58:35 - models.bert_model - INFO - Epoch 9/10 - Batch 7280/10125 - Loss: 0.1016 - Acc: 95.86% - LR: 8.26e-07
2025-12-16 01:58:50 - models.bert_model - INFO - Epoch 9/10 - Batch 7320/10125 - Loss: 0.4287 - Acc: 95.86% - LR: 8.21e-07
2025-12-16 01:59:04 - models.bert_model - INFO - Epoch 9/10 - Batch 7360/10125 - Loss: 0.1022 - Acc: 95.86% - LR: 8.16e-07
2025-12-16 01:59:19 - models.bert_model - INFO - Epoch 9/10 - Batch 7400/10125 - Loss: 0.1159 - Acc: 95.86% - LR: 8.11e-07
2025-12-16 01:59:33 - models.bert_model - INFO - Epoch 9/10 - Batch 7440/10125 - Loss: 0.1261 - Acc: 95.86% - LR: 8.06e-07
2025-12-16 01:59:48 - models.bert_model - INFO - Epoch 9/10 - Batch 7480/10125 - Loss: 0.3126 - Acc: 95.86% - LR: 8.01e-07
2025-12-16 02:00:02 - models.bert_model - INFO - Epoch 9/10 - Batch 7520/10125 - Loss: 0.3181 - Acc: 95.86% - LR: 7.96e-07
2025-12-16 02:00:17 - models.bert_model - INFO - Epoch 9/10 - Batch 7560/10125 - Loss: 0.1300 - Acc: 95.86% - LR: 7.91e-07
2025-12-16 02:00:31 - models.bert_model - INFO - Epoch 9/10 - Batch 7600/10125 - Loss: 0.1079 - Acc: 95.86% - LR: 7.86e-07
2025-12-16 02:00:46 - models.bert_model - INFO - Epoch 9/10 - Batch 7640/10125 - Loss: 0.1682 - Acc: 95.85% - LR: 7.81e-07
2025-12-16 02:01:00 - models.bert_model - INFO - Epoch 9/10 - Batch 7680/10125 - Loss: 0.2302 - Acc: 95.85% - LR: 7.76e-07
2025-12-16 02:01:15 - models.bert_model - INFO - Epoch 9/10 - Batch 7720/10125 - Loss: 0.1310 - Acc: 95.85% - LR: 7.72e-07
2025-12-16 02:01:29 - models.bert_model - INFO - Epoch 9/10 - Batch 7760/10125 - Loss: 0.1106 - Acc: 95.85% - LR: 7.67e-07
2025-12-16 02:01:44 - models.bert_model - INFO - Epoch 9/10 - Batch 7800/10125 - Loss: 0.3192 - Acc: 95.86% - LR: 7.62e-07
2025-12-16 02:01:58 - models.bert_model - INFO - Epoch 9/10 - Batch 7840/10125 - Loss: 0.1773 - Acc: 95.86% - LR: 7.57e-07
2025-12-16 02:02:13 - models.bert_model - INFO - Epoch 9/10 - Batch 7880/10125 - Loss: 0.3005 - Acc: 95.86% - LR: 7.52e-07
2025-12-16 02:02:27 - models.bert_model - INFO - Epoch 9/10 - Batch 7920/10125 - Loss: 0.1441 - Acc: 95.86% - LR: 7.48e-07
2025-12-16 02:02:42 - models.bert_model - INFO - Epoch 9/10 - Batch 7960/10125 - Loss: 0.1185 - Acc: 95.86% - LR: 7.43e-07
2025-12-16 02:02:56 - models.bert_model - INFO - Epoch 9/10 - Batch 8000/10125 - Loss: 0.2549 - Acc: 95.85% - LR: 7.38e-07
2025-12-16 02:03:11 - models.bert_model - INFO - Epoch 9/10 - Batch 8040/10125 - Loss: 0.2831 - Acc: 95.85% - LR: 7.33e-07
2025-12-16 02:03:25 - models.bert_model - INFO - Epoch 9/10 - Batch 8080/10125 - Loss: 0.1473 - Acc: 95.85% - LR: 7.29e-07
2025-12-16 02:03:40 - models.bert_model - INFO - Epoch 9/10 - Batch 8120/10125 - Loss: 0.1153 - Acc: 95.84% - LR: 7.24e-07
2025-12-16 02:03:54 - models.bert_model - INFO - Epoch 9/10 - Batch 8160/10125 - Loss: 0.2775 - Acc: 95.84% - LR: 7.19e-07
2025-12-16 02:04:09 - models.bert_model - INFO - Epoch 9/10 - Batch 8200/10125 - Loss: 0.3243 - Acc: 95.85% - LR: 7.15e-07
2025-12-16 02:04:23 - models.bert_model - INFO - Epoch 9/10 - Batch 8240/10125 - Loss: 0.1738 - Acc: 95.85% - LR: 7.10e-07
2025-12-16 02:04:38 - models.bert_model - INFO - Epoch 9/10 - Batch 8280/10125 - Loss: 0.1351 - Acc: 95.85% - LR: 7.05e-07
2025-12-16 02:04:52 - models.bert_model - INFO - Epoch 9/10 - Batch 8320/10125 - Loss: 0.1497 - Acc: 95.85% - LR: 7.01e-07
2025-12-16 02:05:07 - models.bert_model - INFO - Epoch 9/10 - Batch 8360/10125 - Loss: 0.3379 - Acc: 95.86% - LR: 6.96e-07
2025-12-16 02:05:22 - models.bert_model - INFO - Epoch 9/10 - Batch 8400/10125 - Loss: 0.2674 - Acc: 95.86% - LR: 6.91e-07
2025-12-16 02:05:36 - models.bert_model - INFO - Epoch 9/10 - Batch 8440/10125 - Loss: 0.1294 - Acc: 95.86% - LR: 6.87e-07
2025-12-16 02:05:51 - models.bert_model - INFO - Epoch 9/10 - Batch 8480/10125 - Loss: 0.2018 - Acc: 95.86% - LR: 6.82e-07
2025-12-16 02:06:05 - models.bert_model - INFO - Epoch 9/10 - Batch 8520/10125 - Loss: 0.1135 - Acc: 95.86% - LR: 6.78e-07
2025-12-16 02:06:20 - models.bert_model - INFO - Epoch 9/10 - Batch 8560/10125 - Loss: 0.1116 - Acc: 95.86% - LR: 6.73e-07
2025-12-16 02:06:34 - models.bert_model - INFO - Epoch 9/10 - Batch 8600/10125 - Loss: 0.1062 - Acc: 95.86% - LR: 6.69e-07
2025-12-16 02:06:49 - models.bert_model - INFO - Epoch 9/10 - Batch 8640/10125 - Loss: 0.1344 - Acc: 95.86% - LR: 6.64e-07
2025-12-16 02:07:03 - models.bert_model - INFO - Epoch 9/10 - Batch 8680/10125 - Loss: 0.1262 - Acc: 95.85% - LR: 6.60e-07
2025-12-16 02:07:18 - models.bert_model - INFO - Epoch 9/10 - Batch 8720/10125 - Loss: 0.1122 - Acc: 95.86% - LR: 6.55e-07
2025-12-16 02:07:32 - models.bert_model - INFO - Epoch 9/10 - Batch 8760/10125 - Loss: 0.1728 - Acc: 95.86% - LR: 6.51e-07
2025-12-16 02:07:47 - models.bert_model - INFO - Epoch 9/10 - Batch 8800/10125 - Loss: 0.1352 - Acc: 95.86% - LR: 6.46e-07
2025-12-16 02:08:01 - models.bert_model - INFO - Epoch 9/10 - Batch 8840/10125 - Loss: 0.1539 - Acc: 95.86% - LR: 6.42e-07
2025-12-16 02:08:16 - models.bert_model - INFO - Epoch 9/10 - Batch 8880/10125 - Loss: 0.1205 - Acc: 95.85% - LR: 6.37e-07
2025-12-16 02:08:30 - models.bert_model - INFO - Epoch 9/10 - Batch 8920/10125 - Loss: 0.1734 - Acc: 95.85% - LR: 6.33e-07
2025-12-16 02:08:45 - models.bert_model - INFO - Epoch 9/10 - Batch 8960/10125 - Loss: 0.1299 - Acc: 95.86% - LR: 6.29e-07
2025-12-16 02:08:59 - models.bert_model - INFO - Epoch 9/10 - Batch 9000/10125 - Loss: 0.1038 - Acc: 95.86% - LR: 6.24e-07
2025-12-16 02:09:14 - models.bert_model - INFO - Epoch 9/10 - Batch 9040/10125 - Loss: 0.2975 - Acc: 95.85% - LR: 6.20e-07
2025-12-16 02:09:29 - models.bert_model - INFO - Epoch 9/10 - Batch 9080/10125 - Loss: 0.2214 - Acc: 95.85% - LR: 6.16e-07
2025-12-16 02:09:43 - models.bert_model - INFO - Epoch 9/10 - Batch 9120/10125 - Loss: 0.1243 - Acc: 95.86% - LR: 6.11e-07
2025-12-16 02:09:58 - models.bert_model - INFO - Epoch 9/10 - Batch 9160/10125 - Loss: 0.1507 - Acc: 95.85% - LR: 6.07e-07
2025-12-16 02:10:12 - models.bert_model - INFO - Epoch 9/10 - Batch 9200/10125 - Loss: 0.1786 - Acc: 95.85% - LR: 6.03e-07
2025-12-16 02:10:27 - models.bert_model - INFO - Epoch 9/10 - Batch 9240/10125 - Loss: 0.2484 - Acc: 95.85% - LR: 5.98e-07
2025-12-16 02:10:41 - models.bert_model - INFO - Epoch 9/10 - Batch 9280/10125 - Loss: 0.1256 - Acc: 95.85% - LR: 5.94e-07
2025-12-16 02:10:56 - models.bert_model - INFO - Epoch 9/10 - Batch 9320/10125 - Loss: 0.1246 - Acc: 95.85% - LR: 5.90e-07
2025-12-16 02:11:10 - models.bert_model - INFO - Epoch 9/10 - Batch 9360/10125 - Loss: 0.1099 - Acc: 95.85% - LR: 5.85e-07
2025-12-16 02:11:25 - models.bert_model - INFO - Epoch 9/10 - Batch 9400/10125 - Loss: 0.1907 - Acc: 95.85% - LR: 5.81e-07
2025-12-16 02:11:39 - models.bert_model - INFO - Epoch 9/10 - Batch 9440/10125 - Loss: 0.1366 - Acc: 95.85% - LR: 5.77e-07
2025-12-16 02:11:54 - models.bert_model - INFO - Epoch 9/10 - Batch 9480/10125 - Loss: 0.1729 - Acc: 95.85% - LR: 5.73e-07
2025-12-16 02:12:08 - models.bert_model - INFO - Epoch 9/10 - Batch 9520/10125 - Loss: 0.1025 - Acc: 95.85% - LR: 5.69e-07
2025-12-16 02:12:23 - models.bert_model - INFO - Epoch 9/10 - Batch 9560/10125 - Loss: 0.1076 - Acc: 95.85% - LR: 5.64e-07
2025-12-16 02:12:37 - models.bert_model - INFO - Epoch 9/10 - Batch 9600/10125 - Loss: 0.1808 - Acc: 95.85% - LR: 5.60e-07
2025-12-16 02:12:52 - models.bert_model - INFO - Epoch 9/10 - Batch 9640/10125 - Loss: 0.3991 - Acc: 95.85% - LR: 5.56e-07
2025-12-16 02:13:06 - models.bert_model - INFO - Epoch 9/10 - Batch 9680/10125 - Loss: 0.2404 - Acc: 95.85% - LR: 5.52e-07
2025-12-16 02:13:21 - models.bert_model - INFO - Epoch 9/10 - Batch 9720/10125 - Loss: 0.1074 - Acc: 95.86% - LR: 5.48e-07
2025-12-16 02:13:35 - models.bert_model - INFO - Epoch 9/10 - Batch 9760/10125 - Loss: 0.1460 - Acc: 95.86% - LR: 5.44e-07
2025-12-16 02:13:50 - models.bert_model - INFO - Epoch 9/10 - Batch 9800/10125 - Loss: 0.1512 - Acc: 95.86% - LR: 5.40e-07
2025-12-16 02:14:04 - models.bert_model - INFO - Epoch 9/10 - Batch 9840/10125 - Loss: 0.1551 - Acc: 95.86% - LR: 5.36e-07
2025-12-16 02:14:19 - models.bert_model - INFO - Epoch 9/10 - Batch 9880/10125 - Loss: 0.2384 - Acc: 95.87% - LR: 5.32e-07
2025-12-16 02:14:33 - models.bert_model - INFO - Epoch 9/10 - Batch 9920/10125 - Loss: 0.2754 - Acc: 95.87% - LR: 5.28e-07
2025-12-16 02:14:48 - models.bert_model - INFO - Epoch 9/10 - Batch 9960/10125 - Loss: 0.1050 - Acc: 95.87% - LR: 5.23e-07
2025-12-16 02:15:03 - models.bert_model - INFO - Epoch 9/10 - Batch 10000/10125 - Loss: 0.1251 - Acc: 95.87% - LR: 5.19e-07
2025-12-16 02:15:17 - models.bert_model - INFO - Epoch 9/10 - Batch 10040/10125 - Loss: 0.1105 - Acc: 95.87% - LR: 5.15e-07
2025-12-16 02:15:32 - models.bert_model - INFO - Epoch 9/10 - Batch 10080/10125 - Loss: 0.2276 - Acc: 95.87% - LR: 5.11e-07
2025-12-16 02:15:46 - models.bert_model - INFO - Epoch 9/10 - Batch 10120/10125 - Loss: 0.1417 - Acc: 95.87% - LR: 5.08e-07
2025-12-16 02:18:04 - models.bert_model - INFO - Epoch 9/10 - Train Loss: 0.1887, Train Acc: 95.87% - Val Loss: 0.2075, Val Acc: 94.94%
2025-12-16 02:18:04 - models.bert_model - INFO - New best validation accuracy: 94.94%
2025-12-16 02:18:19 - models.bert_model - INFO - Epoch 10/10 - Batch 40/10125 - Loss: 0.3129 - Acc: 96.41% - LR: 5.03e-07
2025-12-16 02:18:33 - models.bert_model - INFO - Epoch 10/10 - Batch 80/10125 - Loss: 0.1325 - Acc: 96.41% - LR: 4.99e-07
2025-12-16 02:18:48 - models.bert_model - INFO - Epoch 10/10 - Batch 120/10125 - Loss: 0.1678 - Acc: 96.35% - LR: 4.95e-07
2025-12-16 02:19:02 - models.bert_model - INFO - Epoch 10/10 - Batch 160/10125 - Loss: 0.1018 - Acc: 96.60% - LR: 4.91e-07
2025-12-16 02:19:17 - models.bert_model - INFO - Epoch 10/10 - Batch 200/10125 - Loss: 0.1103 - Acc: 96.50% - LR: 4.88e-07
2025-12-16 02:19:31 - models.bert_model - INFO - Epoch 10/10 - Batch 240/10125 - Loss: 0.1481 - Acc: 96.30% - LR: 4.84e-07
2025-12-16 02:19:46 - models.bert_model - INFO - Epoch 10/10 - Batch 280/10125 - Loss: 0.1155 - Acc: 96.21% - LR: 4.80e-07
2025-12-16 02:20:00 - models.bert_model - INFO - Epoch 10/10 - Batch 320/10125 - Loss: 0.2497 - Acc: 96.19% - LR: 4.76e-07
2025-12-16 02:20:15 - models.bert_model - INFO - Epoch 10/10 - Batch 360/10125 - Loss: 0.1076 - Acc: 96.15% - LR: 4.72e-07
2025-12-16 02:20:29 - models.bert_model - INFO - Epoch 10/10 - Batch 400/10125 - Loss: 0.5400 - Acc: 96.16% - LR: 4.68e-07
2025-12-16 02:20:44 - models.bert_model - INFO - Epoch 10/10 - Batch 440/10125 - Loss: 0.4019 - Acc: 96.16% - LR: 4.64e-07
2025-12-16 02:20:58 - models.bert_model - INFO - Epoch 10/10 - Batch 480/10125 - Loss: 0.1665 - Acc: 95.99% - LR: 4.61e-07
2025-12-16 02:21:13 - models.bert_model - INFO - Epoch 10/10 - Batch 520/10125 - Loss: 0.1727 - Acc: 95.93% - LR: 4.57e-07
2025-12-16 02:21:27 - models.bert_model - INFO - Epoch 10/10 - Batch 560/10125 - Loss: 0.1747 - Acc: 95.90% - LR: 4.53e-07
2025-12-16 02:21:42 - models.bert_model - INFO - Epoch 10/10 - Batch 600/10125 - Loss: 0.3278 - Acc: 95.89% - LR: 4.49e-07
2025-12-16 02:21:56 - models.bert_model - INFO - Epoch 10/10 - Batch 640/10125 - Loss: 0.1065 - Acc: 95.95% - LR: 4.46e-07
2025-12-16 02:22:11 - models.bert_model - INFO - Epoch 10/10 - Batch 680/10125 - Loss: 0.1288 - Acc: 96.03% - LR: 4.42e-07
2025-12-16 02:22:25 - models.bert_model - INFO - Epoch 10/10 - Batch 720/10125 - Loss: 0.1070 - Acc: 96.02% - LR: 4.38e-07
2025-12-16 02:22:40 - models.bert_model - INFO - Epoch 10/10 - Batch 760/10125 - Loss: 0.1235 - Acc: 96.01% - LR: 4.35e-07
2025-12-16 02:22:54 - models.bert_model - INFO - Epoch 10/10 - Batch 800/10125 - Loss: 0.2182 - Acc: 96.00% - LR: 4.31e-07
2025-12-16 02:23:09 - models.bert_model - INFO - Epoch 10/10 - Batch 840/10125 - Loss: 0.3982 - Acc: 95.92% - LR: 4.27e-07
2025-12-16 02:23:23 - models.bert_model - INFO - Epoch 10/10 - Batch 880/10125 - Loss: 0.1121 - Acc: 95.90% - LR: 4.24e-07
2025-12-16 02:23:38 - models.bert_model - INFO - Epoch 10/10 - Batch 920/10125 - Loss: 0.2233 - Acc: 95.91% - LR: 4.20e-07
2025-12-16 02:23:53 - models.bert_model - INFO - Epoch 10/10 - Batch 960/10125 - Loss: 0.1728 - Acc: 95.92% - LR: 4.16e-07
2025-12-16 02:24:07 - models.bert_model - INFO - Epoch 10/10 - Batch 1000/10125 - Loss: 0.1740 - Acc: 96.01% - LR: 4.13e-07
2025-12-16 02:24:22 - models.bert_model - INFO - Epoch 10/10 - Batch 1040/10125 - Loss: 0.1841 - Acc: 95.99% - LR: 4.09e-07
2025-12-16 02:24:36 - models.bert_model - INFO - Epoch 10/10 - Batch 1080/10125 - Loss: 0.1553 - Acc: 95.97% - LR: 4.06e-07
2025-12-16 02:24:51 - models.bert_model - INFO - Epoch 10/10 - Batch 1120/10125 - Loss: 0.1430 - Acc: 95.97% - LR: 4.02e-07
2025-12-16 02:25:05 - models.bert_model - INFO - Epoch 10/10 - Batch 1160/10125 - Loss: 0.4536 - Acc: 95.96% - LR: 3.99e-07
2025-12-16 02:25:20 - models.bert_model - INFO - Epoch 10/10 - Batch 1200/10125 - Loss: 0.2914 - Acc: 95.97% - LR: 3.95e-07
2025-12-16 02:25:34 - models.bert_model - INFO - Epoch 10/10 - Batch 1240/10125 - Loss: 0.1374 - Acc: 95.99% - LR: 3.92e-07
2025-12-16 02:25:49 - models.bert_model - INFO - Epoch 10/10 - Batch 1280/10125 - Loss: 0.1103 - Acc: 95.97% - LR: 3.88e-07
2025-12-16 02:26:03 - models.bert_model - INFO - Epoch 10/10 - Batch 1320/10125 - Loss: 0.1076 - Acc: 95.97% - LR: 3.85e-07
2025-12-16 02:26:18 - models.bert_model - INFO - Epoch 10/10 - Batch 1360/10125 - Loss: 0.2248 - Acc: 95.93% - LR: 3.81e-07
2025-12-16 02:26:32 - models.bert_model - INFO - Epoch 10/10 - Batch 1400/10125 - Loss: 0.1499 - Acc: 95.97% - LR: 3.78e-07
2025-12-16 02:26:47 - models.bert_model - INFO - Epoch 10/10 - Batch 1440/10125 - Loss: 0.1340 - Acc: 95.93% - LR: 3.74e-07
2025-12-16 02:27:01 - models.bert_model - INFO - Epoch 10/10 - Batch 1480/10125 - Loss: 0.1023 - Acc: 95.95% - LR: 3.71e-07
2025-12-16 02:27:16 - models.bert_model - INFO - Epoch 10/10 - Batch 1520/10125 - Loss: 0.1059 - Acc: 95.94% - LR: 3.68e-07
2025-12-16 02:27:30 - models.bert_model - INFO - Epoch 10/10 - Batch 1560/10125 - Loss: 0.1090 - Acc: 95.96% - LR: 3.64e-07
2025-12-16 02:27:45 - models.bert_model - INFO - Epoch 10/10 - Batch 1600/10125 - Loss: 0.1135 - Acc: 95.98% - LR: 3.61e-07
2025-12-16 02:27:59 - models.bert_model - INFO - Epoch 10/10 - Batch 1640/10125 - Loss: 0.1292 - Acc: 95.98% - LR: 3.57e-07
2025-12-16 02:28:14 - models.bert_model - INFO - Epoch 10/10 - Batch 1680/10125 - Loss: 0.3020 - Acc: 96.00% - LR: 3.54e-07
2025-12-16 02:28:28 - models.bert_model - INFO - Epoch 10/10 - Batch 1720/10125 - Loss: 0.1176 - Acc: 95.99% - LR: 3.51e-07
2025-12-16 02:28:43 - models.bert_model - INFO - Epoch 10/10 - Batch 1760/10125 - Loss: 0.1914 - Acc: 96.01% - LR: 3.48e-07
2025-12-16 02:28:58 - models.bert_model - INFO - Epoch 10/10 - Batch 1800/10125 - Loss: 0.1170 - Acc: 96.04% - LR: 3.44e-07
2025-12-16 02:29:12 - models.bert_model - INFO - Epoch 10/10 - Batch 1840/10125 - Loss: 0.1270 - Acc: 96.03% - LR: 3.41e-07
2025-12-16 02:29:27 - models.bert_model - INFO - Epoch 10/10 - Batch 1880/10125 - Loss: 0.1584 - Acc: 96.04% - LR: 3.38e-07
2025-12-16 02:29:41 - models.bert_model - INFO - Epoch 10/10 - Batch 1920/10125 - Loss: 0.1108 - Acc: 96.05% - LR: 3.34e-07
2025-12-16 02:29:56 - models.bert_model - INFO - Epoch 10/10 - Batch 1960/10125 - Loss: 0.1280 - Acc: 96.06% - LR: 3.31e-07
2025-12-16 02:30:10 - models.bert_model - INFO - Epoch 10/10 - Batch 2000/10125 - Loss: 0.1159 - Acc: 96.06% - LR: 3.28e-07
2025-12-16 02:30:25 - models.bert_model - INFO - Epoch 10/10 - Batch 2040/10125 - Loss: 0.1416 - Acc: 96.08% - LR: 3.25e-07
2025-12-16 02:30:39 - models.bert_model - INFO - Epoch 10/10 - Batch 2080/10125 - Loss: 0.1465 - Acc: 96.05% - LR: 3.22e-07
2025-12-16 02:30:53 - models.bert_model - INFO - Epoch 10/10 - Batch 2120/10125 - Loss: 0.1813 - Acc: 96.04% - LR: 3.18e-07
2025-12-16 02:31:08 - models.bert_model - INFO - Epoch 10/10 - Batch 2160/10125 - Loss: 0.2519 - Acc: 96.06% - LR: 3.15e-07
2025-12-16 02:31:22 - models.bert_model - INFO - Epoch 10/10 - Batch 2200/10125 - Loss: 0.1097 - Acc: 96.04% - LR: 3.12e-07
2025-12-16 02:31:37 - models.bert_model - INFO - Epoch 10/10 - Batch 2240/10125 - Loss: 0.1746 - Acc: 96.02% - LR: 3.09e-07
2025-12-16 02:31:51 - models.bert_model - INFO - Epoch 10/10 - Batch 2280/10125 - Loss: 0.1137 - Acc: 96.00% - LR: 3.06e-07
2025-12-16 02:32:06 - models.bert_model - INFO - Epoch 10/10 - Batch 2320/10125 - Loss: 0.1881 - Acc: 95.99% - LR: 3.03e-07
2025-12-16 02:32:20 - models.bert_model - INFO - Epoch 10/10 - Batch 2360/10125 - Loss: 0.1230 - Acc: 95.99% - LR: 3.00e-07
2025-12-16 02:32:35 - models.bert_model - INFO - Epoch 10/10 - Batch 2400/10125 - Loss: 0.1720 - Acc: 95.98% - LR: 2.97e-07
2025-12-16 02:32:49 - models.bert_model - INFO - Epoch 10/10 - Batch 2440/10125 - Loss: 0.1173 - Acc: 96.00% - LR: 2.94e-07
2025-12-16 02:33:04 - models.bert_model - INFO - Epoch 10/10 - Batch 2480/10125 - Loss: 0.2082 - Acc: 95.99% - LR: 2.91e-07
2025-12-16 02:33:19 - models.bert_model - INFO - Epoch 10/10 - Batch 2520/10125 - Loss: 0.3063 - Acc: 96.00% - LR: 2.88e-07
2025-12-16 02:33:33 - models.bert_model - INFO - Epoch 10/10 - Batch 2560/10125 - Loss: 0.1097 - Acc: 96.01% - LR: 2.85e-07
2025-12-16 02:33:48 - models.bert_model - INFO - Epoch 10/10 - Batch 2600/10125 - Loss: 0.1427 - Acc: 96.01% - LR: 2.82e-07
2025-12-16 02:34:02 - models.bert_model - INFO - Epoch 10/10 - Batch 2640/10125 - Loss: 0.1159 - Acc: 95.99% - LR: 2.79e-07
2025-12-16 02:34:17 - models.bert_model - INFO - Epoch 10/10 - Batch 2680/10125 - Loss: 0.1429 - Acc: 96.00% - LR: 2.76e-07
2025-12-16 02:34:31 - models.bert_model - INFO - Epoch 10/10 - Batch 2720/10125 - Loss: 0.1126 - Acc: 95.98% - LR: 2.73e-07
2025-12-16 02:34:46 - models.bert_model - INFO - Epoch 10/10 - Batch 2760/10125 - Loss: 0.1043 - Acc: 95.98% - LR: 2.70e-07
2025-12-16 02:35:00 - models.bert_model - INFO - Epoch 10/10 - Batch 2800/10125 - Loss: 0.1348 - Acc: 96.00% - LR: 2.67e-07
2025-12-16 02:35:15 - models.bert_model - INFO - Epoch 10/10 - Batch 2840/10125 - Loss: 0.2365 - Acc: 95.99% - LR: 2.64e-07
2025-12-16 02:35:29 - models.bert_model - INFO - Epoch 10/10 - Batch 2880/10125 - Loss: 0.1611 - Acc: 95.99% - LR: 2.61e-07
2025-12-16 02:35:44 - models.bert_model - INFO - Epoch 10/10 - Batch 2920/10125 - Loss: 0.1118 - Acc: 96.00% - LR: 2.58e-07
2025-12-16 02:35:58 - models.bert_model - INFO - Epoch 10/10 - Batch 2960/10125 - Loss: 0.1594 - Acc: 96.00% - LR: 2.56e-07
2025-12-16 02:36:13 - models.bert_model - INFO - Epoch 10/10 - Batch 3000/10125 - Loss: 0.2622 - Acc: 95.99% - LR: 2.53e-07
2025-12-16 02:36:27 - models.bert_model - INFO - Epoch 10/10 - Batch 3040/10125 - Loss: 0.1100 - Acc: 95.98% - LR: 2.50e-07
2025-12-16 02:36:42 - models.bert_model - INFO - Epoch 10/10 - Batch 3080/10125 - Loss: 0.1039 - Acc: 95.99% - LR: 2.47e-07
2025-12-16 02:36:56 - models.bert_model - INFO - Epoch 10/10 - Batch 3120/10125 - Loss: 0.1061 - Acc: 95.99% - LR: 2.44e-07
2025-12-16 02:37:11 - models.bert_model - INFO - Epoch 10/10 - Batch 3160/10125 - Loss: 0.1816 - Acc: 95.99% - LR: 2.42e-07
2025-12-16 02:37:25 - models.bert_model - INFO - Epoch 10/10 - Batch 3200/10125 - Loss: 0.1360 - Acc: 96.00% - LR: 2.39e-07
2025-12-16 02:37:40 - models.bert_model - INFO - Epoch 10/10 - Batch 3240/10125 - Loss: 0.1192 - Acc: 95.97% - LR: 2.36e-07
2025-12-16 02:37:55 - models.bert_model - INFO - Epoch 10/10 - Batch 3280/10125 - Loss: 0.2473 - Acc: 95.97% - LR: 2.33e-07
2025-12-16 02:38:09 - models.bert_model - INFO - Epoch 10/10 - Batch 3320/10125 - Loss: 0.1880 - Acc: 95.97% - LR: 2.31e-07
2025-12-16 02:38:24 - models.bert_model - INFO - Epoch 10/10 - Batch 3360/10125 - Loss: 0.2546 - Acc: 95.97% - LR: 2.28e-07
2025-12-16 02:38:38 - models.bert_model - INFO - Epoch 10/10 - Batch 3400/10125 - Loss: 0.1149 - Acc: 95.98% - LR: 2.25e-07
2025-12-16 02:38:53 - models.bert_model - INFO - Epoch 10/10 - Batch 3440/10125 - Loss: 0.1161 - Acc: 95.98% - LR: 2.23e-07
2025-12-16 02:39:07 - models.bert_model - INFO - Epoch 10/10 - Batch 3480/10125 - Loss: 0.2542 - Acc: 95.98% - LR: 2.20e-07
2025-12-16 02:39:22 - models.bert_model - INFO - Epoch 10/10 - Batch 3520/10125 - Loss: 0.1231 - Acc: 95.97% - LR: 2.17e-07
2025-12-16 02:39:36 - models.bert_model - INFO - Epoch 10/10 - Batch 3560/10125 - Loss: 0.1531 - Acc: 95.96% - LR: 2.15e-07
2025-12-16 02:39:51 - models.bert_model - INFO - Epoch 10/10 - Batch 3600/10125 - Loss: 0.1349 - Acc: 95.97% - LR: 2.12e-07
2025-12-16 02:40:05 - models.bert_model - INFO - Epoch 10/10 - Batch 3640/10125 - Loss: 0.1028 - Acc: 95.97% - LR: 2.10e-07
2025-12-16 02:40:20 - models.bert_model - INFO - Epoch 10/10 - Batch 3680/10125 - Loss: 0.1274 - Acc: 95.97% - LR: 2.07e-07
2025-12-16 02:40:34 - models.bert_model - INFO - Epoch 10/10 - Batch 3720/10125 - Loss: 0.1107 - Acc: 95.96% - LR: 2.04e-07
2025-12-16 02:40:49 - models.bert_model - INFO - Epoch 10/10 - Batch 3760/10125 - Loss: 0.2021 - Acc: 95.96% - LR: 2.02e-07
2025-12-16 02:41:03 - models.bert_model - INFO - Epoch 10/10 - Batch 3800/10125 - Loss: 0.2370 - Acc: 95.97% - LR: 1.99e-07
2025-12-16 02:41:18 - models.bert_model - INFO - Epoch 10/10 - Batch 3840/10125 - Loss: 0.1220 - Acc: 95.97% - LR: 1.97e-07
2025-12-16 02:41:32 - models.bert_model - INFO - Epoch 10/10 - Batch 3880/10125 - Loss: 0.1478 - Acc: 95.97% - LR: 1.94e-07
2025-12-16 02:41:47 - models.bert_model - INFO - Epoch 10/10 - Batch 3920/10125 - Loss: 0.2937 - Acc: 95.97% - LR: 1.92e-07
2025-12-16 02:42:01 - models.bert_model - INFO - Epoch 10/10 - Batch 3960/10125 - Loss: 0.1099 - Acc: 95.97% - LR: 1.90e-07
2025-12-16 02:42:16 - models.bert_model - INFO - Epoch 10/10 - Batch 4000/10125 - Loss: 0.4092 - Acc: 95.96% - LR: 1.87e-07
2025-12-16 02:42:30 - models.bert_model - INFO - Epoch 10/10 - Batch 4040/10125 - Loss: 0.1154 - Acc: 95.96% - LR: 1.85e-07
2025-12-16 02:42:45 - models.bert_model - INFO - Epoch 10/10 - Batch 4080/10125 - Loss: 0.2372 - Acc: 95.96% - LR: 1.82e-07
2025-12-16 02:42:59 - models.bert_model - INFO - Epoch 10/10 - Batch 4120/10125 - Loss: 0.1186 - Acc: 95.95% - LR: 1.80e-07
2025-12-16 02:43:14 - models.bert_model - INFO - Epoch 10/10 - Batch 4160/10125 - Loss: 0.1356 - Acc: 95.95% - LR: 1.78e-07
2025-12-16 02:43:28 - models.bert_model - INFO - Epoch 10/10 - Batch 4200/10125 - Loss: 0.2632 - Acc: 95.95% - LR: 1.75e-07
2025-12-16 02:43:43 - models.bert_model - INFO - Epoch 10/10 - Batch 4240/10125 - Loss: 0.1092 - Acc: 95.94% - LR: 1.73e-07
2025-12-16 02:43:57 - models.bert_model - INFO - Epoch 10/10 - Batch 4280/10125 - Loss: 0.1538 - Acc: 95.93% - LR: 1.70e-07
2025-12-16 02:44:12 - models.bert_model - INFO - Epoch 10/10 - Batch 4320/10125 - Loss: 0.1076 - Acc: 95.94% - LR: 1.68e-07
2025-12-16 02:44:26 - models.bert_model - INFO - Epoch 10/10 - Batch 4360/10125 - Loss: 0.2075 - Acc: 95.94% - LR: 1.66e-07
2025-12-16 02:44:41 - models.bert_model - INFO - Epoch 10/10 - Batch 4400/10125 - Loss: 0.1811 - Acc: 95.94% - LR: 1.64e-07
2025-12-16 02:44:56 - models.bert_model - INFO - Epoch 10/10 - Batch 4440/10125 - Loss: 0.2622 - Acc: 95.95% - LR: 1.61e-07
2025-12-16 02:45:10 - models.bert_model - INFO - Epoch 10/10 - Batch 4480/10125 - Loss: 0.3345 - Acc: 95.94% - LR: 1.59e-07
2025-12-16 02:45:25 - models.bert_model - INFO - Epoch 10/10 - Batch 4520/10125 - Loss: 0.3125 - Acc: 95.94% - LR: 1.57e-07
2025-12-16 02:45:39 - models.bert_model - INFO - Epoch 10/10 - Batch 4560/10125 - Loss: 0.1942 - Acc: 95.94% - LR: 1.55e-07
2025-12-16 02:45:54 - models.bert_model - INFO - Epoch 10/10 - Batch 4600/10125 - Loss: 0.2231 - Acc: 95.94% - LR: 1.52e-07
2025-12-16 02:46:08 - models.bert_model - INFO - Epoch 10/10 - Batch 4640/10125 - Loss: 0.1397 - Acc: 95.93% - LR: 1.50e-07
2025-12-16 02:46:23 - models.bert_model - INFO - Epoch 10/10 - Batch 4680/10125 - Loss: 0.1990 - Acc: 95.93% - LR: 1.48e-07
2025-12-16 02:46:37 - models.bert_model - INFO - Epoch 10/10 - Batch 4720/10125 - Loss: 0.1081 - Acc: 95.93% - LR: 1.46e-07
2025-12-16 02:46:52 - models.bert_model - INFO - Epoch 10/10 - Batch 4760/10125 - Loss: 0.1352 - Acc: 95.93% - LR: 1.44e-07
2025-12-16 02:47:06 - models.bert_model - INFO - Epoch 10/10 - Batch 4800/10125 - Loss: 0.1077 - Acc: 95.92% - LR: 1.42e-07
2025-12-16 02:47:21 - models.bert_model - INFO - Epoch 10/10 - Batch 4840/10125 - Loss: 0.1223 - Acc: 95.92% - LR: 1.40e-07
2025-12-16 02:47:35 - models.bert_model - INFO - Epoch 10/10 - Batch 4880/10125 - Loss: 0.2081 - Acc: 95.92% - LR: 1.37e-07
2025-12-16 02:47:50 - models.bert_model - INFO - Epoch 10/10 - Batch 4920/10125 - Loss: 0.1124 - Acc: 95.93% - LR: 1.35e-07
2025-12-16 02:48:04 - models.bert_model - INFO - Epoch 10/10 - Batch 4960/10125 - Loss: 0.3427 - Acc: 95.92% - LR: 1.33e-07
2025-12-16 02:48:19 - models.bert_model - INFO - Epoch 10/10 - Batch 5000/10125 - Loss: 0.1060 - Acc: 95.92% - LR: 1.31e-07
2025-12-16 02:48:33 - models.bert_model - INFO - Epoch 10/10 - Batch 5040/10125 - Loss: 0.3704 - Acc: 95.91% - LR: 1.29e-07
2025-12-16 02:48:48 - models.bert_model - INFO - Epoch 10/10 - Batch 5080/10125 - Loss: 0.1116 - Acc: 95.92% - LR: 1.27e-07
2025-12-16 02:49:02 - models.bert_model - INFO - Epoch 10/10 - Batch 5120/10125 - Loss: 0.1326 - Acc: 95.93% - LR: 1.25e-07
2025-12-16 02:49:17 - models.bert_model - INFO - Epoch 10/10 - Batch 5160/10125 - Loss: 0.3413 - Acc: 95.94% - LR: 1.23e-07
2025-12-16 02:49:31 - models.bert_model - INFO - Epoch 10/10 - Batch 5200/10125 - Loss: 0.4171 - Acc: 95.94% - LR: 1.21e-07
2025-12-16 02:49:46 - models.bert_model - INFO - Epoch 10/10 - Batch 5240/10125 - Loss: 0.1194 - Acc: 95.94% - LR: 1.19e-07
2025-12-16 02:50:00 - models.bert_model - INFO - Epoch 10/10 - Batch 5280/10125 - Loss: 0.1408 - Acc: 95.93% - LR: 1.17e-07
2025-12-16 02:50:15 - models.bert_model - INFO - Epoch 10/10 - Batch 5320/10125 - Loss: 0.1194 - Acc: 95.94% - LR: 1.15e-07
2025-12-16 02:50:29 - models.bert_model - INFO - Epoch 10/10 - Batch 5360/10125 - Loss: 0.1301 - Acc: 95.93% - LR: 1.13e-07
2025-12-16 02:50:44 - models.bert_model - INFO - Epoch 10/10 - Batch 5400/10125 - Loss: 0.1597 - Acc: 95.93% - LR: 1.12e-07
2025-12-16 02:50:59 - models.bert_model - INFO - Epoch 10/10 - Batch 5440/10125 - Loss: 0.1315 - Acc: 95.93% - LR: 1.10e-07
2025-12-16 02:51:13 - models.bert_model - INFO - Epoch 10/10 - Batch 5480/10125 - Loss: 0.1126 - Acc: 95.93% - LR: 1.08e-07
2025-12-16 02:51:28 - models.bert_model - INFO - Epoch 10/10 - Batch 5520/10125 - Loss: 0.1274 - Acc: 95.93% - LR: 1.06e-07
2025-12-16 02:51:42 - models.bert_model - INFO - Epoch 10/10 - Batch 5560/10125 - Loss: 0.1232 - Acc: 95.93% - LR: 1.04e-07
2025-12-16 02:51:57 - models.bert_model - INFO - Epoch 10/10 - Batch 5600/10125 - Loss: 0.1122 - Acc: 95.93% - LR: 1.02e-07
2025-12-16 02:52:11 - models.bert_model - INFO - Epoch 10/10 - Batch 5640/10125 - Loss: 0.2905 - Acc: 95.93% - LR: 1.01e-07
2025-12-16 02:52:26 - models.bert_model - INFO - Epoch 10/10 - Batch 5680/10125 - Loss: 0.1502 - Acc: 95.93% - LR: 9.88e-08
2025-12-16 02:52:40 - models.bert_model - INFO - Epoch 10/10 - Batch 5720/10125 - Loss: 0.1599 - Acc: 95.94% - LR: 9.71e-08
2025-12-16 02:52:55 - models.bert_model - INFO - Epoch 10/10 - Batch 5760/10125 - Loss: 0.1021 - Acc: 95.94% - LR: 9.53e-08
2025-12-16 02:53:09 - models.bert_model - INFO - Epoch 10/10 - Batch 5800/10125 - Loss: 0.1338 - Acc: 95.94% - LR: 9.36e-08
2025-12-16 02:53:24 - models.bert_model - INFO - Epoch 10/10 - Batch 5840/10125 - Loss: 0.1112 - Acc: 95.94% - LR: 9.19e-08
2025-12-16 02:53:38 - models.bert_model - INFO - Epoch 10/10 - Batch 5880/10125 - Loss: 0.3283 - Acc: 95.95% - LR: 9.02e-08
2025-12-16 02:53:53 - models.bert_model - INFO - Epoch 10/10 - Batch 5920/10125 - Loss: 0.1878 - Acc: 95.95% - LR: 8.85e-08
2025-12-16 02:54:07 - models.bert_model - INFO - Epoch 10/10 - Batch 5960/10125 - Loss: 0.1493 - Acc: 95.94% - LR: 8.68e-08
2025-12-16 02:54:22 - models.bert_model - INFO - Epoch 10/10 - Batch 6000/10125 - Loss: 0.1140 - Acc: 95.94% - LR: 8.52e-08
2025-12-16 02:54:36 - models.bert_model - INFO - Epoch 10/10 - Batch 6040/10125 - Loss: 0.4601 - Acc: 95.93% - LR: 8.35e-08
2025-12-16 02:54:51 - models.bert_model - INFO - Epoch 10/10 - Batch 6080/10125 - Loss: 0.1095 - Acc: 95.92% - LR: 8.19e-08
2025-12-16 02:55:05 - models.bert_model - INFO - Epoch 10/10 - Batch 6120/10125 - Loss: 0.1612 - Acc: 95.93% - LR: 8.03e-08
2025-12-16 02:55:20 - models.bert_model - INFO - Epoch 10/10 - Batch 6160/10125 - Loss: 0.3838 - Acc: 95.93% - LR: 7.87e-08
2025-12-16 02:55:34 - models.bert_model - INFO - Epoch 10/10 - Batch 6200/10125 - Loss: 0.1120 - Acc: 95.93% - LR: 7.71e-08
2025-12-16 02:55:49 - models.bert_model - INFO - Epoch 10/10 - Batch 6240/10125 - Loss: 0.1596 - Acc: 95.93% - LR: 7.56e-08
2025-12-16 02:56:03 - models.bert_model - INFO - Epoch 10/10 - Batch 6280/10125 - Loss: 0.1190 - Acc: 95.94% - LR: 7.40e-08
2025-12-16 02:56:18 - models.bert_model - INFO - Epoch 10/10 - Batch 6320/10125 - Loss: 0.3744 - Acc: 95.94% - LR: 7.25e-08
2025-12-16 02:56:32 - models.bert_model - INFO - Epoch 10/10 - Batch 6360/10125 - Loss: 0.1368 - Acc: 95.94% - LR: 7.10e-08
2025-12-16 02:56:47 - models.bert_model - INFO - Epoch 10/10 - Batch 6400/10125 - Loss: 0.1694 - Acc: 95.94% - LR: 6.95e-08
2025-12-16 02:57:01 - models.bert_model - INFO - Epoch 10/10 - Batch 6440/10125 - Loss: 0.1102 - Acc: 95.94% - LR: 6.80e-08
2025-12-16 02:57:16 - models.bert_model - INFO - Epoch 10/10 - Batch 6480/10125 - Loss: 0.1071 - Acc: 95.94% - LR: 6.65e-08
2025-12-16 02:57:31 - models.bert_model - INFO - Epoch 10/10 - Batch 6520/10125 - Loss: 0.2413 - Acc: 95.93% - LR: 6.51e-08
2025-12-16 02:57:45 - models.bert_model - INFO - Epoch 10/10 - Batch 6560/10125 - Loss: 0.1470 - Acc: 95.92% - LR: 6.37e-08
2025-12-16 02:58:00 - models.bert_model - INFO - Epoch 10/10 - Batch 6600/10125 - Loss: 0.2734 - Acc: 95.93% - LR: 6.22e-08
2025-12-16 02:58:14 - models.bert_model - INFO - Epoch 10/10 - Batch 6640/10125 - Loss: 0.3877 - Acc: 95.94% - LR: 6.08e-08
2025-12-16 02:58:29 - models.bert_model - INFO - Epoch 10/10 - Batch 6680/10125 - Loss: 0.1420 - Acc: 95.94% - LR: 5.95e-08
2025-12-16 02:58:43 - models.bert_model - INFO - Epoch 10/10 - Batch 6720/10125 - Loss: 0.2917 - Acc: 95.94% - LR: 5.81e-08
2025-12-16 02:58:58 - models.bert_model - INFO - Epoch 10/10 - Batch 6760/10125 - Loss: 0.1064 - Acc: 95.94% - LR: 5.67e-08
2025-12-16 02:59:12 - models.bert_model - INFO - Epoch 10/10 - Batch 6800/10125 - Loss: 0.1719 - Acc: 95.94% - LR: 5.54e-08
2025-12-16 02:59:27 - models.bert_model - INFO - Epoch 10/10 - Batch 6840/10125 - Loss: 0.1123 - Acc: 95.94% - LR: 5.41e-08
2025-12-16 02:59:41 - models.bert_model - INFO - Epoch 10/10 - Batch 6880/10125 - Loss: 0.1629 - Acc: 95.95% - LR: 5.28e-08
2025-12-16 02:59:56 - models.bert_model - INFO - Epoch 10/10 - Batch 6920/10125 - Loss: 0.1102 - Acc: 95.95% - LR: 5.15e-08
2025-12-16 03:00:10 - models.bert_model - INFO - Epoch 10/10 - Batch 6960/10125 - Loss: 0.1059 - Acc: 95.95% - LR: 5.02e-08
2025-12-16 03:00:25 - models.bert_model - INFO - Epoch 10/10 - Batch 7000/10125 - Loss: 0.1337 - Acc: 95.96% - LR: 4.90e-08
2025-12-16 03:00:39 - models.bert_model - INFO - Epoch 10/10 - Batch 7040/10125 - Loss: 0.2175 - Acc: 95.96% - LR: 4.77e-08
2025-12-16 03:00:54 - models.bert_model - INFO - Epoch 10/10 - Batch 7080/10125 - Loss: 0.1505 - Acc: 95.97% - LR: 4.65e-08
2025-12-16 03:01:08 - models.bert_model - INFO - Epoch 10/10 - Batch 7120/10125 - Loss: 0.1802 - Acc: 95.96% - LR: 4.53e-08
2025-12-16 03:01:23 - models.bert_model - INFO - Epoch 10/10 - Batch 7160/10125 - Loss: 0.1538 - Acc: 95.97% - LR: 4.41e-08
2025-12-16 03:01:37 - models.bert_model - INFO - Epoch 10/10 - Batch 7200/10125 - Loss: 0.1094 - Acc: 95.97% - LR: 4.29e-08
2025-12-16 03:01:52 - models.bert_model - INFO - Epoch 10/10 - Batch 7240/10125 - Loss: 0.2916 - Acc: 95.97% - LR: 4.18e-08
2025-12-16 03:02:06 - models.bert_model - INFO - Epoch 10/10 - Batch 7280/10125 - Loss: 0.1200 - Acc: 95.97% - LR: 4.06e-08
2025-12-16 03:02:21 - models.bert_model - INFO - Epoch 10/10 - Batch 7320/10125 - Loss: 0.2541 - Acc: 95.98% - LR: 3.95e-08
2025-12-16 03:02:35 - models.bert_model - INFO - Epoch 10/10 - Batch 7360/10125 - Loss: 0.1096 - Acc: 95.99% - LR: 3.84e-08
2025-12-16 03:02:50 - models.bert_model - INFO - Epoch 10/10 - Batch 7400/10125 - Loss: 0.1864 - Acc: 95.98% - LR: 3.73e-08
2025-12-16 03:03:04 - models.bert_model - INFO - Epoch 10/10 - Batch 7440/10125 - Loss: 0.1473 - Acc: 95.99% - LR: 3.62e-08
2025-12-16 03:03:19 - models.bert_model - INFO - Epoch 10/10 - Batch 7480/10125 - Loss: 0.1414 - Acc: 95.98% - LR: 3.51e-08
2025-12-16 03:03:33 - models.bert_model - INFO - Epoch 10/10 - Batch 7520/10125 - Loss: 0.1210 - Acc: 95.98% - LR: 3.41e-08
2025-12-16 03:03:48 - models.bert_model - INFO - Epoch 10/10 - Batch 7560/10125 - Loss: 0.1009 - Acc: 95.99% - LR: 3.30e-08
2025-12-16 03:04:03 - models.bert_model - INFO - Epoch 10/10 - Batch 7600/10125 - Loss: 0.1095 - Acc: 95.98% - LR: 3.20e-08
2025-12-16 03:04:17 - models.bert_model - INFO - Epoch 10/10 - Batch 7640/10125 - Loss: 0.1054 - Acc: 95.99% - LR: 3.10e-08
2025-12-16 03:04:32 - models.bert_model - INFO - Epoch 10/10 - Batch 7680/10125 - Loss: 0.1109 - Acc: 95.98% - LR: 3.00e-08
2025-12-16 03:04:46 - models.bert_model - INFO - Epoch 10/10 - Batch 7720/10125 - Loss: 0.1281 - Acc: 95.99% - LR: 2.91e-08
2025-12-16 03:05:01 - models.bert_model - INFO - Epoch 10/10 - Batch 7760/10125 - Loss: 0.1476 - Acc: 95.98% - LR: 2.81e-08
2025-12-16 03:05:15 - models.bert_model - INFO - Epoch 10/10 - Batch 7800/10125 - Loss: 0.4632 - Acc: 95.98% - LR: 2.72e-08
2025-12-16 03:05:30 - models.bert_model - INFO - Epoch 10/10 - Batch 7840/10125 - Loss: 0.1709 - Acc: 95.98% - LR: 2.62e-08
2025-12-16 03:05:44 - models.bert_model - INFO - Epoch 10/10 - Batch 7880/10125 - Loss: 0.2738 - Acc: 95.98% - LR: 2.53e-08
2025-12-16 03:05:59 - models.bert_model - INFO - Epoch 10/10 - Batch 7920/10125 - Loss: 0.1238 - Acc: 95.98% - LR: 2.44e-08
2025-12-16 03:06:13 - models.bert_model - INFO - Epoch 10/10 - Batch 7960/10125 - Loss: 0.3729 - Acc: 95.98% - LR: 2.36e-08
2025-12-16 03:06:28 - models.bert_model - INFO - Epoch 10/10 - Batch 8000/10125 - Loss: 0.1111 - Acc: 95.98% - LR: 2.27e-08
2025-12-16 03:06:42 - models.bert_model - INFO - Epoch 10/10 - Batch 8040/10125 - Loss: 0.2757 - Acc: 95.98% - LR: 2.19e-08
2025-12-16 03:06:57 - models.bert_model - INFO - Epoch 10/10 - Batch 8080/10125 - Loss: 0.2703 - Acc: 95.98% - LR: 2.10e-08
2025-12-16 03:07:11 - models.bert_model - INFO - Epoch 10/10 - Batch 8120/10125 - Loss: 0.1453 - Acc: 95.98% - LR: 2.02e-08
2025-12-16 03:07:26 - models.bert_model - INFO - Epoch 10/10 - Batch 8160/10125 - Loss: 0.1129 - Acc: 95.98% - LR: 1.94e-08
2025-12-16 03:07:40 - models.bert_model - INFO - Epoch 10/10 - Batch 8200/10125 - Loss: 0.1210 - Acc: 95.97% - LR: 1.86e-08
2025-12-16 03:07:55 - models.bert_model - INFO - Epoch 10/10 - Batch 8240/10125 - Loss: 0.3351 - Acc: 95.98% - LR: 1.79e-08
2025-12-16 03:08:09 - models.bert_model - INFO - Epoch 10/10 - Batch 8280/10125 - Loss: 0.1123 - Acc: 95.97% - LR: 1.71e-08
2025-12-16 03:08:24 - models.bert_model - INFO - Epoch 10/10 - Batch 8320/10125 - Loss: 0.1116 - Acc: 95.97% - LR: 1.64e-08
2025-12-16 03:08:38 - models.bert_model - INFO - Epoch 10/10 - Batch 8360/10125 - Loss: 0.2741 - Acc: 95.97% - LR: 1.57e-08
2025-12-16 03:08:53 - models.bert_model - INFO - Epoch 10/10 - Batch 8400/10125 - Loss: 0.1143 - Acc: 95.97% - LR: 1.50e-08
2025-12-16 03:09:07 - models.bert_model - INFO - Epoch 10/10 - Batch 8440/10125 - Loss: 0.6088 - Acc: 95.97% - LR: 1.43e-08
2025-12-16 03:09:22 - models.bert_model - INFO - Epoch 10/10 - Batch 8480/10125 - Loss: 0.2532 - Acc: 95.97% - LR: 1.36e-08
2025-12-16 03:09:36 - models.bert_model - INFO - Epoch 10/10 - Batch 8520/10125 - Loss: 0.1067 - Acc: 95.97% - LR: 1.30e-08
2025-12-16 03:09:51 - models.bert_model - INFO - Epoch 10/10 - Batch 8560/10125 - Loss: 0.1097 - Acc: 95.97% - LR: 1.23e-08
2025-12-16 03:10:06 - models.bert_model - INFO - Epoch 10/10 - Batch 8600/10125 - Loss: 0.1384 - Acc: 95.98% - LR: 1.17e-08
2025-12-16 03:10:20 - models.bert_model - INFO - Epoch 10/10 - Batch 8640/10125 - Loss: 0.2084 - Acc: 95.98% - LR: 1.11e-08
2025-12-16 03:10:35 - models.bert_model - INFO - Epoch 10/10 - Batch 8680/10125 - Loss: 0.3185 - Acc: 95.98% - LR: 1.05e-08
2025-12-16 03:10:49 - models.bert_model - INFO - Epoch 10/10 - Batch 8720/10125 - Loss: 0.2458 - Acc: 95.98% - LR: 9.96e-09
2025-12-16 03:11:04 - models.bert_model - INFO - Epoch 10/10 - Batch 8760/10125 - Loss: 0.1701 - Acc: 95.98% - LR: 9.40e-09
2025-12-16 03:11:18 - models.bert_model - INFO - Epoch 10/10 - Batch 8800/10125 - Loss: 0.1224 - Acc: 95.98% - LR: 8.86e-09
2025-12-16 03:11:33 - models.bert_model - INFO - Epoch 10/10 - Batch 8840/10125 - Loss: 0.3492 - Acc: 95.97% - LR: 8.34e-09
2025-12-16 03:11:47 - models.bert_model - INFO - Epoch 10/10 - Batch 8880/10125 - Loss: 0.1344 - Acc: 95.98% - LR: 7.83e-09
2025-12-16 03:12:02 - models.bert_model - INFO - Epoch 10/10 - Batch 8920/10125 - Loss: 0.1106 - Acc: 95.97% - LR: 7.34e-09
2025-12-16 03:12:16 - models.bert_model - INFO - Epoch 10/10 - Batch 8960/10125 - Loss: 0.5066 - Acc: 95.97% - LR: 6.86e-09
2025-12-16 03:12:31 - models.bert_model - INFO - Epoch 10/10 - Batch 9000/10125 - Loss: 0.1196 - Acc: 95.97% - LR: 6.40e-09
2025-12-16 03:12:45 - models.bert_model - INFO - Epoch 10/10 - Batch 9040/10125 - Loss: 0.1180 - Acc: 95.97% - LR: 5.96e-09
2025-12-16 03:13:00 - models.bert_model - INFO - Epoch 10/10 - Batch 9080/10125 - Loss: 0.1679 - Acc: 95.97% - LR: 5.53e-09
2025-12-16 03:13:14 - models.bert_model - INFO - Epoch 10/10 - Batch 9120/10125 - Loss: 0.1331 - Acc: 95.97% - LR: 5.12e-09
2025-12-16 03:13:29 - models.bert_model - INFO - Epoch 10/10 - Batch 9160/10125 - Loss: 0.1598 - Acc: 95.97% - LR: 4.72e-09
2025-12-16 03:13:43 - models.bert_model - INFO - Epoch 10/10 - Batch 9200/10125 - Loss: 0.3496 - Acc: 95.97% - LR: 4.34e-09
2025-12-16 03:13:58 - models.bert_model - INFO - Epoch 10/10 - Batch 9240/10125 - Loss: 0.1496 - Acc: 95.97% - LR: 3.98e-09
2025-12-16 03:14:12 - models.bert_model - INFO - Epoch 10/10 - Batch 9280/10125 - Loss: 0.1042 - Acc: 95.98% - LR: 3.63e-09
2025-12-16 03:14:27 - models.bert_model - INFO - Epoch 10/10 - Batch 9320/10125 - Loss: 0.1986 - Acc: 95.98% - LR: 3.29e-09
2025-12-16 03:14:42 - models.bert_model - INFO - Epoch 10/10 - Batch 9360/10125 - Loss: 0.1299 - Acc: 95.98% - LR: 2.98e-09
2025-12-16 03:14:56 - models.bert_model - INFO - Epoch 10/10 - Batch 9400/10125 - Loss: 0.2456 - Acc: 95.98% - LR: 2.68e-09
2025-12-16 03:15:11 - models.bert_model - INFO - Epoch 10/10 - Batch 9440/10125 - Loss: 0.1715 - Acc: 95.98% - LR: 2.39e-09
2025-12-16 03:15:25 - models.bert_model - INFO - Epoch 10/10 - Batch 9480/10125 - Loss: 0.1251 - Acc: 95.98% - LR: 2.12e-09
2025-12-16 03:15:40 - models.bert_model - INFO - Epoch 10/10 - Batch 9520/10125 - Loss: 0.1069 - Acc: 95.98% - LR: 1.87e-09
2025-12-16 03:15:54 - models.bert_model - INFO - Epoch 10/10 - Batch 9560/10125 - Loss: 0.1070 - Acc: 95.99% - LR: 1.63e-09
2025-12-16 03:16:09 - models.bert_model - INFO - Epoch 10/10 - Batch 9600/10125 - Loss: 0.1079 - Acc: 95.99% - LR: 1.41e-09
2025-12-16 03:16:23 - models.bert_model - INFO - Epoch 10/10 - Batch 9640/10125 - Loss: 0.2703 - Acc: 95.98% - LR: 1.21e-09
2025-12-16 03:16:38 - models.bert_model - INFO - Epoch 10/10 - Batch 9680/10125 - Loss: 0.3265 - Acc: 95.97% - LR: 1.02e-09
2025-12-16 03:16:52 - models.bert_model - INFO - Epoch 10/10 - Batch 9720/10125 - Loss: 0.1262 - Acc: 95.97% - LR: 8.48e-10
2025-12-16 03:17:07 - models.bert_model - INFO - Epoch 10/10 - Batch 9760/10125 - Loss: 0.1505 - Acc: 95.97% - LR: 6.91e-10
2025-12-16 03:17:21 - models.bert_model - INFO - Epoch 10/10 - Batch 9800/10125 - Loss: 0.2408 - Acc: 95.97% - LR: 5.51e-10
2025-12-16 03:17:36 - models.bert_model - INFO - Epoch 10/10 - Batch 9840/10125 - Loss: 0.1042 - Acc: 95.98% - LR: 4.26e-10
2025-12-16 03:17:50 - models.bert_model - INFO - Epoch 10/10 - Batch 9880/10125 - Loss: 0.6833 - Acc: 95.98% - LR: 3.17e-10
2025-12-16 03:18:05 - models.bert_model - INFO - Epoch 10/10 - Batch 9920/10125 - Loss: 0.1457 - Acc: 95.98% - LR: 2.25e-10
2025-12-16 03:18:19 - models.bert_model - INFO - Epoch 10/10 - Batch 9960/10125 - Loss: 0.1502 - Acc: 95.98% - LR: 1.48e-10
2025-12-16 03:18:34 - models.bert_model - INFO - Epoch 10/10 - Batch 10000/10125 - Loss: 0.1328 - Acc: 95.98% - LR: 8.71e-11
2025-12-16 03:18:48 - models.bert_model - INFO - Epoch 10/10 - Batch 10040/10125 - Loss: 0.1621 - Acc: 95.98% - LR: 4.23e-11
2025-12-16 03:19:03 - models.bert_model - INFO - Epoch 10/10 - Batch 10080/10125 - Loss: 0.1508 - Acc: 95.98% - LR: 1.35e-11
2025-12-16 03:19:17 - models.bert_model - INFO - Epoch 10/10 - Batch 10120/10125 - Loss: 0.1446 - Acc: 95.98% - LR: 7.20e-13
2025-12-16 03:21:35 - models.bert_model - INFO - Epoch 10/10 - Train Loss: 0.1864, Train Acc: 95.98% - Val Loss: 0.2073, Val Acc: 94.93%
2025-12-16 03:21:35 - models.bert_model - INFO - Training completed. Best validation accuracy: 94.94%
2025-12-16 03:21:35 - models.bert_model - INFO - Predicting 20000 samples...
2025-12-16 03:24:11 - models.bert_model - INFO - Model saved to model/bert_log_version.pt
